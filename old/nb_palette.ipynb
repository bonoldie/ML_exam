{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image,ImageOps\n",
    "import io\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from package.utils.logger import logger\n",
    "import torch\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision.models import VGG16_Weights\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, adjusted_rand_score\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEFAULT_LOGGER: 2024-06-13 18:26:45,220 | INFO | 4067204959.py:44 ['data shape(train)', (1500, 40000)]\n",
      "DEFAULT_LOGGER: 2024-06-13 18:26:45,221 | INFO | 4067204959.py:45 ['data labels(train)', (1500,)]\n",
      "DEFAULT_LOGGER: 2024-06-13 18:26:45,223 | INFO | 4067204959.py:46 ['data unique labels(train)', array(['apple_pie', 'bibimbap', 'cannoli', 'edamame', 'falafel',\n",
      "       'french_toast', 'ice_cream', 'ramen', 'sushi', 'tiramisu'],\n",
      "      dtype='<U12')]\n",
      "DEFAULT_LOGGER: 2024-06-13 18:26:45,229 | INFO | 4067204959.py:44 ['data shape(valid)', (500, 40000)]\n",
      "DEFAULT_LOGGER: 2024-06-13 18:26:45,231 | INFO | 4067204959.py:45 ['data labels(valid)', (500,)]\n",
      "DEFAULT_LOGGER: 2024-06-13 18:26:45,232 | INFO | 4067204959.py:46 ['data unique labels(valid)', array(['apple_pie', 'bibimbap', 'cannoli', 'edamame', 'falafel',\n",
      "       'french_toast', 'ice_cream', 'ramen', 'sushi', 'tiramisu'],\n",
      "      dtype='<U12')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Bootstrap\n",
    "raw_dataset = np.load('.ds.tiny/dataset.zip')\n",
    "\n",
    "dataset = {\n",
    "    'train': {\n",
    "        'data': [],\n",
    "        'names': [],\n",
    "        'labels': [],\n",
    "        'unique_labels': [],\n",
    "    },\n",
    "    'valid': {\n",
    "        'data': [],\n",
    "        'names': [],\n",
    "        'labels': [],\n",
    "        'unique_labels': [],\n",
    "    }\n",
    "}\n",
    "\n",
    "images_shape = (200,200)\n",
    "\n",
    "# For each image we have the path from which we extract the name and the label of the image\n",
    "for dsKey in raw_dataset.keys():\n",
    "    splittedKey = dsKey.split('/')\n",
    "\n",
    "    img_type = splittedKey[2]\n",
    "    img_label = splittedKey[3]\n",
    "    img_name = splittedKey[4]\n",
    "    \n",
    "    img = Image.open(io.BytesIO(raw_dataset[dsKey]))\n",
    "    img = ImageOps.fit(img,images_shape, Image.Resampling.LANCZOS).convert('P')\n",
    "    \n",
    "    img_array = np.asarray(img).reshape(images_shape[0]*images_shape[1])\n",
    "    \n",
    "    dataset[img_type]['data'].append(img_array)\n",
    "    dataset[img_type]['names'].append(img_name)\n",
    "    dataset[img_type]['labels'].append(img_label)\n",
    "\n",
    "for img_type in dataset.keys():\n",
    "    dataset[img_type]['data'] = np.asarray(dataset[img_type]['data'])\n",
    "    dataset[img_type]['names'] = np.asarray(dataset[img_type]['names'])\n",
    "\n",
    "    dataset[img_type]['unique_labels'], dataset[img_type]['labels'] = np.unique(np.asarray(dataset[img_type]['labels']), return_inverse=True)\n",
    "\n",
    "    logger.info([f'data shape({img_type})', dataset[img_type]['data'].shape])\n",
    "    logger.info([f'data labels({img_type})', dataset[img_type]['labels'].shape])\n",
    "    logger.info([f'data unique labels({img_type})', dataset[img_type]['unique_labels']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEFAULT_LOGGER: 2024-06-13 18:38:35,371 | INFO | 2400584345.py:40 ['PCA (grayscale image, 120 components): explained_variance_ratio sum', 0.7869457025728887]\n",
      "DEFAULT_LOGGER: 2024-06-13 18:38:59,463 | INFO | 2400584345.py:40 ['PCA (grayscale image, 1000 components): explained_variance_ratio sum', 0.9677803302137998]\n",
      "DEFAULT_LOGGER: 2024-06-13 18:39:12,378 | INFO | 2400584345.py:62 ['LDA (grayscale image, 7 components): explained_variance_ratio sum', 0.8354278281803277]\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality reduction\n",
    "\n",
    "n_components_to_test = {\n",
    "    'PCA': [120,1000],#[3, 10, 50, 100, 200, 500, 1200],\n",
    "    'LDA': [7]#[3, 5, 7, 9]    \n",
    "}\n",
    "\n",
    "PCAs_instances = {}\n",
    "\n",
    "LDAs_instances = {}\n",
    "\n",
    "PCAs_results = {\n",
    "    'train': {},\n",
    "    'valid': {},\n",
    "}\n",
    "\n",
    "LDAs_results = {\n",
    "    'train': {},\n",
    "    'valid': {},\n",
    "}\n",
    "\n",
    "for n_components in n_components_to_test['PCA']:\n",
    "    PCAs_instances[n_components] = []\n",
    "\n",
    "    PCAs_results['train'][n_components] = []\n",
    "    PCAs_results['valid'][n_components] = []\n",
    "\n",
    "    PCA_instance = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        PCA(n_components=n_components)\n",
    "    )\n",
    "    \n",
    "    PCA_instance.fit(dataset['train']['data'])\n",
    "\n",
    "    PCAs_results['train'][n_components] = PCA_instance.transform(dataset['train']['data'])\n",
    "    PCAs_results['valid'][n_components] = PCA_instance.transform(dataset['valid']['data']) \n",
    "\n",
    "    PCAs_instances[n_components] = PCA_instance\n",
    "\n",
    "    logger.info([f'PCA ({n_components} components): explained_variance_ratio sum', np.sum(PCA_instance[1].explained_variance_ratio_,axis=0)])\n",
    "\n",
    "\n",
    "for n_components in n_components_to_test['LDA']:\n",
    "\n",
    "    LDAs_instances[n_components] = []\n",
    "\n",
    "    LDAs_results['train'][n_components] = []\n",
    "    LDAs_results['valid'][n_components] = []\n",
    "\n",
    "    LDA_instance = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LinearDiscriminantAnalysis(n_components=n_components)\n",
    "    )\n",
    "    \n",
    "    LDA_instance.fit(dataset['train']['data'], dataset['train']['labels'])\n",
    "\n",
    "    LDAs_results['train'][n_components] = LDA_instance.transform(dataset['train']['data'])\n",
    "    LDAs_results['valid'][n_components] = LDA_instance.transform(dataset['valid']['data']) \n",
    "\n",
    "    LDAs_instances[n_components] = LDA_instance\n",
    "\n",
    "    logger.info([f'LDA ({n_components} components): explained_variance_ratio sum', np.sum(LDA_instance[1].explained_variance_ratio_,axis=0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k\\PCA components</th>\n",
       "      <th>120</th>\n",
       "      <th>1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>(0.192, 0.211)</td>\n",
       "      <td>(0.166, 0.195)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>(0.194, 0.285)</td>\n",
       "      <td>(0.168, 0.106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>(0.2, 0.206)</td>\n",
       "      <td>(0.184, 0.186)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k\\PCA components             120            1000\n",
       "0                11  (0.192, 0.211)  (0.166, 0.195)\n",
       "1                19  (0.194, 0.285)  (0.168, 0.106)\n",
       "2                27    (0.2, 0.206)  (0.184, 0.186)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k\\LDA components</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [k\\LDA components, 7]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classification - KNN\n",
    "\n",
    "k_to_test = {\n",
    "    'PCA': [11,19,27],#np.linspace(15,25, dtype=int),#[3, 5, 9, 15, 21, 55, 111, 251],\n",
    "    'LDA': []#[3, 5, 9, 15, 21, 55, 111, 251]\n",
    "}\n",
    "\n",
    "KNN_PCA_stats = []\n",
    "KNN_LDA_stats = []\n",
    "\n",
    "for k_idx, k in enumerate(k_to_test['PCA']):\n",
    "\n",
    "    KNN_PCA_stats.insert(k_idx,[k])\n",
    "\n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['PCA']):\n",
    "        knn = OneVsOneClassifier(KNeighborsClassifier(k))\n",
    "\n",
    "        knn.fit(PCAs_results['train'][n_components], dataset['train']['labels'])\n",
    "        preds = knn.predict(PCAs_results['valid'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "        \n",
    "        KNN_PCA_stats[k_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "        #ConfusionMatrixDisplay(confusion_matrix(dataset['valid']['labels'], preds),display_labels=dataset['valid']['unique_labels']).plot()\n",
    "\n",
    "KNN_PCA_df = pd.DataFrame(KNN_PCA_stats, columns=['k\\\\PCA components'] + n_components_to_test['PCA'])\n",
    "display(KNN_PCA_df)\n",
    "\n",
    "for k_idx,k in enumerate(k_to_test['LDA']):\n",
    "    \n",
    "    KNN_LDA_stats.insert(k_idx,[k])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['LDA']):\n",
    "        knn = OneVsOneClassifier( KNeighborsClassifier(k))\n",
    "        \n",
    "        knn.fit(LDAs_results['train'][n_components], dataset['train']['labels'])\n",
    "        preds = knn.predict(LDAs_results['valid'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        KNN_LDA_stats[k_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "\n",
    "KNN_LDA_df = pd.DataFrame(KNN_LDA_stats, columns=['k\\\\LDA components'] + n_components_to_test['LDA'])\n",
    "display(KNN_LDA_df)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss\\PCA (grayscale)</th>\n",
       "      <th>120</th>\n",
       "      <th>1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modified_huber</td>\n",
       "      <td>(0.194, 0.184)</td>\n",
       "      <td>(0.196, 0.191)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_loss</td>\n",
       "      <td>(0.192, 0.183)</td>\n",
       "      <td>(0.186, 0.182)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hinge</td>\n",
       "      <td>(0.186, 0.181)</td>\n",
       "      <td>(0.18, 0.179)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  loss\\PCA (grayscale)             120            1000\n",
       "0       modified_huber  (0.194, 0.184)  (0.196, 0.191)\n",
       "1             log_loss  (0.192, 0.183)  (0.186, 0.182)\n",
       "2                hinge  (0.186, 0.181)   (0.18, 0.179)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss\\LDA (grayscale)</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modified_huber</td>\n",
       "      <td>(0.178, 0.206)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_loss</td>\n",
       "      <td>(0.186, 0.19)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hinge</td>\n",
       "      <td>(0.186, 0.184)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  loss\\LDA (grayscale)               7\n",
       "0       modified_huber  (0.178, 0.206)\n",
       "1             log_loss   (0.186, 0.19)\n",
       "2                hinge  (0.186, 0.184)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classification - SGD\n",
    "\n",
    "losses_to_test = {\n",
    "    'PCA': ['modified_huber', 'log_loss', 'hinge'],\n",
    "    'LDA': ['modified_huber', 'log_loss', 'hinge'],#['modified_huber', 'log_loss', 'hinge']\n",
    "}\n",
    "\n",
    "SGD_PCA_grayscale_stats = []\n",
    "SGD_LDA_grayscale_stats = []\n",
    "\n",
    "for loss_idx,loss in enumerate(losses_to_test['PCA']):\n",
    "\n",
    "    SGD_PCA_grayscale_stats.insert(loss_idx,[loss])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['PCA']):#n_components_to_test['PCA']):\n",
    "        svm = OneVsOneClassifier(SGDClassifier(loss=loss, max_iter=10000 ))\n",
    "\n",
    "        svm.fit(PCAs_results['train'][n_components], dataset['train']['labels'])\n",
    "\n",
    "        preds = svm.predict(PCAs_results['valid'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        SGD_PCA_grayscale_stats[loss_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "        # ConfusionMatrixDisplay(confusion_matrix(dataset['valid']['labels'], preds),display_labels=dataset['valid']['unique_labels']).plot()\n",
    "\n",
    "SGD_PCA_df = pd.DataFrame(SGD_PCA_grayscale_stats, columns=['loss\\\\PCA (grayscale)'] + n_components_to_test['PCA'])\n",
    "display(SGD_PCA_df)\n",
    "\n",
    "for loss_idx,loss in enumerate(losses_to_test['LDA']):\n",
    "\n",
    "    SGD_LDA_grayscale_stats.insert(loss_idx,[loss])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['LDA']):\n",
    "        svm = OneVsOneClassifier(SGDClassifier(loss=loss, max_iter=10000 ))\n",
    "\n",
    "        svm.fit(LDAs_results['train'][n_components], dataset['train']['labels'])\n",
    "\n",
    "        preds = svm.predict(LDAs_results['valid'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        SGD_LDA_grayscale_stats[loss_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "SGD_LDA_df = pd.DataFrame(SGD_LDA_grayscale_stats, columns=['loss\\\\LDA (grayscale)'] + n_components_to_test['LDA'])\n",
    "display(SGD_LDA_df)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel\\PCA components</th>\n",
       "      <th>120</th>\n",
       "      <th>1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poly</td>\n",
       "      <td>(0.216, 0.258)</td>\n",
       "      <td>(0.208, 0.268)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>(0.226, 0.197)</td>\n",
       "      <td>(0.226, 0.21)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernel\\PCA components             120            1000\n",
       "0                  poly  (0.216, 0.258)  (0.208, 0.268)\n",
       "1               sigmoid  (0.226, 0.197)   (0.226, 0.21)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel\\LDA components</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poly</td>\n",
       "      <td>(0.162, 0.204)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>(0.164, 0.161)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernel\\LDA components               7\n",
       "0                  poly  (0.162, 0.204)\n",
       "1               sigmoid  (0.164, 0.161)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classification - SVM\n",
    "\n",
    "kernels_to_test = {\n",
    "    'PCA': ['poly', 'sigmoid'],#['linear', 'poly', 'sigmoid'],\n",
    "    'LDA': ['linear']#['linear', 'poly', 'sigmoid'],\n",
    "}\n",
    "\n",
    "SVM_PCA_stats = []\n",
    "SVM_LDA_stats = []\n",
    "\n",
    "for kernel_idx,kernel in enumerate(kernels_to_test['PCA']):\n",
    "\n",
    "    SVM_PCA_stats.insert(kernel_idx,[kernel])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['PCA']):#n_components_to_test['PCA']):\n",
    "        svm = OneVsOneClassifier(SVC(kernel=kernel))\n",
    "\n",
    "        svm.fit(PCAs_results['train'][n_components], dataset['train']['labels'])\n",
    "\n",
    "        preds = svm.predict(PCAs_results['valid'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        SVM_PCA_stats[kernel_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "SVM_PCA_df = pd.DataFrame(SVM_PCA_stats, columns=['kernel\\\\PCA components'] + n_components_to_test['PCA'])\n",
    "display(SVM_PCA_df)\n",
    "\n",
    "for kernel_idx,kernel in enumerate(kernels_to_test['LDA']):\n",
    "\n",
    "    SVM_LDA_stats.insert(kernel_idx,[kernel])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['LDA']):\n",
    "        svm = OneVsOneClassifier(SVC(kernel=kernel))\n",
    "\n",
    "        svm.fit(LDAs_results['train'][n_components], dataset['train']['labels'])\n",
    "\n",
    "        preds = svm.predict(LDAs_results['valid'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        SVM_LDA_stats[kernel_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "SVM_LDA_df = pd.DataFrame(SVM_LDA_stats, columns=['kernel\\\\LDA components'] + n_components_to_test['LDA'])\n",
    "display(SVM_LDA_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
