{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "from numpy.dtypes import StrDType\n",
    "from matplotlib import pyplot as plt\n",
    "from package.utils.logger import logger\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, adjusted_rand_score\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEFAULT_LOGGER: 2024-06-04 14:27:43,492 | INFO | 2263878544.py:42 ['data shape(train)', (1500, 16384, 3)]\n",
      "DEFAULT_LOGGER: 2024-06-04 14:27:43,492 | INFO | 2263878544.py:43 ['data labels(train)', (1500,)]\n",
      "DEFAULT_LOGGER: 2024-06-04 14:27:43,493 | INFO | 2263878544.py:44 ['data unique labels(train)', array(['apple_pie', 'bibimbap', 'cannoli', 'edamame', 'falafel',\n",
      "       'french_toast', 'ice_cream', 'ramen', 'sushi', 'tiramisu'],\n",
      "      dtype='<U12')]\n",
      "DEFAULT_LOGGER: 2024-06-04 14:27:43,499 | INFO | 2263878544.py:42 ['data shape(valid)', (500, 16384, 3)]\n",
      "DEFAULT_LOGGER: 2024-06-04 14:27:43,500 | INFO | 2263878544.py:43 ['data labels(valid)', (500,)]\n",
      "DEFAULT_LOGGER: 2024-06-04 14:27:43,500 | INFO | 2263878544.py:44 ['data unique labels(valid)', array(['apple_pie', 'bibimbap', 'cannoli', 'edamame', 'falafel',\n",
      "       'french_toast', 'ice_cream', 'ramen', 'sushi', 'tiramisu'],\n",
      "      dtype='<U12')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Bootstrap\n",
    "raw_dataset = np.load('.ds.tiny/dataset.zip')\n",
    "\n",
    "dataset = {\n",
    "    'train': {\n",
    "        'data': [],\n",
    "        'names': [],\n",
    "        'labels': [],\n",
    "        'unique_labels': [],\n",
    "    },\n",
    "    'valid': {\n",
    "        'data': [],\n",
    "        'names': [],\n",
    "        'labels': [],\n",
    "        'unique_labels': [],\n",
    "    }\n",
    "}\n",
    "\n",
    "images_resize_shape = (128,128)\n",
    "\n",
    "# For each image we have the path from which we extract the name and the label of the image\n",
    "for dsKey in raw_dataset.keys():\n",
    "    splittedKey = dsKey.split('/')\n",
    "\n",
    "    img_type = splittedKey[2]\n",
    "    img_label = splittedKey[3]\n",
    "    img_name = splittedKey[4]\n",
    "    \n",
    "    img = Image.open(io.BytesIO(raw_dataset[dsKey])).resize(images_resize_shape, Image.Resampling.LANCZOS)\n",
    "    img_array = np.asarray(img).reshape(images_resize_shape[0]*images_resize_shape[1], 3)\n",
    "    \n",
    "    dataset[img_type]['data'].append(img_array)\n",
    "    dataset[img_type]['names'].append(img_name)\n",
    "    dataset[img_type]['labels'].append(img_label)\n",
    "\n",
    "for img_type in dataset.keys():\n",
    "    dataset[img_type]['data'] = np.asarray(dataset[img_type]['data'])\n",
    "    dataset[img_type]['names'] = np.asarray(dataset[img_type]['names'])\n",
    "\n",
    "    dataset[img_type]['unique_labels'], dataset[img_type]['labels'] = np.unique(np.asarray(dataset[img_type]['labels']), return_inverse=True)\n",
    "\n",
    "    logger.info([f'data shape({img_type})', dataset[img_type]['data'].shape])\n",
    "    logger.info([f'data labels({img_type})', dataset[img_type]['labels'].shape])\n",
    "    logger.info([f'data unique labels({img_type})', dataset[img_type]['unique_labels']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEFAULT_LOGGER: 2024-06-04 15:13:31,251 | INFO | 2195140652.py:78 ['PCA (channel 0, 1200 components): explained_variance_ratio sum', 0.995446612574062]\n",
      "DEFAULT_LOGGER: 2024-06-04 15:13:48,118 | INFO | 2195140652.py:78 ['PCA (channel 1, 1200 components): explained_variance_ratio sum', 0.9947216163948556]\n",
      "DEFAULT_LOGGER: 2024-06-04 15:14:05,381 | INFO | 2195140652.py:78 ['PCA (channel 2, 1200 components): explained_variance_ratio sum', 0.9950718531475843]\n",
      "DEFAULT_LOGGER: 2024-06-04 15:14:22,367 | INFO | 2195140652.py:88 ['PCA (grayscale image, 1200 components): explained_variance_ratio sum', 0.994628499786816]\n",
      "DEFAULT_LOGGER: 2024-06-04 15:14:40,558 | INFO | 2195140652.py:125 ['LDA (channel 0, 9 components): explained_variance_ratio sum', 1.0]\n",
      "DEFAULT_LOGGER: 2024-06-04 15:14:58,417 | INFO | 2195140652.py:125 ['LDA (channel 1, 9 components): explained_variance_ratio sum', 0.9999999999999998]\n",
      "DEFAULT_LOGGER: 2024-06-04 15:15:15,385 | INFO | 2195140652.py:125 ['LDA (channel 2, 9 components): explained_variance_ratio sum', 0.9999999999999999]\n",
      "DEFAULT_LOGGER: 2024-06-04 15:15:31,529 | INFO | 2195140652.py:136 ['LDA (grayscale image, 9 components): explained_variance_ratio sum', 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality reduction\n",
    "\n",
    "n_components_to_test = {\n",
    "    'PCA': [1200],#[3, 10, 50, 100, 200, 500],\n",
    "    'LDA': [9]#[3, 5, 7, 9]    \n",
    "}\n",
    "\n",
    "PCAs_instances = {\n",
    "    'original': {},\n",
    "    'grayscale': {}\n",
    "}\n",
    "\n",
    "LDAs_instances = {\n",
    "    'original': {},\n",
    "    'grayscale': {}\n",
    "}\n",
    "\n",
    "PCAs_results = {\n",
    "    'train': {\n",
    "        'original': {},\n",
    "        'grayscale': {}\n",
    "    },\n",
    "    'valid': {\n",
    "        'original': {},\n",
    "        'grayscale': {}\n",
    "    },\n",
    "}\n",
    "\n",
    "LDAs_results = {\n",
    "    'train': {\n",
    "        'original': {},\n",
    "        'grayscale': {}\n",
    "    },\n",
    "    'valid': {\n",
    "        'original': {},\n",
    "        'grayscale': {}\n",
    "    },\n",
    "}\n",
    "\n",
    "# Grayscaled data\n",
    "grayscale_train_images = np.mean(dataset['train']['data'], axis=2)\n",
    "grayscale_valid_images = np.mean(dataset['valid']['data'], axis=2)\n",
    "\n",
    "for n_components in n_components_to_test['PCA']:\n",
    "    PCAs_instances['original'][n_components] = []\n",
    "    PCAs_instances['grayscale'][n_components] = []\n",
    "\n",
    "    PCAs_results['train']['original'][n_components] = []\n",
    "    PCAs_results['train']['grayscale'][n_components] = []\n",
    "    PCAs_results['valid']['original'][n_components] = []\n",
    "    PCAs_results['valid']['grayscale'][n_components] = []\n",
    "\n",
    "    PCA_original = [\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            PCA(n_components=n_components)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            PCA(n_components=n_components)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            PCA(n_components=n_components)\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    PCA_grayscale = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        PCA(n_components=n_components)\n",
    "    )\n",
    "\n",
    "    # Multichannel section\n",
    "    for i in range(3):\n",
    "        PCA_original[i].fit(dataset['train']['data'][:,:,i]) \n",
    "        PCAs_results['train']['original'][n_components].append(PCA_original[i].transform(dataset['train']['data'][:,:,i]))\n",
    "        PCAs_results['valid']['original'][n_components].append(PCA_original[i].transform(dataset['valid']['data'][:,:,i]))\n",
    "        logger.info([f'PCA (channel {i}, {n_components} components): explained_variance_ratio sum', np.sum(PCA_original[i][1].explained_variance_ratio_, axis=0)])\n",
    "\n",
    "    PCAs_instances['original'][n_components].append(PCA_original)\n",
    "\n",
    "    # Grayscale section\n",
    "    PCA_grayscale.fit(grayscale_train_images)\n",
    "\n",
    "    PCAs_results['train']['grayscale'][n_components] = PCA_grayscale.transform(grayscale_train_images)\n",
    "    PCAs_results['valid']['grayscale'][n_components] = PCA_grayscale.transform(grayscale_valid_images)\n",
    "\n",
    "    logger.info([f'PCA (grayscale image, {n_components} components): explained_variance_ratio sum', np.sum(PCA_grayscale[1].explained_variance_ratio_, axis=0)])\n",
    "\n",
    "for n_components in n_components_to_test['LDA']:\n",
    "    LDAs_instances['original'][n_components] = []\n",
    "    LDAs_instances['grayscale'][n_components] = []\n",
    "\n",
    "    LDAs_results['train']['original'][n_components] = []\n",
    "    LDAs_results['train']['grayscale'][n_components] = []\n",
    "    LDAs_results['valid']['original'][n_components] = []\n",
    "    LDAs_results['valid']['grayscale'][n_components] = []\n",
    "\n",
    "    LDA_original = [\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            LinearDiscriminantAnalysis(n_components=n_components)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            LinearDiscriminantAnalysis(n_components=n_components)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            StandardScaler(),\n",
    "            LinearDiscriminantAnalysis(n_components=n_components)\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    LDA_grayscale = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LinearDiscriminantAnalysis(n_components=n_components)\n",
    "    )\n",
    "\n",
    "\n",
    "    # Multichannel section\n",
    "    for i in range(3):\n",
    "        LDA_original[i].fit(dataset['train']['data'][:,:,i], dataset['train']['labels']) \n",
    "        LDAs_results['train']['original'][n_components].append(LDA_original[i].transform(dataset['train']['data'][:,:,i]))\n",
    "        LDAs_results['valid']['original'][n_components].append(LDA_original[i].transform(dataset['valid']['data'][:,:,i]))\n",
    "        logger.info([f'LDA (channel {i}, {n_components} components): explained_variance_ratio sum', np.sum(LDA_original[i][1].explained_variance_ratio_, axis=0)])\n",
    "\n",
    "    LDAs_instances['original'][n_components].append(LDA_original)\n",
    "\n",
    "    # Grayscale section\n",
    "    LDA_grayscale.fit(grayscale_train_images,dataset['train']['labels'])\n",
    "\n",
    "    \n",
    "    LDAs_results['train']['grayscale'][n_components] = LDA_grayscale.transform(grayscale_train_images)\n",
    "    LDAs_results['valid']['grayscale'][n_components] = LDA_grayscale.transform(grayscale_valid_images)\n",
    "\n",
    "    logger.info([f'LDA (grayscale image, {n_components} components): explained_variance_ratio sum', np.sum(LDA_grayscale[1].explained_variance_ratio_, axis=0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k\\PCA components</th>\n",
       "      <th>1000</th>\n",
       "      <th>1500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>(0.136, 0.201)</td>\n",
       "      <td>(0.14, 0.204)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>(0.132, 0.171)</td>\n",
       "      <td>(0.128, 0.173)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>(0.144, 0.223)</td>\n",
       "      <td>(0.146, 0.21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>(0.144, 0.232)</td>\n",
       "      <td>(0.138, 0.228)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>(0.14, 0.245)</td>\n",
       "      <td>(0.142, 0.235)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27</td>\n",
       "      <td>(0.15, 0.225)</td>\n",
       "      <td>(0.148, 0.22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55</td>\n",
       "      <td>(0.162, 0.195)</td>\n",
       "      <td>(0.158, 0.19)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>111</td>\n",
       "      <td>(0.154, 0.267)</td>\n",
       "      <td>(0.156, 0.28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>251</td>\n",
       "      <td>(0.192, 0.146)</td>\n",
       "      <td>(0.192, 0.158)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k\\PCA components            1000            1500\n",
       "0                 3  (0.136, 0.201)   (0.14, 0.204)\n",
       "1                 5  (0.132, 0.171)  (0.128, 0.173)\n",
       "2                 9  (0.144, 0.223)   (0.146, 0.21)\n",
       "3                15  (0.144, 0.232)  (0.138, 0.228)\n",
       "4                21   (0.14, 0.245)  (0.142, 0.235)\n",
       "5                27   (0.15, 0.225)   (0.148, 0.22)\n",
       "6                55  (0.162, 0.195)   (0.158, 0.19)\n",
       "7               111  (0.154, 0.267)   (0.156, 0.28)\n",
       "8               251  (0.192, 0.146)  (0.192, 0.158)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k\\LDA components</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>(0.14, 0.16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>(0.134, 0.141)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>(0.138, 0.142)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>(0.138, 0.138)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>(0.144, 0.145)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27</td>\n",
       "      <td>(0.148, 0.151)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55</td>\n",
       "      <td>(0.146, 0.144)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>111</td>\n",
       "      <td>(0.142, 0.139)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>251</td>\n",
       "      <td>(0.144, 0.142)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k\\LDA components               3\n",
       "0                 3    (0.14, 0.16)\n",
       "1                 5  (0.134, 0.141)\n",
       "2                 9  (0.138, 0.142)\n",
       "3                15  (0.138, 0.138)\n",
       "4                21  (0.144, 0.145)\n",
       "5                27  (0.148, 0.151)\n",
       "6                55  (0.146, 0.144)\n",
       "7               111  (0.142, 0.139)\n",
       "8               251  (0.144, 0.142)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classification - KNN\n",
    "\n",
    "k_to_test = {\n",
    "    'PCA': [3, 5, 9, 15, 21, 27, 55, 111, 251],\n",
    "    'LDA': [3, 5, 9, 15, 21, 27, 55, 111, 251]\n",
    "}\n",
    "\n",
    "KNN_PCA_stats = []\n",
    "KNN_LDA_stats = []\n",
    "\n",
    "for k_idx, k in enumerate(k_to_test['PCA']):\n",
    "\n",
    "    KNN_PCA_stats.insert(k_idx,[k])\n",
    "\n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['PCA']):\n",
    "        knn = OneVsOneClassifier(KNeighborsClassifier(k))\n",
    "\n",
    "        knn.fit(PCAs_results['train']['grayscale'][n_components], dataset['train']['labels'])\n",
    "        preds = knn.predict(PCAs_results['valid']['grayscale'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "        \n",
    "        # logger.info([f\"KNN on PCA (grayscale images, k = {k}, {n_components} components)\", \"accuracy\", accuracy, \"precision\", precision])\n",
    "\n",
    "        KNN_PCA_stats[k_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "\n",
    "for k_idx,k in enumerate(k_to_test['LDA']):\n",
    "    \n",
    "    KNN_LDA_stats.insert(k_idx,[k])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['LDA']):\n",
    "        knn = OneVsRestClassifier( KNeighborsClassifier(k))\n",
    "        \n",
    "        knn.fit(LDAs_results['train']['grayscale'][n_components], dataset['train']['labels'])\n",
    "        preds = knn.predict(LDAs_results['valid']['grayscale'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        # logger.info([f\"KNN on LDA (grayscale images, k = {k}, {n_components} components)\", \"accuracy\", accuracy, \"precision\", precision])\n",
    "\n",
    "        KNN_LDA_stats[k_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "KNN_PCA_df = pd.DataFrame(KNN_PCA_stats, columns=['k\\\\PCA components'] + n_components_to_test['PCA'])\n",
    "KNN_LDA_df = pd.DataFrame(KNN_LDA_stats, columns=['k\\\\LDA components'] + n_components_to_test['LDA'])\n",
    "\n",
    "display(KNN_PCA_df)\n",
    "display(KNN_LDA_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel\\PCA components</th>\n",
       "      <th>1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poly</td>\n",
       "      <td>(0.208, 0.275)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernel\\PCA components            1200\n",
       "0                  poly  (0.208, 0.275)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel\\LDA components</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poly</td>\n",
       "      <td>(0.126, 0.135)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernel\\LDA components               9\n",
       "0                  poly  (0.126, 0.135)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "kernels_to_test = {\n",
    "    'PCA': ['poly'],#['linear', 'poly', 'sigmoid'],\n",
    "    'LDA': ['poly']#['linear', 'poly', 'sigmoid'],\n",
    "}\n",
    "\n",
    "SVM_PCA_stats = []\n",
    "SVM_LDA_stats = []\n",
    "\n",
    "for kernel_idx,kernel in enumerate(kernels_to_test['PCA']):\n",
    "\n",
    "    SVM_PCA_stats.insert(kernel_idx,[kernel])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['PCA']):#n_components_to_test['PCA']):\n",
    "        svm = OneVsOneClassifier(SVC(kernel=kernel))\n",
    "\n",
    "        svm.fit(PCAs_results['train']['grayscale'][n_components], dataset['train']['labels'])\n",
    "\n",
    "        preds = svm.predict(PCAs_results['valid']['grayscale'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        SVM_PCA_stats[kernel_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "\n",
    "for kernel_idx,kernel in enumerate(kernels_to_test['LDA']):\n",
    "\n",
    "    SVM_LDA_stats.insert(kernel_idx,[kernel])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['LDA']):\n",
    "        svm = SVC(kernel=kernel)\n",
    "\n",
    "        svm.fit(LDAs_results['train']['grayscale'][n_components], dataset['train']['labels'])\n",
    "\n",
    "        preds = svm.predict(LDAs_results['valid']['grayscale'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        SVM_LDA_stats[kernel_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "SVM_PCA_stats = pd.DataFrame(SVM_PCA_stats, columns=['kernel\\\\PCA components'] + n_components_to_test['PCA'])\n",
    "SVM_LDA_stats = pd.DataFrame(SVM_LDA_stats, columns=['kernel\\\\LDA components'] + n_components_to_test['LDA'])\n",
    "\n",
    "display(SVM_PCA_stats)\n",
    "display(SVM_LDA_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>components\\PCA components</th>\n",
       "      <th>3</th>\n",
       "      <th>10</th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>200</th>\n",
       "      <th>500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   components\\PCA components      3     10     50    100    200    500\n",
       "0                         15  0.017  0.010  0.010  0.002 -0.000  0.009\n",
       "1                         30  0.013  0.008  0.007 -0.000  0.005  0.010\n",
       "2                        100  0.008  0.010  0.001  0.000  0.019  0.008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GMM\n",
    "\n",
    "GMM_n_components_to_test = {\n",
    "    'PCA': [15, 30, 100]\n",
    "}\n",
    "\n",
    "GMM_PCA_score = []\n",
    "\n",
    "for GMM_n_components_idx,GMM_n_components in enumerate(GMM_n_components_to_test['PCA']):\n",
    "\n",
    "    GMM_PCA_score.insert(GMM_n_components_idx,[GMM_n_components])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['PCA']):\n",
    "        gmm = GaussianMixture(n_components=GMM_n_components)\n",
    "\n",
    "        gmm.fit(PCAs_results['train']['grayscale'][n_components])\n",
    "\n",
    "        preds = gmm.predict(PCAs_results['valid']['grayscale'][n_components])\n",
    "\n",
    "        rand_score = round(adjusted_rand_score(dataset['valid']['labels'], preds),3)\n",
    "\n",
    "        GMM_PCA_score[GMM_n_components_idx].insert(n_components_idx + 1,(rand_score))\n",
    "\n",
    "GMM_PCA_stats = pd.DataFrame(GMM_PCA_score, columns=['components\\\\PCA components'] + n_components_to_test['PCA'])\n",
    "\n",
    "display(GMM_PCA_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
