{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "from numpy.dtypes import StrDType\n",
    "from matplotlib import pyplot as plt\n",
    "from package.utils.logger import logger\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from scipy.stats import multivariate_normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEFAULT_LOGGER: 2024-06-03 17:20:30,308 | INFO | 2263878544.py:42 ['data shape(train)', (1500, 16384, 3)]\n",
      "DEFAULT_LOGGER: 2024-06-03 17:20:30,309 | INFO | 2263878544.py:43 ['data labels(train)', (1500,)]\n",
      "DEFAULT_LOGGER: 2024-06-03 17:20:30,309 | INFO | 2263878544.py:44 ['data unique labels(train)', array(['apple_pie', 'bibimbap', 'cannoli', 'edamame', 'falafel',\n",
      "       'french_toast', 'ice_cream', 'ramen', 'sushi', 'tiramisu'],\n",
      "      dtype='<U12')]\n",
      "DEFAULT_LOGGER: 2024-06-03 17:20:30,312 | INFO | 2263878544.py:42 ['data shape(valid)', (500, 16384, 3)]\n",
      "DEFAULT_LOGGER: 2024-06-03 17:20:30,313 | INFO | 2263878544.py:43 ['data labels(valid)', (500,)]\n",
      "DEFAULT_LOGGER: 2024-06-03 17:20:30,313 | INFO | 2263878544.py:44 ['data unique labels(valid)', array(['apple_pie', 'bibimbap', 'cannoli', 'edamame', 'falafel',\n",
      "       'french_toast', 'ice_cream', 'ramen', 'sushi', 'tiramisu'],\n",
      "      dtype='<U12')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Bootstrap\n",
    "raw_dataset = np.load('.ds.tiny/dataset.zip')\n",
    "\n",
    "dataset = {\n",
    "    'train': {\n",
    "        'data': [],\n",
    "        'names': [],\n",
    "        'labels': [],\n",
    "        'unique_labels': [],\n",
    "    },\n",
    "    'valid': {\n",
    "        'data': [],\n",
    "        'names': [],\n",
    "        'labels': [],\n",
    "        'unique_labels': [],\n",
    "    }\n",
    "}\n",
    "\n",
    "images_resize_shape = (128,128)\n",
    "\n",
    "# For each image we have the path from which we extract the name and the label of the image\n",
    "for dsKey in raw_dataset.keys():\n",
    "    splittedKey = dsKey.split('/')\n",
    "\n",
    "    img_type = splittedKey[2]\n",
    "    img_label = splittedKey[3]\n",
    "    img_name = splittedKey[4]\n",
    "    \n",
    "    img = Image.open(io.BytesIO(raw_dataset[dsKey])).resize(images_resize_shape, Image.Resampling.LANCZOS)\n",
    "    img_array = np.asarray(img).reshape(images_resize_shape[0]*images_resize_shape[1], 3)\n",
    "    \n",
    "    dataset[img_type]['data'].append(img_array)\n",
    "    dataset[img_type]['names'].append(img_name)\n",
    "    dataset[img_type]['labels'].append(img_label)\n",
    "\n",
    "for img_type in dataset.keys():\n",
    "    dataset[img_type]['data'] = np.asarray(dataset[img_type]['data'])\n",
    "    dataset[img_type]['names'] = np.asarray(dataset[img_type]['names'])\n",
    "\n",
    "    dataset[img_type]['unique_labels'], dataset[img_type]['labels'] = np.unique(np.asarray(dataset[img_type]['labels']), return_inverse=True)\n",
    "\n",
    "    logger.info([f'data shape({img_type})', dataset[img_type]['data'].shape])\n",
    "    logger.info([f'data labels({img_type})', dataset[img_type]['labels'].shape])\n",
    "    logger.info([f'data unique labels({img_type})', dataset[img_type]['unique_labels']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_images \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_images\u001b[49m[:,:,:,:]\u001b[38;5;241m.\u001b[39mreshape((train_images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], train_images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39mtrain_images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m      2\u001b[0m test_images \u001b[38;5;241m=\u001b[39m test_images[:,:,:,:]\u001b[38;5;241m.\u001b[39mreshape((test_images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], test_images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39mtest_images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m      4\u001b[0m pca \u001b[38;5;241m=\u001b[39m [PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m), PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m), PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dimensionality reduction \n",
    "\n",
    "\n",
    "\n",
    "train_images = train_images[:,:,:,:].reshape((train_images.shape[0], train_images.shape[1]*train_images.shape[2], 3))\n",
    "test_images = test_images[:,:,:,:].reshape((test_images.shape[0], test_images.shape[1]*test_images.shape[2], 3))\n",
    "\n",
    "pca = [PCA(n_components=10), PCA(n_components=10), PCA(n_components=10)]\n",
    "\n",
    "pca_train_images = []\n",
    "pca_test_images = []\n",
    "\n",
    "for i in range(3):\n",
    "    pca[i].fit(train_images[:,:,i]) \n",
    "    pca_train_images.append(pca[i].transform(train_images[:,:,i])) \n",
    "    pca_test_images.append(pca[i].transform(test_images[:,:,i])) \n",
    "\n",
    "    logger.info([f'PCA{i} variance ratio: ', np.sum(pca[i].explained_variance_ratio_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = []\n",
    "\n",
    "for labelIdx in range(unique_train_labels.shape[0]):\n",
    "    estimators.append([])\n",
    "    label = unique_train_labels[labelIdx]\n",
    "\n",
    "    for i in range(3):\n",
    "        estimators[labelIdx].append(multivariate_normal(np.mean(pca_train_images[i][train_labels == label], axis=0), np.cov(np.transpose(pca_train_images[i][train_labels == label])), allow_singular=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.327427937216965e-37\n",
      "2.0696532111436884e-37\n",
      "1.5736377499224094e-37\n",
      "0.248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7908f605c280>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estims = np.zeros((len(estimators), 3, test_images.shape[0]))\n",
    "\n",
    "for estimator_idx in range(len(estimators)):\n",
    "    for color_idx in range(3):\n",
    "        estims[estimator_idx,color_idx] = estimators[estimator_idx][color_idx].pdf(pca_test_images[color_idx])\n",
    "\n",
    "max_estims_idx = np.argmax(estims.sum(1),0)\n",
    "\n",
    "max_estims = unique_test_labels[max_estims_idx]\n",
    "\n",
    "print(np.count_nonzero(max_estims == test_labels)/test_images.shape[0])\n",
    "\n",
    "plt.show()\n",
    "ConfusionMatrixDisplay(confusion_matrix(test_labels, max_estims),display_labels=unique_test_labels).plot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
