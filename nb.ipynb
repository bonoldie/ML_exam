{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image,ImageOps\n",
    "import io\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from package.utils.logger import logger\n",
    "import torch\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision.models import VGG16_Weights\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, adjusted_rand_score\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEFAULT_LOGGER: 2024-07-02 17:23:10,242 | INFO | 2472717071.py:44 ['data shape(train)', (1500, 40000, 3)]\n",
      "DEFAULT_LOGGER: 2024-07-02 17:23:10,244 | INFO | 2472717071.py:45 ['data labels(train)', (1500,)]\n",
      "DEFAULT_LOGGER: 2024-07-02 17:23:10,245 | INFO | 2472717071.py:46 ['data unique labels(train)', array(['apple_pie', 'bibimbap', 'cannoli', 'edamame', 'falafel',\n",
      "       'french_toast', 'ice_cream', 'ramen', 'sushi', 'tiramisu'],\n",
      "      dtype='<U12')]\n",
      "DEFAULT_LOGGER: 2024-07-02 17:23:10,297 | INFO | 2472717071.py:44 ['data shape(valid)', (500, 40000, 3)]\n",
      "DEFAULT_LOGGER: 2024-07-02 17:23:10,300 | INFO | 2472717071.py:45 ['data labels(valid)', (500,)]\n",
      "DEFAULT_LOGGER: 2024-07-02 17:23:10,301 | INFO | 2472717071.py:46 ['data unique labels(valid)', array(['apple_pie', 'bibimbap', 'cannoli', 'edamame', 'falafel',\n",
      "       'french_toast', 'ice_cream', 'ramen', 'sushi', 'tiramisu'],\n",
      "      dtype='<U12')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Bootstrap\n",
    "raw_dataset = np.load('.ds.tiny/dataset.zip')\n",
    "\n",
    "dataset = {\n",
    "    'train': {\n",
    "        'data': [],\n",
    "        'names': [],\n",
    "        'labels': [],\n",
    "        'unique_labels': [],\n",
    "    },\n",
    "    'valid': {\n",
    "        'data': [],\n",
    "        'names': [],\n",
    "        'labels': [],\n",
    "        'unique_labels': [],\n",
    "    }\n",
    "}\n",
    "\n",
    "images_shape = (200,200)\n",
    "\n",
    "# For each image we have the path from which we extract the name and the label of the image\n",
    "for dsKey in raw_dataset.keys():\n",
    "    splittedKey = dsKey.split('/')\n",
    "\n",
    "    img_type = splittedKey[2]\n",
    "    img_label = splittedKey[3]\n",
    "    img_name = splittedKey[4]\n",
    "    \n",
    "    img = Image.open(io.BytesIO(raw_dataset[dsKey]))\n",
    "    img = ImageOps.fit(img,images_shape, Image.Resampling.LANCZOS)\n",
    "    \n",
    "    img_array = np.asarray(img).reshape(images_shape[0]*images_shape[1], 3)\n",
    "    \n",
    "    dataset[img_type]['data'].append(img_array)\n",
    "    dataset[img_type]['names'].append(img_name)\n",
    "    dataset[img_type]['labels'].append(img_label)\n",
    "\n",
    "for img_type in dataset.keys():\n",
    "    dataset[img_type]['data'] = np.asarray(dataset[img_type]['data'])\n",
    "    dataset[img_type]['names'] = np.asarray(dataset[img_type]['names'])\n",
    "\n",
    "    dataset[img_type]['unique_labels'], dataset[img_type]['labels'] = np.unique(np.asarray(dataset[img_type]['labels']), return_inverse=True)\n",
    "\n",
    "    logger.info([f'data shape({img_type})', dataset[img_type]['data'].shape])\n",
    "    logger.info([f'data labels({img_type})', dataset[img_type]['labels'].shape])\n",
    "    logger.info([f'data unique labels({img_type})', dataset[img_type]['unique_labels']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>n_components</th>\n",
       "      <th>channel</th>\n",
       "      <th>explained_variance_ratio_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.382316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCA</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.341308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCA</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.373610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCA</td>\n",
       "      <td>3</td>\n",
       "      <td>Grayscale</td>\n",
       "      <td>0.346850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  n_components    channel  explained_variance_ratio_sum\n",
       "0    PCA             3          0                      0.382316\n",
       "1    PCA             3          1                      0.341308\n",
       "2    PCA             3          2                      0.373610\n",
       "3    PCA             3  Grayscale                      0.346850"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>n_components</th>\n",
       "      <th>channel</th>\n",
       "      <th>explained_variance_ratio_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LDA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.199572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LDA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.369997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LDA</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.449102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LDA</td>\n",
       "      <td>1</td>\n",
       "      <td>Grayscale</td>\n",
       "      <td>0.341293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  n_components    channel  explained_variance_ratio_sum\n",
       "0    LDA             1          0                      0.199572\n",
       "1    LDA             1          1                      0.369997\n",
       "2    LDA             1          2                      0.449102\n",
       "3    LDA             1  Grayscale                      0.341293"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Riduzione della dimensionalit√†\n",
    "n_components_to_test = {\"PCA\": [3], #[3, 10, 50, 100, 200, 500, 1200], \n",
    "                        \"LDA\": [1], }# [3, 5, 7, 9]}\n",
    "\n",
    "results_PCA = []\n",
    "results_LDA = []\n",
    "\n",
    "# Grayscaled data\n",
    "grayscale_train_images = np.mean(dataset[\"train\"][\"data\"], axis=2)\n",
    "grayscale_valid_images = np.mean(dataset[\"valid\"][\"data\"], axis=2)\n",
    "\n",
    "for n_components in n_components_to_test[\"PCA\"]:\n",
    "    PCA_original = [\n",
    "        make_pipeline(StandardScaler(), PCA(n_components=n_components)),\n",
    "        make_pipeline(StandardScaler(), PCA(n_components=n_components)),\n",
    "        make_pipeline(StandardScaler(), PCA(n_components=n_components)),\n",
    "    ]\n",
    "\n",
    "    PCA_grayscale = make_pipeline(StandardScaler(), PCA(n_components=n_components))\n",
    "\n",
    "    # Multichannel section\n",
    "    for i in range(3):\n",
    "        PCA_original[i].fit(dataset[\"train\"][\"data\"][:, :, i])\n",
    "        train_transformed = PCA_original[i].transform(\n",
    "            dataset[\"train\"][\"data\"][:, :,  i]\n",
    "        )\n",
    "        valid_transformed = PCA_original[i].transform(\n",
    "            dataset[\"valid\"][\"data\"][:, :,  i]\n",
    "        )\n",
    "        explained_variance_ratio_sum = np.sum(\n",
    "            PCA_original[i][1].explained_variance_ratio_, axis=0\n",
    "        )\n",
    "\n",
    "        results_PCA.append(\n",
    "            {\n",
    "                \"method\": \"PCA\",\n",
    "                \"n_components\": n_components,\n",
    "                \"channel\": i,\n",
    "                \"explained_variance_ratio_sum\": explained_variance_ratio_sum,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Grayscale section\n",
    "    PCA_grayscale.fit(grayscale_train_images)\n",
    "    train_transformed = PCA_grayscale.transform(grayscale_train_images)\n",
    "    valid_transformed = PCA_grayscale.transform(grayscale_valid_images)\n",
    "    explained_variance_ratio_sum = np.sum(\n",
    "        PCA_grayscale[1].explained_variance_ratio_, axis=0\n",
    "    )\n",
    "\n",
    "    results_PCA.append(\n",
    "        {\n",
    "            \"method\": \"PCA\",\n",
    "            \"n_components\": n_components,\n",
    "            \"channel\": \"Grayscale\",\n",
    "            \"explained_variance_ratio_sum\": explained_variance_ratio_sum,\n",
    "        }\n",
    "    )\n",
    "\n",
    "for n_components in n_components_to_test[\"LDA\"]:\n",
    "    LDA_original = [\n",
    "        make_pipeline(\n",
    "            StandardScaler(), LinearDiscriminantAnalysis(n_components=n_components)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            StandardScaler(), LinearDiscriminantAnalysis(n_components=n_components)\n",
    "        ),\n",
    "        make_pipeline(\n",
    "            StandardScaler(), LinearDiscriminantAnalysis(n_components=n_components)\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    LDA_grayscale = make_pipeline(\n",
    "        StandardScaler(), LinearDiscriminantAnalysis(n_components=n_components)\n",
    "    )\n",
    "\n",
    "    # Multichannel section\n",
    "    for i in range(3):\n",
    "        LDA_original[i].fit(\n",
    "            dataset[\"train\"][\"data\"][:, :, i], dataset[\"train\"][\"labels\"]\n",
    "        )\n",
    "        train_transformed = LDA_original[i].transform(\n",
    "            dataset[\"train\"][\"data\"][:, :, i]\n",
    "        )\n",
    "        valid_transformed = LDA_original[i].transform(\n",
    "            dataset[\"valid\"][\"data\"][:, :, i]\n",
    "        )\n",
    "        explained_variance_ratio_sum = np.sum(\n",
    "            LDA_original[i][1].explained_variance_ratio_, axis=0\n",
    "        )\n",
    "\n",
    "        results_LDA.append(\n",
    "            {\n",
    "                \"method\": \"LDA\",\n",
    "                \"n_components\": n_components,\n",
    "                \"channel\": i,\n",
    "                \"explained_variance_ratio_sum\": explained_variance_ratio_sum,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Grayscale section\n",
    "    LDA_grayscale.fit(grayscale_train_images, dataset[\"train\"][\"labels\"])\n",
    "    train_transformed = LDA_grayscale.transform(grayscale_train_images)\n",
    "    valid_transformed = LDA_grayscale.transform(grayscale_valid_images)\n",
    "    explained_variance_ratio_sum = np.sum(\n",
    "        LDA_grayscale[1].explained_variance_ratio_, axis=0\n",
    "    )\n",
    "\n",
    "    results_LDA.append(\n",
    "        {\n",
    "            \"method\": \"LDA\",\n",
    "            \"n_components\": n_components,\n",
    "            \"channel\": \"Grayscale\",\n",
    "            \"explained_variance_ratio_sum\": explained_variance_ratio_sum,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Conversione dei risultati in un DataFrame\n",
    "df_results_PCA = pd.DataFrame(results_PCA)\n",
    "df_results_LDA = pd.DataFrame(results_LDA)\n",
    "\n",
    "\n",
    "display(df_results_PCA)\n",
    "display(df_results_LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\luca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\luca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\luca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\luca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\luca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\luca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\luca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\luca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k\\PCA (grayscale)</th>\n",
       "      <th>3</th>\n",
       "      <th>10</th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>200</th>\n",
       "      <th>500</th>\n",
       "      <th>1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>(0.15, 0.148)</td>\n",
       "      <td>(0.168, 0.165)</td>\n",
       "      <td>(0.148, 0.189)</td>\n",
       "      <td>(0.156, 0.213)</td>\n",
       "      <td>(0.146, 0.205)</td>\n",
       "      <td>(0.134, 0.164)</td>\n",
       "      <td>(0.138, 0.142)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>(0.156, 0.157)</td>\n",
       "      <td>(0.166, 0.183)</td>\n",
       "      <td>(0.154, 0.186)</td>\n",
       "      <td>(0.156, 0.19)</td>\n",
       "      <td>(0.154, 0.217)</td>\n",
       "      <td>(0.146, 0.217)</td>\n",
       "      <td>(0.144, 0.19)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>(0.172, 0.168)</td>\n",
       "      <td>(0.158, 0.165)</td>\n",
       "      <td>(0.156, 0.206)</td>\n",
       "      <td>(0.146, 0.2)</td>\n",
       "      <td>(0.132, 0.2)</td>\n",
       "      <td>(0.132, 0.193)</td>\n",
       "      <td>(0.128, 0.202)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>(0.17, 0.164)</td>\n",
       "      <td>(0.166, 0.174)</td>\n",
       "      <td>(0.152, 0.191)</td>\n",
       "      <td>(0.154, 0.228)</td>\n",
       "      <td>(0.134, 0.187)</td>\n",
       "      <td>(0.128, 0.205)</td>\n",
       "      <td>(0.13, 0.243)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>(0.182, 0.18)</td>\n",
       "      <td>(0.174, 0.183)</td>\n",
       "      <td>(0.156, 0.198)</td>\n",
       "      <td>(0.134, 0.205)</td>\n",
       "      <td>(0.134, 0.213)</td>\n",
       "      <td>(0.138, 0.179)</td>\n",
       "      <td>(0.138, 0.189)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55</td>\n",
       "      <td>(0.202, 0.187)</td>\n",
       "      <td>(0.186, 0.19)</td>\n",
       "      <td>(0.16, 0.186)</td>\n",
       "      <td>(0.156, 0.196)</td>\n",
       "      <td>(0.162, 0.214)</td>\n",
       "      <td>(0.134, 0.149)</td>\n",
       "      <td>(0.134, 0.142)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111</td>\n",
       "      <td>(0.184, 0.161)</td>\n",
       "      <td>(0.21, 0.19)</td>\n",
       "      <td>(0.178, 0.208)</td>\n",
       "      <td>(0.164, 0.179)</td>\n",
       "      <td>(0.162, 0.192)</td>\n",
       "      <td>(0.16, 0.22)</td>\n",
       "      <td>(0.154, 0.161)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>251</td>\n",
       "      <td>(0.208, 0.204)</td>\n",
       "      <td>(0.234, 0.273)</td>\n",
       "      <td>(0.182, 0.206)</td>\n",
       "      <td>(0.16, 0.189)</td>\n",
       "      <td>(0.16, 0.173)</td>\n",
       "      <td>(0.158, 0.149)</td>\n",
       "      <td>(0.162, 0.156)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k\\PCA (grayscale)               3              10              50  \\\n",
       "0                  3   (0.15, 0.148)  (0.168, 0.165)  (0.148, 0.189)   \n",
       "1                  5  (0.156, 0.157)  (0.166, 0.183)  (0.154, 0.186)   \n",
       "2                  9  (0.172, 0.168)  (0.158, 0.165)  (0.156, 0.206)   \n",
       "3                 15   (0.17, 0.164)  (0.166, 0.174)  (0.152, 0.191)   \n",
       "4                 21   (0.182, 0.18)  (0.174, 0.183)  (0.156, 0.198)   \n",
       "5                 55  (0.202, 0.187)   (0.186, 0.19)   (0.16, 0.186)   \n",
       "6                111  (0.184, 0.161)    (0.21, 0.19)  (0.178, 0.208)   \n",
       "7                251  (0.208, 0.204)  (0.234, 0.273)  (0.182, 0.206)   \n",
       "\n",
       "              100             200             500            1200  \n",
       "0  (0.156, 0.213)  (0.146, 0.205)  (0.134, 0.164)  (0.138, 0.142)  \n",
       "1   (0.156, 0.19)  (0.154, 0.217)  (0.146, 0.217)   (0.144, 0.19)  \n",
       "2    (0.146, 0.2)    (0.132, 0.2)  (0.132, 0.193)  (0.128, 0.202)  \n",
       "3  (0.154, 0.228)  (0.134, 0.187)  (0.128, 0.205)   (0.13, 0.243)  \n",
       "4  (0.134, 0.205)  (0.134, 0.213)  (0.138, 0.179)  (0.138, 0.189)  \n",
       "5  (0.156, 0.196)  (0.162, 0.214)  (0.134, 0.149)  (0.134, 0.142)  \n",
       "6  (0.164, 0.179)  (0.162, 0.192)    (0.16, 0.22)  (0.154, 0.161)  \n",
       "7   (0.16, 0.189)   (0.16, 0.173)  (0.158, 0.149)  (0.162, 0.156)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k\\LDA (grayscale)</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>(0.144, 0.125)</td>\n",
       "      <td>(0.128, 0.122)</td>\n",
       "      <td>(0.158, 0.156)</td>\n",
       "      <td>(0.152, 0.146)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>(0.154, 0.139)</td>\n",
       "      <td>(0.144, 0.14)</td>\n",
       "      <td>(0.162, 0.155)</td>\n",
       "      <td>(0.162, 0.154)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>(0.138, 0.123)</td>\n",
       "      <td>(0.148, 0.144)</td>\n",
       "      <td>(0.164, 0.153)</td>\n",
       "      <td>(0.146, 0.136)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>(0.144, 0.131)</td>\n",
       "      <td>(0.158, 0.154)</td>\n",
       "      <td>(0.168, 0.158)</td>\n",
       "      <td>(0.154, 0.144)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>(0.136, 0.122)</td>\n",
       "      <td>(0.144, 0.144)</td>\n",
       "      <td>(0.162, 0.153)</td>\n",
       "      <td>(0.154, 0.147)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55</td>\n",
       "      <td>(0.12, 0.107)</td>\n",
       "      <td>(0.148, 0.147)</td>\n",
       "      <td>(0.158, 0.146)</td>\n",
       "      <td>(0.154, 0.146)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111</td>\n",
       "      <td>(0.128, 0.122)</td>\n",
       "      <td>(0.142, 0.141)</td>\n",
       "      <td>(0.168, 0.155)</td>\n",
       "      <td>(0.152, 0.144)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>251</td>\n",
       "      <td>(0.118, 0.113)</td>\n",
       "      <td>(0.148, 0.148)</td>\n",
       "      <td>(0.16, 0.147)</td>\n",
       "      <td>(0.148, 0.141)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k\\LDA (grayscale)               3               5               7  \\\n",
       "0                  3  (0.144, 0.125)  (0.128, 0.122)  (0.158, 0.156)   \n",
       "1                  5  (0.154, 0.139)   (0.144, 0.14)  (0.162, 0.155)   \n",
       "2                  9  (0.138, 0.123)  (0.148, 0.144)  (0.164, 0.153)   \n",
       "3                 15  (0.144, 0.131)  (0.158, 0.154)  (0.168, 0.158)   \n",
       "4                 21  (0.136, 0.122)  (0.144, 0.144)  (0.162, 0.153)   \n",
       "5                 55   (0.12, 0.107)  (0.148, 0.147)  (0.158, 0.146)   \n",
       "6                111  (0.128, 0.122)  (0.142, 0.141)  (0.168, 0.155)   \n",
       "7                251  (0.118, 0.113)  (0.148, 0.148)   (0.16, 0.147)   \n",
       "\n",
       "                9  \n",
       "0  (0.152, 0.146)  \n",
       "1  (0.162, 0.154)  \n",
       "2  (0.146, 0.136)  \n",
       "3  (0.154, 0.144)  \n",
       "4  (0.154, 0.147)  \n",
       "5  (0.154, 0.146)  \n",
       "6  (0.152, 0.144)  \n",
       "7  (0.148, 0.141)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classification - KNN\n",
    "\n",
    "k_to_test = {\n",
    "    'PCA': [3, 5, 9, 15, 21, 55, 111, 251],\n",
    "    'LDA': [3, 5, 9, 15, 21, 55, 111, 251]\n",
    "}\n",
    "\n",
    "KNN_PCA_grayscale_stats = []\n",
    "KNN_LDA_grayscale_stats = []\n",
    "\n",
    "KNN_PCA_original_stats = []\n",
    "KNN_LDA_original_stats = []\n",
    "\n",
    "for k_idx, k in enumerate(k_to_test['PCA']):\n",
    "\n",
    "    KNN_PCA_grayscale_stats.insert(k_idx,[k])\n",
    "\n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['PCA']):\n",
    "        knn = KNeighborsClassifier(k)\n",
    "\n",
    "        knn.fit(PCAs_results['train']['grayscale'][n_components], dataset['train']['labels'])\n",
    "        preds = knn.predict(PCAs_results['valid']['grayscale'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "        \n",
    "        # logger.info([f\"KNN on PCA (grayscale images, k = {k}, {n_components} components)\", \"accuracy\", accuracy, \"precision\", precision])\n",
    "\n",
    "        KNN_PCA_grayscale_stats[k_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "KNN_PCA_df = pd.DataFrame(KNN_PCA_grayscale_stats, columns=['k\\\\PCA (grayscale)'] + n_components_to_test['PCA'])\n",
    "display(KNN_PCA_df)\n",
    "\n",
    "for k_idx,k in enumerate(k_to_test['LDA']):\n",
    "    \n",
    "    KNN_LDA_grayscale_stats.insert(k_idx,[k])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['LDA']):\n",
    "        knn = OneVsRestClassifier( KNeighborsClassifier(k))\n",
    "        \n",
    "        knn.fit(LDAs_results['train']['grayscale'][n_components], dataset['train']['labels'])\n",
    "        preds = knn.predict(LDAs_results['valid']['grayscale'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        # logger.info([f\"KNN on LDA (grayscale images, k = {k}, {n_components} components)\", \"accuracy\", accuracy, \"precision\", precision])\n",
    "\n",
    "        KNN_LDA_grayscale_stats[k_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "\n",
    "KNN_LDA_df = pd.DataFrame(KNN_LDA_grayscale_stats, columns=['k\\\\LDA (grayscale)'] + n_components_to_test['LDA'])\n",
    "display(KNN_LDA_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification - KRR\n",
    "\n",
    "kernels_to_test = {\n",
    "    'PCA': ['linear', 'poly', 'rbf'],\n",
    "    'LDA': ['linear', 'poly', 'rbf']\n",
    "}\n",
    "\n",
    "KRR_PCA_grayscale_stats = []\n",
    "KRR_LDA_grayscale_stats = []\n",
    "\n",
    "for kernel_idx,kernel in enumerate(kernels_to_test['PCA']):\n",
    "\n",
    "    KRR_PCA_grayscale_stats.insert(kernel_idx,[kernel])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['PCA']):#n_components_to_test['PCA']):\n",
    "        svm = OneVsOneClassifier(KernelRidge(kernel=kernel))\n",
    "\n",
    "        svm.fit(PCAs_results['train']['grayscale'][n_components], dataset['train']['labels'])\n",
    "\n",
    "        preds = svm.predict(PCAs_results['valid']['grayscale'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        KRR_PCA_grayscale_stats[kernel_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "KRR_PCA_df = pd.DataFrame(KRR_PCA_grayscale_stats, columns=['kernel\\\\PCA (grayscale)'] + n_components_to_test['PCA'])\n",
    "display(KRR_PCA_df)\n",
    "\n",
    "for kernel_idx,kernel in enumerate(kernels_to_test['LDA']):\n",
    "\n",
    "    KRR_LDA_grayscale_stats.insert(kernel_idx,[kernel])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['LDA']):\n",
    "        svm = OneVsOneClassifier(KernelRidge(kernel=kernel))\n",
    "\n",
    "        svm.fit(LDAs_results['train']['grayscale'][n_components], dataset['train']['labels'])\n",
    "\n",
    "        preds = svm.predict(LDAs_results['valid']['grayscale'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        KRR_LDA_grayscale_stats[kernel_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "KRR_LDA_df = pd.DataFrame(KRR_LDA_grayscale_stats, columns=['kernel\\\\LDA (grayscale)'] + n_components_to_test['LDA'])\n",
    "display(KRR_LDA_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel\\PCA (grayscale)</th>\n",
       "      <th>3</th>\n",
       "      <th>10</th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>200</th>\n",
       "      <th>500</th>\n",
       "      <th>1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>(0.196, 0.167)</td>\n",
       "      <td>(0.23, 0.208)</td>\n",
       "      <td>(0.188, 0.179)</td>\n",
       "      <td>(0.194, 0.187)</td>\n",
       "      <td>(0.188, 0.188)</td>\n",
       "      <td>(0.18, 0.183)</td>\n",
       "      <td>(0.192, 0.193)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poly</td>\n",
       "      <td>(0.164, 0.197)</td>\n",
       "      <td>(0.21, 0.236)</td>\n",
       "      <td>(0.206, 0.23)</td>\n",
       "      <td>(0.208, 0.235)</td>\n",
       "      <td>(0.206, 0.243)</td>\n",
       "      <td>(0.198, 0.242)</td>\n",
       "      <td>(0.208, 0.258)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>(0.14, 0.11)</td>\n",
       "      <td>(0.16, 0.143)</td>\n",
       "      <td>(0.204, 0.183)</td>\n",
       "      <td>(0.222, 0.198)</td>\n",
       "      <td>(0.228, 0.203)</td>\n",
       "      <td>(0.232, 0.212)</td>\n",
       "      <td>(0.234, 0.214)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernel\\PCA (grayscale)               3             10              50  \\\n",
       "0                 linear  (0.196, 0.167)  (0.23, 0.208)  (0.188, 0.179)   \n",
       "1                   poly  (0.164, 0.197)  (0.21, 0.236)   (0.206, 0.23)   \n",
       "2                sigmoid    (0.14, 0.11)  (0.16, 0.143)  (0.204, 0.183)   \n",
       "\n",
       "              100             200             500            1200  \n",
       "0  (0.194, 0.187)  (0.188, 0.188)   (0.18, 0.183)  (0.192, 0.193)  \n",
       "1  (0.208, 0.235)  (0.206, 0.243)  (0.198, 0.242)  (0.208, 0.258)  \n",
       "2  (0.222, 0.198)  (0.228, 0.203)  (0.232, 0.212)  (0.234, 0.214)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel\\LDA (grayscale)</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>(0.124, 0.099)</td>\n",
       "      <td>(0.124, 0.138)</td>\n",
       "      <td>(0.134, 0.139)</td>\n",
       "      <td>(0.136, 0.147)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poly</td>\n",
       "      <td>(0.126, 0.131)</td>\n",
       "      <td>(0.124, 0.119)</td>\n",
       "      <td>(0.156, 0.156)</td>\n",
       "      <td>(0.134, 0.136)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>(0.134, 0.132)</td>\n",
       "      <td>(0.136, 0.137)</td>\n",
       "      <td>(0.148, 0.142)</td>\n",
       "      <td>(0.15, 0.135)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernel\\LDA (grayscale)               3               5               7  \\\n",
       "0                 linear  (0.124, 0.099)  (0.124, 0.138)  (0.134, 0.139)   \n",
       "1                   poly  (0.126, 0.131)  (0.124, 0.119)  (0.156, 0.156)   \n",
       "2                sigmoid  (0.134, 0.132)  (0.136, 0.137)  (0.148, 0.142)   \n",
       "\n",
       "                9  \n",
       "0  (0.136, 0.147)  \n",
       "1  (0.134, 0.136)  \n",
       "2   (0.15, 0.135)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classification - SVM\n",
    "\n",
    "kernels_to_test = {\n",
    "    'PCA': ['linear', 'poly', 'sigmoid'],\n",
    "    'LDA': ['linear', 'poly', 'sigmoid'],\n",
    "}\n",
    "\n",
    "SVM_PCA_grayscale_stats = []\n",
    "SVM_LDA_grayscale_stats = []\n",
    "\n",
    "for kernel_idx,kernel in enumerate(kernels_to_test['PCA']):\n",
    "\n",
    "    SVM_PCA_grayscale_stats.insert(kernel_idx,[kernel])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['PCA']):#n_components_to_test['PCA']):\n",
    "        svm = OneVsOneClassifier(SVC(kernel=kernel))\n",
    "\n",
    "        svm.fit(PCAs_results['train']['grayscale'][n_components], dataset['train']['labels'])\n",
    "\n",
    "        preds = svm.predict(PCAs_results['valid']['grayscale'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        SVM_PCA_grayscale_stats[kernel_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "SVM_PCA_df = pd.DataFrame(SVM_PCA_grayscale_stats, columns=['kernel\\\\PCA (grayscale)'] + n_components_to_test['PCA'])\n",
    "display(SVM_PCA_df)\n",
    "\n",
    "for kernel_idx,kernel in enumerate(kernels_to_test['LDA']):\n",
    "\n",
    "    SVM_LDA_grayscale_stats.insert(kernel_idx,[kernel])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['LDA']):\n",
    "        svm = OneVsOneClassifier(SVC(kernel=kernel))\n",
    "\n",
    "        svm.fit(LDAs_results['train']['grayscale'][n_components], dataset['train']['labels'])\n",
    "\n",
    "        preds = svm.predict(LDAs_results['valid']['grayscale'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        SVM_LDA_grayscale_stats[kernel_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "SVM_LDA_df = pd.DataFrame(SVM_LDA_grayscale_stats, columns=['kernel\\\\LDA (grayscale)'] + n_components_to_test['LDA'])\n",
    "display(SVM_LDA_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification - QDA\n",
    "\n",
    "kernels_to_test = {\n",
    "    'PCA': [''],#['linear', 'poly', 'sigmoid'],\n",
    "    'LDA': ['']#['linear', 'poly', 'sigmoid'],\n",
    "}\n",
    "\n",
    "QDA_PCA_grayscale_stats = []\n",
    "QDA_LDA_grayscale_stats = []\n",
    "\n",
    "for kernel_idx,kernel in enumerate(kernels_to_test['PCA']):\n",
    "\n",
    "    QDA_PCA_grayscale_stats.insert(kernel_idx,[kernel])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['PCA']):#n_components_to_test['PCA']):\n",
    "        qda = OneVsOneClassifier(QuadraticDiscriminantAnalysis())\n",
    "\n",
    "        qda.fit(PCAs_results['train']['grayscale'][n_components], dataset['train']['labels'])\n",
    "\n",
    "        preds = qda.predict(PCAs_results['valid']['grayscale'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        QDA_PCA_grayscale_stats[kernel_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "QDA_PCA_df = pd.DataFrame(QDA_PCA_grayscale_stats, columns=['kernel\\\\PCA (grayscale)'] + n_components_to_test['PCA'])\n",
    "display(QDA_PCA_df)\n",
    "\n",
    "for kernel_idx,kernel in enumerate(kernels_to_test['LDA']):\n",
    "\n",
    "    QDA_LDA_grayscale_stats.insert(kernel_idx,[kernel])\n",
    "\n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['LDA']):#n_components_to_test['PCA']):\n",
    "\n",
    "        qda = OneVsOneClassifier(QuadraticDiscriminantAnalysis())\n",
    "\n",
    "        qda.fit(LDAs_results['train']['grayscale'][n_components], dataset['train']['labels'])\n",
    "\n",
    "        preds = qda.predict(LDAs_results['valid']['grayscale'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        QDA_LDA_grayscale_stats[kernel_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "QDA_original_grayscale_df = pd.DataFrame(QDA_LDA_grayscale_stats, columns=['kernel\\\\LDA (grayscale)']+ n_components_to_test['LDA'])\n",
    "display(QDA_original_grayscale_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>components\\PCA components</th>\n",
       "      <th>3</th>\n",
       "      <th>10</th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>200</th>\n",
       "      <th>500</th>\n",
       "      <th>1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   components\\PCA components      3     10     50    100    200    500   1200\n",
       "0                         15  0.017  0.011  0.014  0.001  0.000  0.003  0.000\n",
       "1                         30  0.013  0.011  0.005  0.000 -0.001  0.003  0.004\n",
       "2                        100  0.009  0.013  0.000  0.005  0.006  0.008  0.002\n",
       "3                        500  0.002  0.006  0.008  0.005  0.002  0.010  0.018"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GMM\n",
    "\n",
    "GMM_n_components_to_test = {\n",
    "    'PCA': [15, 30, 100, 500]\n",
    "}\n",
    "\n",
    "GMM_PCA_score = []\n",
    "\n",
    "for GMM_n_components_idx,GMM_n_components in enumerate(GMM_n_components_to_test['PCA']):\n",
    "\n",
    "    GMM_PCA_score.insert(GMM_n_components_idx,[GMM_n_components])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['PCA']):\n",
    "        gmm = GaussianMixture(n_components=GMM_n_components)\n",
    "\n",
    "        gmm.fit(PCAs_results['train']['grayscale'][n_components])\n",
    "\n",
    "        preds = gmm.predict(PCAs_results['valid']['grayscale'][n_components])\n",
    "\n",
    "        rand_score = round(adjusted_rand_score(dataset['valid']['labels'], preds),3)\n",
    "\n",
    "        GMM_PCA_score[GMM_n_components_idx].insert(n_components_idx + 1,(rand_score))\n",
    "\n",
    "GMM_PCA_stats = pd.DataFrame(GMM_PCA_score, columns=['components\\\\PCA components'] + n_components_to_test['PCA'])\n",
    "\n",
    "display(GMM_PCA_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
