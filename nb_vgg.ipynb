{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch] using cpu\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import pickle\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision.models import VGG16_Weights\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Initialing compute device (use GPU if available).\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'[torch] using {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "raw_dataset = np.load(\"dataset_food101tiny.zip\", allow_pickle=True)\n",
    "\n",
    "dataset = {\n",
    "    \"train\": {\n",
    "        \"data\": [],\n",
    "        \"names\": [],\n",
    "        \"labels\": [],\n",
    "        \"unique_labels\": [],\n",
    "    },\n",
    "    \"valid\": {\n",
    "        \"data\": [],\n",
    "        \"names\": [],\n",
    "        \"labels\": [],\n",
    "        \"unique_labels\": [],\n",
    "    },\n",
    "}\n",
    "\n",
    "images_shape = (224, 224)\n",
    "\n",
    "# For each image we have the path from which we extract the name and the label of the image\n",
    "for dsKey in raw_dataset.keys():\n",
    "    splittedKey = dsKey.split(\"/\")\n",
    "\n",
    "    img_type = splittedKey[2]\n",
    "    img_label = splittedKey[3]\n",
    "    img_name = splittedKey[4]\n",
    "\n",
    "    img = Image.open(io.BytesIO(raw_dataset[dsKey]))\n",
    "    img = ImageOps.fit(img, images_shape, Image.Resampling.LANCZOS).convert(\"RGB\")\n",
    "\n",
    "    img_array = np.asarray(img)\n",
    "\n",
    "    dataset[img_type][\"data\"].append(img_array)\n",
    "    dataset[img_type][\"names\"].append(img_name)\n",
    "    dataset[img_type][\"labels\"].append(img_label)\n",
    "\n",
    "for img_type in dataset.keys():\n",
    "    dataset[img_type][\"data\"] = np.asarray(dataset[img_type][\"data\"])\n",
    "    dataset[img_type][\"names\"] = np.asarray(dataset[img_type][\"names\"])\n",
    "\n",
    "    dataset[img_type][\"unique_labels\"], dataset[img_type][\"labels\"] = np.unique(\n",
    "        np.asarray(dataset[img_type][\"labels\"]), return_inverse=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction using VGG\n",
    "\n",
    "Normalization mean and standard deviation are [here](https://pytorch.org/hub/pytorch_vision_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting feature: 0/1500\n",
      "Extracting feature: 1/1500\n",
      "Extracting feature: 2/1500\n",
      "Extracting feature: 3/1500\n",
      "Extracting feature: 4/1500\n",
      "Extracting feature: 5/1500\n",
      "Extracting feature: 6/1500\n",
      "Extracting feature: 7/1500\n",
      "Extracting feature: 8/1500\n",
      "Extracting feature: 9/1500\n",
      "Extracting feature: 10/1500\n",
      "Extracting feature: 11/1500\n",
      "Extracting feature: 12/1500\n",
      "Extracting feature: 13/1500\n",
      "Extracting feature: 14/1500\n",
      "Extracting feature: 15/1500\n",
      "Extracting feature: 16/1500\n",
      "Extracting feature: 17/1500\n",
      "Extracting feature: 18/1500\n",
      "Extracting feature: 19/1500\n",
      "Extracting feature: 20/1500\n",
      "Extracting feature: 21/1500\n",
      "Extracting feature: 22/1500\n",
      "Extracting feature: 23/1500\n",
      "Extracting feature: 24/1500\n",
      "Extracting feature: 25/1500\n",
      "Extracting feature: 26/1500\n",
      "Extracting feature: 27/1500\n",
      "Extracting feature: 28/1500\n",
      "Extracting feature: 29/1500\n",
      "Extracting feature: 30/1500\n",
      "Extracting feature: 31/1500\n",
      "Extracting feature: 32/1500\n",
      "Extracting feature: 33/1500\n",
      "Extracting feature: 34/1500\n",
      "Extracting feature: 35/1500\n",
      "Extracting feature: 36/1500\n",
      "Extracting feature: 37/1500\n",
      "Extracting feature: 38/1500\n",
      "Extracting feature: 39/1500\n",
      "Extracting feature: 40/1500\n",
      "Extracting feature: 41/1500\n",
      "Extracting feature: 42/1500\n",
      "Extracting feature: 43/1500\n",
      "Extracting feature: 44/1500\n",
      "Extracting feature: 45/1500\n",
      "Extracting feature: 46/1500\n",
      "Extracting feature: 47/1500\n",
      "Extracting feature: 48/1500\n",
      "Extracting feature: 49/1500\n",
      "Extracting feature: 50/1500\n",
      "Extracting feature: 51/1500\n",
      "Extracting feature: 52/1500\n",
      "Extracting feature: 53/1500\n",
      "Extracting feature: 54/1500\n",
      "Extracting feature: 55/1500\n",
      "Extracting feature: 56/1500\n",
      "Extracting feature: 57/1500\n",
      "Extracting feature: 58/1500\n",
      "Extracting feature: 59/1500\n",
      "Extracting feature: 60/1500\n",
      "Extracting feature: 61/1500\n",
      "Extracting feature: 62/1500\n",
      "Extracting feature: 63/1500\n",
      "Extracting feature: 64/1500\n",
      "Extracting feature: 65/1500\n",
      "Extracting feature: 66/1500\n",
      "Extracting feature: 67/1500\n",
      "Extracting feature: 68/1500\n",
      "Extracting feature: 69/1500\n",
      "Extracting feature: 70/1500\n",
      "Extracting feature: 71/1500\n",
      "Extracting feature: 72/1500\n",
      "Extracting feature: 73/1500\n",
      "Extracting feature: 74/1500\n",
      "Extracting feature: 75/1500\n",
      "Extracting feature: 76/1500\n",
      "Extracting feature: 77/1500\n",
      "Extracting feature: 78/1500\n",
      "Extracting feature: 79/1500\n",
      "Extracting feature: 80/1500\n",
      "Extracting feature: 81/1500\n",
      "Extracting feature: 82/1500\n",
      "Extracting feature: 83/1500\n",
      "Extracting feature: 84/1500\n",
      "Extracting feature: 85/1500\n",
      "Extracting feature: 86/1500\n",
      "Extracting feature: 87/1500\n",
      "Extracting feature: 88/1500\n",
      "Extracting feature: 89/1500\n",
      "Extracting feature: 90/1500\n",
      "Extracting feature: 91/1500\n",
      "Extracting feature: 92/1500\n",
      "Extracting feature: 93/1500\n",
      "Extracting feature: 94/1500\n",
      "Extracting feature: 95/1500\n",
      "Extracting feature: 96/1500\n",
      "Extracting feature: 97/1500\n",
      "Extracting feature: 98/1500\n",
      "Extracting feature: 99/1500\n",
      "Extracting feature: 100/1500\n",
      "Extracting feature: 101/1500\n",
      "Extracting feature: 102/1500\n",
      "Extracting feature: 103/1500\n",
      "Extracting feature: 104/1500\n",
      "Extracting feature: 105/1500\n",
      "Extracting feature: 106/1500\n",
      "Extracting feature: 107/1500\n",
      "Extracting feature: 108/1500\n",
      "Extracting feature: 109/1500\n",
      "Extracting feature: 110/1500\n",
      "Extracting feature: 111/1500\n",
      "Extracting feature: 112/1500\n",
      "Extracting feature: 113/1500\n",
      "Extracting feature: 114/1500\n",
      "Extracting feature: 115/1500\n",
      "Extracting feature: 116/1500\n",
      "Extracting feature: 117/1500\n",
      "Extracting feature: 118/1500\n",
      "Extracting feature: 119/1500\n",
      "Extracting feature: 120/1500\n",
      "Extracting feature: 121/1500\n",
      "Extracting feature: 122/1500\n",
      "Extracting feature: 123/1500\n",
      "Extracting feature: 124/1500\n",
      "Extracting feature: 125/1500\n",
      "Extracting feature: 126/1500\n",
      "Extracting feature: 127/1500\n",
      "Extracting feature: 128/1500\n",
      "Extracting feature: 129/1500\n",
      "Extracting feature: 130/1500\n",
      "Extracting feature: 131/1500\n",
      "Extracting feature: 132/1500\n",
      "Extracting feature: 133/1500\n",
      "Extracting feature: 134/1500\n",
      "Extracting feature: 135/1500\n",
      "Extracting feature: 136/1500\n",
      "Extracting feature: 137/1500\n",
      "Extracting feature: 138/1500\n",
      "Extracting feature: 139/1500\n",
      "Extracting feature: 140/1500\n",
      "Extracting feature: 141/1500\n",
      "Extracting feature: 142/1500\n",
      "Extracting feature: 143/1500\n",
      "Extracting feature: 144/1500\n",
      "Extracting feature: 145/1500\n",
      "Extracting feature: 146/1500\n",
      "Extracting feature: 147/1500\n",
      "Extracting feature: 148/1500\n",
      "Extracting feature: 149/1500\n",
      "Extracting feature: 150/1500\n",
      "Extracting feature: 151/1500\n",
      "Extracting feature: 152/1500\n",
      "Extracting feature: 153/1500\n",
      "Extracting feature: 154/1500\n",
      "Extracting feature: 155/1500\n",
      "Extracting feature: 156/1500\n",
      "Extracting feature: 157/1500\n",
      "Extracting feature: 158/1500\n",
      "Extracting feature: 159/1500\n",
      "Extracting feature: 160/1500\n",
      "Extracting feature: 161/1500\n",
      "Extracting feature: 162/1500\n",
      "Extracting feature: 163/1500\n",
      "Extracting feature: 164/1500\n",
      "Extracting feature: 165/1500\n",
      "Extracting feature: 166/1500\n",
      "Extracting feature: 167/1500\n",
      "Extracting feature: 168/1500\n",
      "Extracting feature: 169/1500\n",
      "Extracting feature: 170/1500\n",
      "Extracting feature: 171/1500\n",
      "Extracting feature: 172/1500\n",
      "Extracting feature: 173/1500\n",
      "Extracting feature: 174/1500\n",
      "Extracting feature: 175/1500\n",
      "Extracting feature: 176/1500\n",
      "Extracting feature: 177/1500\n",
      "Extracting feature: 178/1500\n",
      "Extracting feature: 179/1500\n",
      "Extracting feature: 180/1500\n",
      "Extracting feature: 181/1500\n",
      "Extracting feature: 182/1500\n",
      "Extracting feature: 183/1500\n",
      "Extracting feature: 184/1500\n",
      "Extracting feature: 185/1500\n",
      "Extracting feature: 186/1500\n",
      "Extracting feature: 187/1500\n",
      "Extracting feature: 188/1500\n",
      "Extracting feature: 189/1500\n",
      "Extracting feature: 190/1500\n",
      "Extracting feature: 191/1500\n",
      "Extracting feature: 192/1500\n",
      "Extracting feature: 193/1500\n",
      "Extracting feature: 194/1500\n",
      "Extracting feature: 195/1500\n",
      "Extracting feature: 196/1500\n",
      "Extracting feature: 197/1500\n",
      "Extracting feature: 198/1500\n",
      "Extracting feature: 199/1500\n",
      "Extracting feature: 200/1500\n",
      "Extracting feature: 201/1500\n",
      "Extracting feature: 202/1500\n",
      "Extracting feature: 203/1500\n",
      "Extracting feature: 204/1500\n",
      "Extracting feature: 205/1500\n",
      "Extracting feature: 206/1500\n",
      "Extracting feature: 207/1500\n",
      "Extracting feature: 208/1500\n",
      "Extracting feature: 209/1500\n",
      "Extracting feature: 210/1500\n",
      "Extracting feature: 211/1500\n",
      "Extracting feature: 212/1500\n",
      "Extracting feature: 213/1500\n",
      "Extracting feature: 214/1500\n",
      "Extracting feature: 215/1500\n",
      "Extracting feature: 216/1500\n",
      "Extracting feature: 217/1500\n",
      "Extracting feature: 218/1500\n",
      "Extracting feature: 219/1500\n",
      "Extracting feature: 220/1500\n",
      "Extracting feature: 221/1500\n",
      "Extracting feature: 222/1500\n",
      "Extracting feature: 223/1500\n",
      "Extracting feature: 224/1500\n",
      "Extracting feature: 225/1500\n",
      "Extracting feature: 226/1500\n",
      "Extracting feature: 227/1500\n",
      "Extracting feature: 228/1500\n",
      "Extracting feature: 229/1500\n",
      "Extracting feature: 230/1500\n",
      "Extracting feature: 231/1500\n",
      "Extracting feature: 232/1500\n",
      "Extracting feature: 233/1500\n",
      "Extracting feature: 234/1500\n",
      "Extracting feature: 235/1500\n",
      "Extracting feature: 236/1500\n",
      "Extracting feature: 237/1500\n",
      "Extracting feature: 238/1500\n",
      "Extracting feature: 239/1500\n",
      "Extracting feature: 240/1500\n",
      "Extracting feature: 241/1500\n",
      "Extracting feature: 242/1500\n",
      "Extracting feature: 243/1500\n",
      "Extracting feature: 244/1500\n",
      "Extracting feature: 245/1500\n",
      "Extracting feature: 246/1500\n",
      "Extracting feature: 247/1500\n",
      "Extracting feature: 248/1500\n",
      "Extracting feature: 249/1500\n",
      "Extracting feature: 250/1500\n",
      "Extracting feature: 251/1500\n",
      "Extracting feature: 252/1500\n",
      "Extracting feature: 253/1500\n",
      "Extracting feature: 254/1500\n",
      "Extracting feature: 255/1500\n",
      "Extracting feature: 256/1500\n",
      "Extracting feature: 257/1500\n",
      "Extracting feature: 258/1500\n",
      "Extracting feature: 259/1500\n",
      "Extracting feature: 260/1500\n",
      "Extracting feature: 261/1500\n",
      "Extracting feature: 262/1500\n",
      "Extracting feature: 263/1500\n",
      "Extracting feature: 264/1500\n",
      "Extracting feature: 265/1500\n",
      "Extracting feature: 266/1500\n",
      "Extracting feature: 267/1500\n",
      "Extracting feature: 268/1500\n",
      "Extracting feature: 269/1500\n",
      "Extracting feature: 270/1500\n",
      "Extracting feature: 271/1500\n",
      "Extracting feature: 272/1500\n",
      "Extracting feature: 273/1500\n",
      "Extracting feature: 274/1500\n",
      "Extracting feature: 275/1500\n",
      "Extracting feature: 276/1500\n",
      "Extracting feature: 277/1500\n",
      "Extracting feature: 278/1500\n",
      "Extracting feature: 279/1500\n",
      "Extracting feature: 280/1500\n",
      "Extracting feature: 281/1500\n",
      "Extracting feature: 282/1500\n",
      "Extracting feature: 283/1500\n",
      "Extracting feature: 284/1500\n",
      "Extracting feature: 285/1500\n",
      "Extracting feature: 286/1500\n",
      "Extracting feature: 287/1500\n",
      "Extracting feature: 288/1500\n",
      "Extracting feature: 289/1500\n",
      "Extracting feature: 290/1500\n",
      "Extracting feature: 291/1500\n",
      "Extracting feature: 292/1500\n",
      "Extracting feature: 293/1500\n",
      "Extracting feature: 294/1500\n",
      "Extracting feature: 295/1500\n",
      "Extracting feature: 296/1500\n",
      "Extracting feature: 297/1500\n",
      "Extracting feature: 298/1500\n",
      "Extracting feature: 299/1500\n",
      "Extracting feature: 300/1500\n",
      "Extracting feature: 301/1500\n",
      "Extracting feature: 302/1500\n",
      "Extracting feature: 303/1500\n",
      "Extracting feature: 304/1500\n",
      "Extracting feature: 305/1500\n",
      "Extracting feature: 306/1500\n",
      "Extracting feature: 307/1500\n",
      "Extracting feature: 308/1500\n",
      "Extracting feature: 309/1500\n",
      "Extracting feature: 310/1500\n",
      "Extracting feature: 311/1500\n",
      "Extracting feature: 312/1500\n",
      "Extracting feature: 313/1500\n",
      "Extracting feature: 314/1500\n",
      "Extracting feature: 315/1500\n",
      "Extracting feature: 316/1500\n",
      "Extracting feature: 317/1500\n",
      "Extracting feature: 318/1500\n",
      "Extracting feature: 319/1500\n",
      "Extracting feature: 320/1500\n",
      "Extracting feature: 321/1500\n",
      "Extracting feature: 322/1500\n",
      "Extracting feature: 323/1500\n",
      "Extracting feature: 324/1500\n",
      "Extracting feature: 325/1500\n",
      "Extracting feature: 326/1500\n",
      "Extracting feature: 327/1500\n",
      "Extracting feature: 328/1500\n",
      "Extracting feature: 329/1500\n",
      "Extracting feature: 330/1500\n",
      "Extracting feature: 331/1500\n",
      "Extracting feature: 332/1500\n",
      "Extracting feature: 333/1500\n",
      "Extracting feature: 334/1500\n",
      "Extracting feature: 335/1500\n",
      "Extracting feature: 336/1500\n",
      "Extracting feature: 337/1500\n",
      "Extracting feature: 338/1500\n",
      "Extracting feature: 339/1500\n",
      "Extracting feature: 340/1500\n",
      "Extracting feature: 341/1500\n",
      "Extracting feature: 342/1500\n",
      "Extracting feature: 343/1500\n",
      "Extracting feature: 344/1500\n",
      "Extracting feature: 345/1500\n",
      "Extracting feature: 346/1500\n",
      "Extracting feature: 347/1500\n",
      "Extracting feature: 348/1500\n",
      "Extracting feature: 349/1500\n",
      "Extracting feature: 350/1500\n",
      "Extracting feature: 351/1500\n",
      "Extracting feature: 352/1500\n",
      "Extracting feature: 353/1500\n",
      "Extracting feature: 354/1500\n",
      "Extracting feature: 355/1500\n",
      "Extracting feature: 356/1500\n",
      "Extracting feature: 357/1500\n",
      "Extracting feature: 358/1500\n",
      "Extracting feature: 359/1500\n",
      "Extracting feature: 360/1500\n",
      "Extracting feature: 361/1500\n",
      "Extracting feature: 362/1500\n",
      "Extracting feature: 363/1500\n",
      "Extracting feature: 364/1500\n",
      "Extracting feature: 365/1500\n",
      "Extracting feature: 366/1500\n",
      "Extracting feature: 367/1500\n",
      "Extracting feature: 368/1500\n",
      "Extracting feature: 369/1500\n",
      "Extracting feature: 370/1500\n",
      "Extracting feature: 371/1500\n",
      "Extracting feature: 372/1500\n",
      "Extracting feature: 373/1500\n",
      "Extracting feature: 374/1500\n",
      "Extracting feature: 375/1500\n",
      "Extracting feature: 376/1500\n",
      "Extracting feature: 377/1500\n",
      "Extracting feature: 378/1500\n",
      "Extracting feature: 379/1500\n",
      "Extracting feature: 380/1500\n",
      "Extracting feature: 381/1500\n",
      "Extracting feature: 382/1500\n",
      "Extracting feature: 383/1500\n",
      "Extracting feature: 384/1500\n",
      "Extracting feature: 385/1500\n",
      "Extracting feature: 386/1500\n",
      "Extracting feature: 387/1500\n",
      "Extracting feature: 388/1500\n",
      "Extracting feature: 389/1500\n",
      "Extracting feature: 390/1500\n",
      "Extracting feature: 391/1500\n",
      "Extracting feature: 392/1500\n",
      "Extracting feature: 393/1500\n",
      "Extracting feature: 394/1500\n",
      "Extracting feature: 395/1500\n",
      "Extracting feature: 396/1500\n",
      "Extracting feature: 397/1500\n",
      "Extracting feature: 398/1500\n",
      "Extracting feature: 399/1500\n",
      "Extracting feature: 400/1500\n",
      "Extracting feature: 401/1500\n",
      "Extracting feature: 402/1500\n",
      "Extracting feature: 403/1500\n",
      "Extracting feature: 404/1500\n",
      "Extracting feature: 405/1500\n",
      "Extracting feature: 406/1500\n",
      "Extracting feature: 407/1500\n",
      "Extracting feature: 408/1500\n",
      "Extracting feature: 409/1500\n",
      "Extracting feature: 410/1500\n",
      "Extracting feature: 411/1500\n",
      "Extracting feature: 412/1500\n",
      "Extracting feature: 413/1500\n",
      "Extracting feature: 414/1500\n",
      "Extracting feature: 415/1500\n",
      "Extracting feature: 416/1500\n",
      "Extracting feature: 417/1500\n",
      "Extracting feature: 418/1500\n",
      "Extracting feature: 419/1500\n",
      "Extracting feature: 420/1500\n",
      "Extracting feature: 421/1500\n",
      "Extracting feature: 422/1500\n",
      "Extracting feature: 423/1500\n",
      "Extracting feature: 424/1500\n",
      "Extracting feature: 425/1500\n",
      "Extracting feature: 426/1500\n",
      "Extracting feature: 427/1500\n",
      "Extracting feature: 428/1500\n",
      "Extracting feature: 429/1500\n",
      "Extracting feature: 430/1500\n",
      "Extracting feature: 431/1500\n",
      "Extracting feature: 432/1500\n",
      "Extracting feature: 433/1500\n",
      "Extracting feature: 434/1500\n",
      "Extracting feature: 435/1500\n",
      "Extracting feature: 436/1500\n",
      "Extracting feature: 437/1500\n",
      "Extracting feature: 438/1500\n",
      "Extracting feature: 439/1500\n",
      "Extracting feature: 440/1500\n",
      "Extracting feature: 441/1500\n",
      "Extracting feature: 442/1500\n",
      "Extracting feature: 443/1500\n",
      "Extracting feature: 444/1500\n",
      "Extracting feature: 445/1500\n",
      "Extracting feature: 446/1500\n",
      "Extracting feature: 447/1500\n",
      "Extracting feature: 448/1500\n",
      "Extracting feature: 449/1500\n",
      "Extracting feature: 450/1500\n",
      "Extracting feature: 451/1500\n",
      "Extracting feature: 452/1500\n",
      "Extracting feature: 453/1500\n",
      "Extracting feature: 454/1500\n",
      "Extracting feature: 455/1500\n",
      "Extracting feature: 456/1500\n",
      "Extracting feature: 457/1500\n",
      "Extracting feature: 458/1500\n",
      "Extracting feature: 459/1500\n",
      "Extracting feature: 460/1500\n",
      "Extracting feature: 461/1500\n",
      "Extracting feature: 462/1500\n",
      "Extracting feature: 463/1500\n",
      "Extracting feature: 464/1500\n",
      "Extracting feature: 465/1500\n",
      "Extracting feature: 466/1500\n",
      "Extracting feature: 467/1500\n",
      "Extracting feature: 468/1500\n",
      "Extracting feature: 469/1500\n",
      "Extracting feature: 470/1500\n",
      "Extracting feature: 471/1500\n",
      "Extracting feature: 472/1500\n",
      "Extracting feature: 473/1500\n",
      "Extracting feature: 474/1500\n",
      "Extracting feature: 475/1500\n",
      "Extracting feature: 476/1500\n",
      "Extracting feature: 477/1500\n",
      "Extracting feature: 478/1500\n",
      "Extracting feature: 479/1500\n",
      "Extracting feature: 480/1500\n",
      "Extracting feature: 481/1500\n",
      "Extracting feature: 482/1500\n",
      "Extracting feature: 483/1500\n",
      "Extracting feature: 484/1500\n",
      "Extracting feature: 485/1500\n",
      "Extracting feature: 486/1500\n",
      "Extracting feature: 487/1500\n",
      "Extracting feature: 488/1500\n",
      "Extracting feature: 489/1500\n",
      "Extracting feature: 490/1500\n",
      "Extracting feature: 491/1500\n",
      "Extracting feature: 492/1500\n",
      "Extracting feature: 493/1500\n",
      "Extracting feature: 494/1500\n",
      "Extracting feature: 495/1500\n",
      "Extracting feature: 496/1500\n",
      "Extracting feature: 497/1500\n",
      "Extracting feature: 498/1500\n",
      "Extracting feature: 499/1500\n",
      "Extracting feature: 500/1500\n",
      "Extracting feature: 501/1500\n",
      "Extracting feature: 502/1500\n",
      "Extracting feature: 503/1500\n",
      "Extracting feature: 504/1500\n",
      "Extracting feature: 505/1500\n",
      "Extracting feature: 506/1500\n",
      "Extracting feature: 507/1500\n",
      "Extracting feature: 508/1500\n",
      "Extracting feature: 509/1500\n",
      "Extracting feature: 510/1500\n",
      "Extracting feature: 511/1500\n",
      "Extracting feature: 512/1500\n",
      "Extracting feature: 513/1500\n",
      "Extracting feature: 514/1500\n",
      "Extracting feature: 515/1500\n",
      "Extracting feature: 516/1500\n",
      "Extracting feature: 517/1500\n",
      "Extracting feature: 518/1500\n",
      "Extracting feature: 519/1500\n",
      "Extracting feature: 520/1500\n",
      "Extracting feature: 521/1500\n",
      "Extracting feature: 522/1500\n",
      "Extracting feature: 523/1500\n",
      "Extracting feature: 524/1500\n",
      "Extracting feature: 525/1500\n",
      "Extracting feature: 526/1500\n",
      "Extracting feature: 527/1500\n",
      "Extracting feature: 528/1500\n",
      "Extracting feature: 529/1500\n",
      "Extracting feature: 530/1500\n",
      "Extracting feature: 531/1500\n",
      "Extracting feature: 532/1500\n",
      "Extracting feature: 533/1500\n",
      "Extracting feature: 534/1500\n",
      "Extracting feature: 535/1500\n",
      "Extracting feature: 536/1500\n",
      "Extracting feature: 537/1500\n",
      "Extracting feature: 538/1500\n",
      "Extracting feature: 539/1500\n",
      "Extracting feature: 540/1500\n",
      "Extracting feature: 541/1500\n",
      "Extracting feature: 542/1500\n",
      "Extracting feature: 543/1500\n",
      "Extracting feature: 544/1500\n",
      "Extracting feature: 545/1500\n",
      "Extracting feature: 546/1500\n",
      "Extracting feature: 547/1500\n",
      "Extracting feature: 548/1500\n",
      "Extracting feature: 549/1500\n",
      "Extracting feature: 550/1500\n",
      "Extracting feature: 551/1500\n",
      "Extracting feature: 552/1500\n",
      "Extracting feature: 553/1500\n",
      "Extracting feature: 554/1500\n",
      "Extracting feature: 555/1500\n",
      "Extracting feature: 556/1500\n",
      "Extracting feature: 557/1500\n",
      "Extracting feature: 558/1500\n",
      "Extracting feature: 559/1500\n",
      "Extracting feature: 560/1500\n",
      "Extracting feature: 561/1500\n",
      "Extracting feature: 562/1500\n",
      "Extracting feature: 563/1500\n",
      "Extracting feature: 564/1500\n",
      "Extracting feature: 565/1500\n",
      "Extracting feature: 566/1500\n",
      "Extracting feature: 567/1500\n",
      "Extracting feature: 568/1500\n",
      "Extracting feature: 569/1500\n",
      "Extracting feature: 570/1500\n",
      "Extracting feature: 571/1500\n",
      "Extracting feature: 572/1500\n",
      "Extracting feature: 573/1500\n",
      "Extracting feature: 574/1500\n",
      "Extracting feature: 575/1500\n",
      "Extracting feature: 576/1500\n",
      "Extracting feature: 577/1500\n",
      "Extracting feature: 578/1500\n",
      "Extracting feature: 579/1500\n",
      "Extracting feature: 580/1500\n",
      "Extracting feature: 581/1500\n",
      "Extracting feature: 582/1500\n",
      "Extracting feature: 583/1500\n",
      "Extracting feature: 584/1500\n",
      "Extracting feature: 585/1500\n",
      "Extracting feature: 586/1500\n",
      "Extracting feature: 587/1500\n",
      "Extracting feature: 588/1500\n",
      "Extracting feature: 589/1500\n",
      "Extracting feature: 590/1500\n",
      "Extracting feature: 591/1500\n",
      "Extracting feature: 592/1500\n",
      "Extracting feature: 593/1500\n",
      "Extracting feature: 594/1500\n",
      "Extracting feature: 595/1500\n",
      "Extracting feature: 596/1500\n",
      "Extracting feature: 597/1500\n",
      "Extracting feature: 598/1500\n",
      "Extracting feature: 599/1500\n",
      "Extracting feature: 600/1500\n",
      "Extracting feature: 601/1500\n",
      "Extracting feature: 602/1500\n",
      "Extracting feature: 603/1500\n",
      "Extracting feature: 604/1500\n",
      "Extracting feature: 605/1500\n",
      "Extracting feature: 606/1500\n",
      "Extracting feature: 607/1500\n",
      "Extracting feature: 608/1500\n",
      "Extracting feature: 609/1500\n",
      "Extracting feature: 610/1500\n",
      "Extracting feature: 611/1500\n",
      "Extracting feature: 612/1500\n",
      "Extracting feature: 613/1500\n",
      "Extracting feature: 614/1500\n",
      "Extracting feature: 615/1500\n",
      "Extracting feature: 616/1500\n",
      "Extracting feature: 617/1500\n",
      "Extracting feature: 618/1500\n",
      "Extracting feature: 619/1500\n",
      "Extracting feature: 620/1500\n",
      "Extracting feature: 621/1500\n",
      "Extracting feature: 622/1500\n",
      "Extracting feature: 623/1500\n",
      "Extracting feature: 624/1500\n",
      "Extracting feature: 625/1500\n",
      "Extracting feature: 626/1500\n",
      "Extracting feature: 627/1500\n",
      "Extracting feature: 628/1500\n",
      "Extracting feature: 629/1500\n",
      "Extracting feature: 630/1500\n",
      "Extracting feature: 631/1500\n",
      "Extracting feature: 632/1500\n",
      "Extracting feature: 633/1500\n",
      "Extracting feature: 634/1500\n",
      "Extracting feature: 635/1500\n",
      "Extracting feature: 636/1500\n",
      "Extracting feature: 637/1500\n",
      "Extracting feature: 638/1500\n",
      "Extracting feature: 639/1500\n",
      "Extracting feature: 640/1500\n",
      "Extracting feature: 641/1500\n",
      "Extracting feature: 642/1500\n",
      "Extracting feature: 643/1500\n",
      "Extracting feature: 644/1500\n",
      "Extracting feature: 645/1500\n",
      "Extracting feature: 646/1500\n",
      "Extracting feature: 647/1500\n",
      "Extracting feature: 648/1500\n",
      "Extracting feature: 649/1500\n",
      "Extracting feature: 650/1500\n",
      "Extracting feature: 651/1500\n",
      "Extracting feature: 652/1500\n",
      "Extracting feature: 653/1500\n",
      "Extracting feature: 654/1500\n",
      "Extracting feature: 655/1500\n",
      "Extracting feature: 656/1500\n",
      "Extracting feature: 657/1500\n",
      "Extracting feature: 658/1500\n",
      "Extracting feature: 659/1500\n",
      "Extracting feature: 660/1500\n",
      "Extracting feature: 661/1500\n",
      "Extracting feature: 662/1500\n",
      "Extracting feature: 663/1500\n",
      "Extracting feature: 664/1500\n",
      "Extracting feature: 665/1500\n",
      "Extracting feature: 666/1500\n",
      "Extracting feature: 667/1500\n",
      "Extracting feature: 668/1500\n",
      "Extracting feature: 669/1500\n",
      "Extracting feature: 670/1500\n",
      "Extracting feature: 671/1500\n",
      "Extracting feature: 672/1500\n",
      "Extracting feature: 673/1500\n",
      "Extracting feature: 674/1500\n",
      "Extracting feature: 675/1500\n",
      "Extracting feature: 676/1500\n",
      "Extracting feature: 677/1500\n",
      "Extracting feature: 678/1500\n",
      "Extracting feature: 679/1500\n",
      "Extracting feature: 680/1500\n",
      "Extracting feature: 681/1500\n",
      "Extracting feature: 682/1500\n",
      "Extracting feature: 683/1500\n",
      "Extracting feature: 684/1500\n",
      "Extracting feature: 685/1500\n",
      "Extracting feature: 686/1500\n",
      "Extracting feature: 687/1500\n",
      "Extracting feature: 688/1500\n",
      "Extracting feature: 689/1500\n",
      "Extracting feature: 690/1500\n",
      "Extracting feature: 691/1500\n",
      "Extracting feature: 692/1500\n",
      "Extracting feature: 693/1500\n",
      "Extracting feature: 694/1500\n",
      "Extracting feature: 695/1500\n",
      "Extracting feature: 696/1500\n",
      "Extracting feature: 697/1500\n",
      "Extracting feature: 698/1500\n",
      "Extracting feature: 699/1500\n",
      "Extracting feature: 700/1500\n",
      "Extracting feature: 701/1500\n",
      "Extracting feature: 702/1500\n",
      "Extracting feature: 703/1500\n",
      "Extracting feature: 704/1500\n",
      "Extracting feature: 705/1500\n",
      "Extracting feature: 706/1500\n",
      "Extracting feature: 707/1500\n",
      "Extracting feature: 708/1500\n",
      "Extracting feature: 709/1500\n",
      "Extracting feature: 710/1500\n",
      "Extracting feature: 711/1500\n",
      "Extracting feature: 712/1500\n",
      "Extracting feature: 713/1500\n",
      "Extracting feature: 714/1500\n",
      "Extracting feature: 715/1500\n",
      "Extracting feature: 716/1500\n",
      "Extracting feature: 717/1500\n",
      "Extracting feature: 718/1500\n",
      "Extracting feature: 719/1500\n",
      "Extracting feature: 720/1500\n",
      "Extracting feature: 721/1500\n",
      "Extracting feature: 722/1500\n",
      "Extracting feature: 723/1500\n",
      "Extracting feature: 724/1500\n",
      "Extracting feature: 725/1500\n",
      "Extracting feature: 726/1500\n",
      "Extracting feature: 727/1500\n",
      "Extracting feature: 728/1500\n",
      "Extracting feature: 729/1500\n",
      "Extracting feature: 730/1500\n",
      "Extracting feature: 731/1500\n",
      "Extracting feature: 732/1500\n",
      "Extracting feature: 733/1500\n",
      "Extracting feature: 734/1500\n",
      "Extracting feature: 735/1500\n",
      "Extracting feature: 736/1500\n",
      "Extracting feature: 737/1500\n",
      "Extracting feature: 738/1500\n",
      "Extracting feature: 739/1500\n",
      "Extracting feature: 740/1500\n",
      "Extracting feature: 741/1500\n",
      "Extracting feature: 742/1500\n",
      "Extracting feature: 743/1500\n",
      "Extracting feature: 744/1500\n",
      "Extracting feature: 745/1500\n",
      "Extracting feature: 746/1500\n",
      "Extracting feature: 747/1500\n",
      "Extracting feature: 748/1500\n",
      "Extracting feature: 749/1500\n",
      "Extracting feature: 750/1500\n",
      "Extracting feature: 751/1500\n",
      "Extracting feature: 752/1500\n",
      "Extracting feature: 753/1500\n",
      "Extracting feature: 754/1500\n",
      "Extracting feature: 755/1500\n",
      "Extracting feature: 756/1500\n",
      "Extracting feature: 757/1500\n",
      "Extracting feature: 758/1500\n",
      "Extracting feature: 759/1500\n",
      "Extracting feature: 760/1500\n",
      "Extracting feature: 761/1500\n",
      "Extracting feature: 762/1500\n",
      "Extracting feature: 763/1500\n",
      "Extracting feature: 764/1500\n",
      "Extracting feature: 765/1500\n",
      "Extracting feature: 766/1500\n",
      "Extracting feature: 767/1500\n",
      "Extracting feature: 768/1500\n",
      "Extracting feature: 769/1500\n",
      "Extracting feature: 770/1500\n",
      "Extracting feature: 771/1500\n",
      "Extracting feature: 772/1500\n",
      "Extracting feature: 773/1500\n",
      "Extracting feature: 774/1500\n",
      "Extracting feature: 775/1500\n",
      "Extracting feature: 776/1500\n",
      "Extracting feature: 777/1500\n",
      "Extracting feature: 778/1500\n",
      "Extracting feature: 779/1500\n",
      "Extracting feature: 780/1500\n",
      "Extracting feature: 781/1500\n",
      "Extracting feature: 782/1500\n",
      "Extracting feature: 783/1500\n",
      "Extracting feature: 784/1500\n",
      "Extracting feature: 785/1500\n",
      "Extracting feature: 786/1500\n",
      "Extracting feature: 787/1500\n",
      "Extracting feature: 788/1500\n",
      "Extracting feature: 789/1500\n",
      "Extracting feature: 790/1500\n",
      "Extracting feature: 791/1500\n",
      "Extracting feature: 792/1500\n",
      "Extracting feature: 793/1500\n",
      "Extracting feature: 794/1500\n",
      "Extracting feature: 795/1500\n",
      "Extracting feature: 796/1500\n",
      "Extracting feature: 797/1500\n",
      "Extracting feature: 798/1500\n",
      "Extracting feature: 799/1500\n",
      "Extracting feature: 800/1500\n",
      "Extracting feature: 801/1500\n",
      "Extracting feature: 802/1500\n",
      "Extracting feature: 803/1500\n",
      "Extracting feature: 804/1500\n",
      "Extracting feature: 805/1500\n",
      "Extracting feature: 806/1500\n",
      "Extracting feature: 807/1500\n",
      "Extracting feature: 808/1500\n",
      "Extracting feature: 809/1500\n",
      "Extracting feature: 810/1500\n",
      "Extracting feature: 811/1500\n",
      "Extracting feature: 812/1500\n",
      "Extracting feature: 813/1500\n",
      "Extracting feature: 814/1500\n",
      "Extracting feature: 815/1500\n",
      "Extracting feature: 816/1500\n",
      "Extracting feature: 817/1500\n",
      "Extracting feature: 818/1500\n",
      "Extracting feature: 819/1500\n",
      "Extracting feature: 820/1500\n",
      "Extracting feature: 821/1500\n",
      "Extracting feature: 822/1500\n",
      "Extracting feature: 823/1500\n",
      "Extracting feature: 824/1500\n",
      "Extracting feature: 825/1500\n",
      "Extracting feature: 826/1500\n",
      "Extracting feature: 827/1500\n",
      "Extracting feature: 828/1500\n",
      "Extracting feature: 829/1500\n",
      "Extracting feature: 830/1500\n",
      "Extracting feature: 831/1500\n",
      "Extracting feature: 832/1500\n",
      "Extracting feature: 833/1500\n",
      "Extracting feature: 834/1500\n",
      "Extracting feature: 835/1500\n",
      "Extracting feature: 836/1500\n",
      "Extracting feature: 837/1500\n",
      "Extracting feature: 838/1500\n",
      "Extracting feature: 839/1500\n",
      "Extracting feature: 840/1500\n",
      "Extracting feature: 841/1500\n",
      "Extracting feature: 842/1500\n",
      "Extracting feature: 843/1500\n",
      "Extracting feature: 844/1500\n",
      "Extracting feature: 845/1500\n",
      "Extracting feature: 846/1500\n",
      "Extracting feature: 847/1500\n",
      "Extracting feature: 848/1500\n",
      "Extracting feature: 849/1500\n",
      "Extracting feature: 850/1500\n",
      "Extracting feature: 851/1500\n",
      "Extracting feature: 852/1500\n",
      "Extracting feature: 853/1500\n",
      "Extracting feature: 854/1500\n",
      "Extracting feature: 855/1500\n",
      "Extracting feature: 856/1500\n",
      "Extracting feature: 857/1500\n",
      "Extracting feature: 858/1500\n",
      "Extracting feature: 859/1500\n",
      "Extracting feature: 860/1500\n",
      "Extracting feature: 861/1500\n",
      "Extracting feature: 862/1500\n",
      "Extracting feature: 863/1500\n",
      "Extracting feature: 864/1500\n",
      "Extracting feature: 865/1500\n",
      "Extracting feature: 866/1500\n",
      "Extracting feature: 867/1500\n",
      "Extracting feature: 868/1500\n",
      "Extracting feature: 869/1500\n",
      "Extracting feature: 870/1500\n",
      "Extracting feature: 871/1500\n",
      "Extracting feature: 872/1500\n",
      "Extracting feature: 873/1500\n",
      "Extracting feature: 874/1500\n",
      "Extracting feature: 875/1500\n",
      "Extracting feature: 876/1500\n",
      "Extracting feature: 877/1500\n",
      "Extracting feature: 878/1500\n",
      "Extracting feature: 879/1500\n",
      "Extracting feature: 880/1500\n",
      "Extracting feature: 881/1500\n",
      "Extracting feature: 882/1500\n",
      "Extracting feature: 883/1500\n",
      "Extracting feature: 884/1500\n",
      "Extracting feature: 885/1500\n",
      "Extracting feature: 886/1500\n",
      "Extracting feature: 887/1500\n",
      "Extracting feature: 888/1500\n",
      "Extracting feature: 889/1500\n",
      "Extracting feature: 890/1500\n",
      "Extracting feature: 891/1500\n",
      "Extracting feature: 892/1500\n",
      "Extracting feature: 893/1500\n",
      "Extracting feature: 894/1500\n",
      "Extracting feature: 895/1500\n",
      "Extracting feature: 896/1500\n",
      "Extracting feature: 897/1500\n",
      "Extracting feature: 898/1500\n",
      "Extracting feature: 899/1500\n",
      "Extracting feature: 900/1500\n",
      "Extracting feature: 901/1500\n",
      "Extracting feature: 902/1500\n",
      "Extracting feature: 903/1500\n",
      "Extracting feature: 904/1500\n",
      "Extracting feature: 905/1500\n",
      "Extracting feature: 906/1500\n",
      "Extracting feature: 907/1500\n",
      "Extracting feature: 908/1500\n",
      "Extracting feature: 909/1500\n",
      "Extracting feature: 910/1500\n",
      "Extracting feature: 911/1500\n",
      "Extracting feature: 912/1500\n",
      "Extracting feature: 913/1500\n",
      "Extracting feature: 914/1500\n",
      "Extracting feature: 915/1500\n",
      "Extracting feature: 916/1500\n",
      "Extracting feature: 917/1500\n",
      "Extracting feature: 918/1500\n",
      "Extracting feature: 919/1500\n",
      "Extracting feature: 920/1500\n",
      "Extracting feature: 921/1500\n",
      "Extracting feature: 922/1500\n",
      "Extracting feature: 923/1500\n",
      "Extracting feature: 924/1500\n",
      "Extracting feature: 925/1500\n",
      "Extracting feature: 926/1500\n",
      "Extracting feature: 927/1500\n",
      "Extracting feature: 928/1500\n",
      "Extracting feature: 929/1500\n",
      "Extracting feature: 930/1500\n",
      "Extracting feature: 931/1500\n",
      "Extracting feature: 932/1500\n",
      "Extracting feature: 933/1500\n",
      "Extracting feature: 934/1500\n",
      "Extracting feature: 935/1500\n",
      "Extracting feature: 936/1500\n",
      "Extracting feature: 937/1500\n",
      "Extracting feature: 938/1500\n",
      "Extracting feature: 939/1500\n",
      "Extracting feature: 940/1500\n",
      "Extracting feature: 941/1500\n",
      "Extracting feature: 942/1500\n",
      "Extracting feature: 943/1500\n",
      "Extracting feature: 944/1500\n",
      "Extracting feature: 945/1500\n",
      "Extracting feature: 946/1500\n",
      "Extracting feature: 947/1500\n",
      "Extracting feature: 948/1500\n",
      "Extracting feature: 949/1500\n",
      "Extracting feature: 950/1500\n",
      "Extracting feature: 951/1500\n",
      "Extracting feature: 952/1500\n",
      "Extracting feature: 953/1500\n",
      "Extracting feature: 954/1500\n",
      "Extracting feature: 955/1500\n",
      "Extracting feature: 956/1500\n",
      "Extracting feature: 957/1500\n",
      "Extracting feature: 958/1500\n",
      "Extracting feature: 959/1500\n",
      "Extracting feature: 960/1500\n",
      "Extracting feature: 961/1500\n",
      "Extracting feature: 962/1500\n",
      "Extracting feature: 963/1500\n",
      "Extracting feature: 964/1500\n",
      "Extracting feature: 965/1500\n",
      "Extracting feature: 966/1500\n",
      "Extracting feature: 967/1500\n",
      "Extracting feature: 968/1500\n",
      "Extracting feature: 969/1500\n",
      "Extracting feature: 970/1500\n",
      "Extracting feature: 971/1500\n",
      "Extracting feature: 972/1500\n",
      "Extracting feature: 973/1500\n",
      "Extracting feature: 974/1500\n",
      "Extracting feature: 975/1500\n",
      "Extracting feature: 976/1500\n",
      "Extracting feature: 977/1500\n",
      "Extracting feature: 978/1500\n",
      "Extracting feature: 979/1500\n",
      "Extracting feature: 980/1500\n",
      "Extracting feature: 981/1500\n",
      "Extracting feature: 982/1500\n",
      "Extracting feature: 983/1500\n",
      "Extracting feature: 984/1500\n",
      "Extracting feature: 985/1500\n",
      "Extracting feature: 986/1500\n",
      "Extracting feature: 987/1500\n",
      "Extracting feature: 988/1500\n",
      "Extracting feature: 989/1500\n",
      "Extracting feature: 990/1500\n",
      "Extracting feature: 991/1500\n",
      "Extracting feature: 992/1500\n",
      "Extracting feature: 993/1500\n",
      "Extracting feature: 994/1500\n",
      "Extracting feature: 995/1500\n",
      "Extracting feature: 996/1500\n",
      "Extracting feature: 997/1500\n",
      "Extracting feature: 998/1500\n",
      "Extracting feature: 999/1500\n",
      "Extracting feature: 1000/1500\n",
      "Extracting feature: 1001/1500\n",
      "Extracting feature: 1002/1500\n",
      "Extracting feature: 1003/1500\n",
      "Extracting feature: 1004/1500\n",
      "Extracting feature: 1005/1500\n",
      "Extracting feature: 1006/1500\n",
      "Extracting feature: 1007/1500\n",
      "Extracting feature: 1008/1500\n",
      "Extracting feature: 1009/1500\n",
      "Extracting feature: 1010/1500\n",
      "Extracting feature: 1011/1500\n",
      "Extracting feature: 1012/1500\n",
      "Extracting feature: 1013/1500\n",
      "Extracting feature: 1014/1500\n",
      "Extracting feature: 1015/1500\n",
      "Extracting feature: 1016/1500\n",
      "Extracting feature: 1017/1500\n",
      "Extracting feature: 1018/1500\n",
      "Extracting feature: 1019/1500\n",
      "Extracting feature: 1020/1500\n",
      "Extracting feature: 1021/1500\n",
      "Extracting feature: 1022/1500\n",
      "Extracting feature: 1023/1500\n",
      "Extracting feature: 1024/1500\n",
      "Extracting feature: 1025/1500\n",
      "Extracting feature: 1026/1500\n",
      "Extracting feature: 1027/1500\n",
      "Extracting feature: 1028/1500\n",
      "Extracting feature: 1029/1500\n",
      "Extracting feature: 1030/1500\n",
      "Extracting feature: 1031/1500\n",
      "Extracting feature: 1032/1500\n",
      "Extracting feature: 1033/1500\n",
      "Extracting feature: 1034/1500\n",
      "Extracting feature: 1035/1500\n",
      "Extracting feature: 1036/1500\n",
      "Extracting feature: 1037/1500\n",
      "Extracting feature: 1038/1500\n",
      "Extracting feature: 1039/1500\n",
      "Extracting feature: 1040/1500\n",
      "Extracting feature: 1041/1500\n",
      "Extracting feature: 1042/1500\n",
      "Extracting feature: 1043/1500\n",
      "Extracting feature: 1044/1500\n",
      "Extracting feature: 1045/1500\n",
      "Extracting feature: 1046/1500\n",
      "Extracting feature: 1047/1500\n",
      "Extracting feature: 1048/1500\n",
      "Extracting feature: 1049/1500\n",
      "Extracting feature: 1050/1500\n",
      "Extracting feature: 1051/1500\n",
      "Extracting feature: 1052/1500\n",
      "Extracting feature: 1053/1500\n",
      "Extracting feature: 1054/1500\n",
      "Extracting feature: 1055/1500\n",
      "Extracting feature: 1056/1500\n",
      "Extracting feature: 1057/1500\n",
      "Extracting feature: 1058/1500\n",
      "Extracting feature: 1059/1500\n",
      "Extracting feature: 1060/1500\n",
      "Extracting feature: 1061/1500\n",
      "Extracting feature: 1062/1500\n",
      "Extracting feature: 1063/1500\n",
      "Extracting feature: 1064/1500\n",
      "Extracting feature: 1065/1500\n",
      "Extracting feature: 1066/1500\n",
      "Extracting feature: 1067/1500\n",
      "Extracting feature: 1068/1500\n",
      "Extracting feature: 1069/1500\n",
      "Extracting feature: 1070/1500\n",
      "Extracting feature: 1071/1500\n",
      "Extracting feature: 1072/1500\n",
      "Extracting feature: 1073/1500\n",
      "Extracting feature: 1074/1500\n",
      "Extracting feature: 1075/1500\n",
      "Extracting feature: 1076/1500\n",
      "Extracting feature: 1077/1500\n",
      "Extracting feature: 1078/1500\n",
      "Extracting feature: 1079/1500\n",
      "Extracting feature: 1080/1500\n",
      "Extracting feature: 1081/1500\n",
      "Extracting feature: 1082/1500\n",
      "Extracting feature: 1083/1500\n",
      "Extracting feature: 1084/1500\n",
      "Extracting feature: 1085/1500\n",
      "Extracting feature: 1086/1500\n",
      "Extracting feature: 1087/1500\n",
      "Extracting feature: 1088/1500\n",
      "Extracting feature: 1089/1500\n",
      "Extracting feature: 1090/1500\n",
      "Extracting feature: 1091/1500\n",
      "Extracting feature: 1092/1500\n",
      "Extracting feature: 1093/1500\n",
      "Extracting feature: 1094/1500\n",
      "Extracting feature: 1095/1500\n",
      "Extracting feature: 1096/1500\n",
      "Extracting feature: 1097/1500\n",
      "Extracting feature: 1098/1500\n",
      "Extracting feature: 1099/1500\n",
      "Extracting feature: 1100/1500\n",
      "Extracting feature: 1101/1500\n",
      "Extracting feature: 1102/1500\n",
      "Extracting feature: 1103/1500\n",
      "Extracting feature: 1104/1500\n",
      "Extracting feature: 1105/1500\n",
      "Extracting feature: 1106/1500\n",
      "Extracting feature: 1107/1500\n",
      "Extracting feature: 1108/1500\n",
      "Extracting feature: 1109/1500\n",
      "Extracting feature: 1110/1500\n",
      "Extracting feature: 1111/1500\n",
      "Extracting feature: 1112/1500\n",
      "Extracting feature: 1113/1500\n",
      "Extracting feature: 1114/1500\n",
      "Extracting feature: 1115/1500\n",
      "Extracting feature: 1116/1500\n",
      "Extracting feature: 1117/1500\n",
      "Extracting feature: 1118/1500\n",
      "Extracting feature: 1119/1500\n",
      "Extracting feature: 1120/1500\n",
      "Extracting feature: 1121/1500\n",
      "Extracting feature: 1122/1500\n",
      "Extracting feature: 1123/1500\n",
      "Extracting feature: 1124/1500\n",
      "Extracting feature: 1125/1500\n",
      "Extracting feature: 1126/1500\n",
      "Extracting feature: 1127/1500\n",
      "Extracting feature: 1128/1500\n",
      "Extracting feature: 1129/1500\n",
      "Extracting feature: 1130/1500\n",
      "Extracting feature: 1131/1500\n",
      "Extracting feature: 1132/1500\n",
      "Extracting feature: 1133/1500\n",
      "Extracting feature: 1134/1500\n",
      "Extracting feature: 1135/1500\n",
      "Extracting feature: 1136/1500\n",
      "Extracting feature: 1137/1500\n",
      "Extracting feature: 1138/1500\n",
      "Extracting feature: 1139/1500\n",
      "Extracting feature: 1140/1500\n",
      "Extracting feature: 1141/1500\n",
      "Extracting feature: 1142/1500\n",
      "Extracting feature: 1143/1500\n",
      "Extracting feature: 1144/1500\n",
      "Extracting feature: 1145/1500\n",
      "Extracting feature: 1146/1500\n",
      "Extracting feature: 1147/1500\n",
      "Extracting feature: 1148/1500\n",
      "Extracting feature: 1149/1500\n",
      "Extracting feature: 1150/1500\n",
      "Extracting feature: 1151/1500\n",
      "Extracting feature: 1152/1500\n",
      "Extracting feature: 1153/1500\n",
      "Extracting feature: 1154/1500\n",
      "Extracting feature: 1155/1500\n",
      "Extracting feature: 1156/1500\n",
      "Extracting feature: 1157/1500\n",
      "Extracting feature: 1158/1500\n",
      "Extracting feature: 1159/1500\n",
      "Extracting feature: 1160/1500\n",
      "Extracting feature: 1161/1500\n",
      "Extracting feature: 1162/1500\n",
      "Extracting feature: 1163/1500\n",
      "Extracting feature: 1164/1500\n",
      "Extracting feature: 1165/1500\n",
      "Extracting feature: 1166/1500\n",
      "Extracting feature: 1167/1500\n",
      "Extracting feature: 1168/1500\n",
      "Extracting feature: 1169/1500\n",
      "Extracting feature: 1170/1500\n",
      "Extracting feature: 1171/1500\n",
      "Extracting feature: 1172/1500\n",
      "Extracting feature: 1173/1500\n",
      "Extracting feature: 1174/1500\n",
      "Extracting feature: 1175/1500\n",
      "Extracting feature: 1176/1500\n",
      "Extracting feature: 1177/1500\n",
      "Extracting feature: 1178/1500\n",
      "Extracting feature: 1179/1500\n",
      "Extracting feature: 1180/1500\n",
      "Extracting feature: 1181/1500\n",
      "Extracting feature: 1182/1500\n",
      "Extracting feature: 1183/1500\n",
      "Extracting feature: 1184/1500\n",
      "Extracting feature: 1185/1500\n",
      "Extracting feature: 1186/1500\n",
      "Extracting feature: 1187/1500\n",
      "Extracting feature: 1188/1500\n",
      "Extracting feature: 1189/1500\n",
      "Extracting feature: 1190/1500\n",
      "Extracting feature: 1191/1500\n",
      "Extracting feature: 1192/1500\n",
      "Extracting feature: 1193/1500\n",
      "Extracting feature: 1194/1500\n",
      "Extracting feature: 1195/1500\n",
      "Extracting feature: 1196/1500\n",
      "Extracting feature: 1197/1500\n",
      "Extracting feature: 1198/1500\n",
      "Extracting feature: 1199/1500\n",
      "Extracting feature: 1200/1500\n",
      "Extracting feature: 1201/1500\n",
      "Extracting feature: 1202/1500\n",
      "Extracting feature: 1203/1500\n",
      "Extracting feature: 1204/1500\n",
      "Extracting feature: 1205/1500\n",
      "Extracting feature: 1206/1500\n",
      "Extracting feature: 1207/1500\n",
      "Extracting feature: 1208/1500\n",
      "Extracting feature: 1209/1500\n",
      "Extracting feature: 1210/1500\n",
      "Extracting feature: 1211/1500\n",
      "Extracting feature: 1212/1500\n",
      "Extracting feature: 1213/1500\n",
      "Extracting feature: 1214/1500\n",
      "Extracting feature: 1215/1500\n",
      "Extracting feature: 1216/1500\n",
      "Extracting feature: 1217/1500\n",
      "Extracting feature: 1218/1500\n",
      "Extracting feature: 1219/1500\n",
      "Extracting feature: 1220/1500\n",
      "Extracting feature: 1221/1500\n",
      "Extracting feature: 1222/1500\n",
      "Extracting feature: 1223/1500\n",
      "Extracting feature: 1224/1500\n",
      "Extracting feature: 1225/1500\n",
      "Extracting feature: 1226/1500\n",
      "Extracting feature: 1227/1500\n",
      "Extracting feature: 1228/1500\n",
      "Extracting feature: 1229/1500\n",
      "Extracting feature: 1230/1500\n",
      "Extracting feature: 1231/1500\n",
      "Extracting feature: 1232/1500\n",
      "Extracting feature: 1233/1500\n",
      "Extracting feature: 1234/1500\n",
      "Extracting feature: 1235/1500\n",
      "Extracting feature: 1236/1500\n",
      "Extracting feature: 1237/1500\n",
      "Extracting feature: 1238/1500\n",
      "Extracting feature: 1239/1500\n",
      "Extracting feature: 1240/1500\n",
      "Extracting feature: 1241/1500\n",
      "Extracting feature: 1242/1500\n",
      "Extracting feature: 1243/1500\n",
      "Extracting feature: 1244/1500\n",
      "Extracting feature: 1245/1500\n",
      "Extracting feature: 1246/1500\n",
      "Extracting feature: 1247/1500\n",
      "Extracting feature: 1248/1500\n",
      "Extracting feature: 1249/1500\n",
      "Extracting feature: 1250/1500\n",
      "Extracting feature: 1251/1500\n",
      "Extracting feature: 1252/1500\n",
      "Extracting feature: 1253/1500\n",
      "Extracting feature: 1254/1500\n",
      "Extracting feature: 1255/1500\n",
      "Extracting feature: 1256/1500\n",
      "Extracting feature: 1257/1500\n",
      "Extracting feature: 1258/1500\n",
      "Extracting feature: 1259/1500\n",
      "Extracting feature: 1260/1500\n",
      "Extracting feature: 1261/1500\n",
      "Extracting feature: 1262/1500\n",
      "Extracting feature: 1263/1500\n",
      "Extracting feature: 1264/1500\n",
      "Extracting feature: 1265/1500\n",
      "Extracting feature: 1266/1500\n",
      "Extracting feature: 1267/1500\n",
      "Extracting feature: 1268/1500\n",
      "Extracting feature: 1269/1500\n",
      "Extracting feature: 1270/1500\n",
      "Extracting feature: 1271/1500\n",
      "Extracting feature: 1272/1500\n",
      "Extracting feature: 1273/1500\n",
      "Extracting feature: 1274/1500\n",
      "Extracting feature: 1275/1500\n",
      "Extracting feature: 1276/1500\n",
      "Extracting feature: 1277/1500\n",
      "Extracting feature: 1278/1500\n",
      "Extracting feature: 1279/1500\n",
      "Extracting feature: 1280/1500\n",
      "Extracting feature: 1281/1500\n",
      "Extracting feature: 1282/1500\n",
      "Extracting feature: 1283/1500\n",
      "Extracting feature: 1284/1500\n",
      "Extracting feature: 1285/1500\n",
      "Extracting feature: 1286/1500\n",
      "Extracting feature: 1287/1500\n",
      "Extracting feature: 1288/1500\n",
      "Extracting feature: 1289/1500\n",
      "Extracting feature: 1290/1500\n",
      "Extracting feature: 1291/1500\n",
      "Extracting feature: 1292/1500\n",
      "Extracting feature: 1293/1500\n",
      "Extracting feature: 1294/1500\n",
      "Extracting feature: 1295/1500\n",
      "Extracting feature: 1296/1500\n",
      "Extracting feature: 1297/1500\n",
      "Extracting feature: 1298/1500\n",
      "Extracting feature: 1299/1500\n",
      "Extracting feature: 1300/1500\n",
      "Extracting feature: 1301/1500\n",
      "Extracting feature: 1302/1500\n",
      "Extracting feature: 1303/1500\n",
      "Extracting feature: 1304/1500\n",
      "Extracting feature: 1305/1500\n",
      "Extracting feature: 1306/1500\n",
      "Extracting feature: 1307/1500\n",
      "Extracting feature: 1308/1500\n",
      "Extracting feature: 1309/1500\n",
      "Extracting feature: 1310/1500\n",
      "Extracting feature: 1311/1500\n",
      "Extracting feature: 1312/1500\n",
      "Extracting feature: 1313/1500\n",
      "Extracting feature: 1314/1500\n",
      "Extracting feature: 1315/1500\n",
      "Extracting feature: 1316/1500\n",
      "Extracting feature: 1317/1500\n",
      "Extracting feature: 1318/1500\n",
      "Extracting feature: 1319/1500\n",
      "Extracting feature: 1320/1500\n",
      "Extracting feature: 1321/1500\n",
      "Extracting feature: 1322/1500\n",
      "Extracting feature: 1323/1500\n",
      "Extracting feature: 1324/1500\n",
      "Extracting feature: 1325/1500\n",
      "Extracting feature: 1326/1500\n",
      "Extracting feature: 1327/1500\n",
      "Extracting feature: 1328/1500\n",
      "Extracting feature: 1329/1500\n",
      "Extracting feature: 1330/1500\n",
      "Extracting feature: 1331/1500\n",
      "Extracting feature: 1332/1500\n",
      "Extracting feature: 1333/1500\n",
      "Extracting feature: 1334/1500\n",
      "Extracting feature: 1335/1500\n",
      "Extracting feature: 1336/1500\n",
      "Extracting feature: 1337/1500\n",
      "Extracting feature: 1338/1500\n",
      "Extracting feature: 1339/1500\n",
      "Extracting feature: 1340/1500\n",
      "Extracting feature: 1341/1500\n",
      "Extracting feature: 1342/1500\n",
      "Extracting feature: 1343/1500\n",
      "Extracting feature: 1344/1500\n",
      "Extracting feature: 1345/1500\n",
      "Extracting feature: 1346/1500\n",
      "Extracting feature: 1347/1500\n",
      "Extracting feature: 1348/1500\n",
      "Extracting feature: 1349/1500\n",
      "Extracting feature: 1350/1500\n",
      "Extracting feature: 1351/1500\n",
      "Extracting feature: 1352/1500\n",
      "Extracting feature: 1353/1500\n",
      "Extracting feature: 1354/1500\n",
      "Extracting feature: 1355/1500\n",
      "Extracting feature: 1356/1500\n",
      "Extracting feature: 1357/1500\n",
      "Extracting feature: 1358/1500\n",
      "Extracting feature: 1359/1500\n",
      "Extracting feature: 1360/1500\n",
      "Extracting feature: 1361/1500\n",
      "Extracting feature: 1362/1500\n",
      "Extracting feature: 1363/1500\n",
      "Extracting feature: 1364/1500\n",
      "Extracting feature: 1365/1500\n",
      "Extracting feature: 1366/1500\n",
      "Extracting feature: 1367/1500\n",
      "Extracting feature: 1368/1500\n",
      "Extracting feature: 1369/1500\n",
      "Extracting feature: 1370/1500\n",
      "Extracting feature: 1371/1500\n",
      "Extracting feature: 1372/1500\n",
      "Extracting feature: 1373/1500\n",
      "Extracting feature: 1374/1500\n",
      "Extracting feature: 1375/1500\n",
      "Extracting feature: 1376/1500\n",
      "Extracting feature: 1377/1500\n",
      "Extracting feature: 1378/1500\n",
      "Extracting feature: 1379/1500\n",
      "Extracting feature: 1380/1500\n",
      "Extracting feature: 1381/1500\n",
      "Extracting feature: 1382/1500\n",
      "Extracting feature: 1383/1500\n",
      "Extracting feature: 1384/1500\n",
      "Extracting feature: 1385/1500\n",
      "Extracting feature: 1386/1500\n",
      "Extracting feature: 1387/1500\n",
      "Extracting feature: 1388/1500\n",
      "Extracting feature: 1389/1500\n",
      "Extracting feature: 1390/1500\n",
      "Extracting feature: 1391/1500\n",
      "Extracting feature: 1392/1500\n",
      "Extracting feature: 1393/1500\n",
      "Extracting feature: 1394/1500\n",
      "Extracting feature: 1395/1500\n",
      "Extracting feature: 1396/1500\n",
      "Extracting feature: 1397/1500\n",
      "Extracting feature: 1398/1500\n",
      "Extracting feature: 1399/1500\n",
      "Extracting feature: 1400/1500\n",
      "Extracting feature: 1401/1500\n",
      "Extracting feature: 1402/1500\n",
      "Extracting feature: 1403/1500\n",
      "Extracting feature: 1404/1500\n",
      "Extracting feature: 1405/1500\n",
      "Extracting feature: 1406/1500\n",
      "Extracting feature: 1407/1500\n",
      "Extracting feature: 1408/1500\n",
      "Extracting feature: 1409/1500\n",
      "Extracting feature: 1410/1500\n",
      "Extracting feature: 1411/1500\n",
      "Extracting feature: 1412/1500\n",
      "Extracting feature: 1413/1500\n",
      "Extracting feature: 1414/1500\n",
      "Extracting feature: 1415/1500\n",
      "Extracting feature: 1416/1500\n",
      "Extracting feature: 1417/1500\n",
      "Extracting feature: 1418/1500\n",
      "Extracting feature: 1419/1500\n",
      "Extracting feature: 1420/1500\n",
      "Extracting feature: 1421/1500\n",
      "Extracting feature: 1422/1500\n",
      "Extracting feature: 1423/1500\n",
      "Extracting feature: 1424/1500\n",
      "Extracting feature: 1425/1500\n",
      "Extracting feature: 1426/1500\n",
      "Extracting feature: 1427/1500\n",
      "Extracting feature: 1428/1500\n",
      "Extracting feature: 1429/1500\n",
      "Extracting feature: 1430/1500\n",
      "Extracting feature: 1431/1500\n",
      "Extracting feature: 1432/1500\n",
      "Extracting feature: 1433/1500\n",
      "Extracting feature: 1434/1500\n",
      "Extracting feature: 1435/1500\n",
      "Extracting feature: 1436/1500\n",
      "Extracting feature: 1437/1500\n",
      "Extracting feature: 1438/1500\n",
      "Extracting feature: 1439/1500\n",
      "Extracting feature: 1440/1500\n",
      "Extracting feature: 1441/1500\n",
      "Extracting feature: 1442/1500\n",
      "Extracting feature: 1443/1500\n",
      "Extracting feature: 1444/1500\n",
      "Extracting feature: 1445/1500\n",
      "Extracting feature: 1446/1500\n",
      "Extracting feature: 1447/1500\n",
      "Extracting feature: 1448/1500\n",
      "Extracting feature: 1449/1500\n",
      "Extracting feature: 1450/1500\n",
      "Extracting feature: 1451/1500\n",
      "Extracting feature: 1452/1500\n",
      "Extracting feature: 1453/1500\n",
      "Extracting feature: 1454/1500\n",
      "Extracting feature: 1455/1500\n",
      "Extracting feature: 1456/1500\n",
      "Extracting feature: 1457/1500\n",
      "Extracting feature: 1458/1500\n",
      "Extracting feature: 1459/1500\n",
      "Extracting feature: 1460/1500\n",
      "Extracting feature: 1461/1500\n",
      "Extracting feature: 1462/1500\n",
      "Extracting feature: 1463/1500\n",
      "Extracting feature: 1464/1500\n",
      "Extracting feature: 1465/1500\n",
      "Extracting feature: 1466/1500\n",
      "Extracting feature: 1467/1500\n",
      "Extracting feature: 1468/1500\n",
      "Extracting feature: 1469/1500\n",
      "Extracting feature: 1470/1500\n",
      "Extracting feature: 1471/1500\n",
      "Extracting feature: 1472/1500\n",
      "Extracting feature: 1473/1500\n",
      "Extracting feature: 1474/1500\n",
      "Extracting feature: 1475/1500\n",
      "Extracting feature: 1476/1500\n",
      "Extracting feature: 1477/1500\n",
      "Extracting feature: 1478/1500\n",
      "Extracting feature: 1479/1500\n",
      "Extracting feature: 1480/1500\n",
      "Extracting feature: 1481/1500\n",
      "Extracting feature: 1482/1500\n",
      "Extracting feature: 1483/1500\n",
      "Extracting feature: 1484/1500\n",
      "Extracting feature: 1485/1500\n",
      "Extracting feature: 1486/1500\n",
      "Extracting feature: 1487/1500\n",
      "Extracting feature: 1488/1500\n",
      "Extracting feature: 1489/1500\n",
      "Extracting feature: 1490/1500\n",
      "Extracting feature: 1491/1500\n",
      "Extracting feature: 1492/1500\n",
      "Extracting feature: 1493/1500\n",
      "Extracting feature: 1494/1500\n",
      "Extracting feature: 1495/1500\n",
      "Extracting feature: 1496/1500\n",
      "Extracting feature: 1497/1500\n",
      "Extracting feature: 1498/1500\n",
      "Extracting feature: 1499/1500\n",
      "(1500, 25088)\n",
      "Extracting feature: 0/500\n",
      "Extracting feature: 1/500\n",
      "Extracting feature: 2/500\n",
      "Extracting feature: 3/500\n",
      "Extracting feature: 4/500\n",
      "Extracting feature: 5/500\n",
      "Extracting feature: 6/500\n",
      "Extracting feature: 7/500\n",
      "Extracting feature: 8/500\n",
      "Extracting feature: 9/500\n",
      "Extracting feature: 10/500\n",
      "Extracting feature: 11/500\n",
      "Extracting feature: 12/500\n",
      "Extracting feature: 13/500\n",
      "Extracting feature: 14/500\n",
      "Extracting feature: 15/500\n",
      "Extracting feature: 16/500\n",
      "Extracting feature: 17/500\n",
      "Extracting feature: 18/500\n",
      "Extracting feature: 19/500\n",
      "Extracting feature: 20/500\n",
      "Extracting feature: 21/500\n",
      "Extracting feature: 22/500\n",
      "Extracting feature: 23/500\n",
      "Extracting feature: 24/500\n",
      "Extracting feature: 25/500\n",
      "Extracting feature: 26/500\n",
      "Extracting feature: 27/500\n",
      "Extracting feature: 28/500\n",
      "Extracting feature: 29/500\n",
      "Extracting feature: 30/500\n",
      "Extracting feature: 31/500\n",
      "Extracting feature: 32/500\n",
      "Extracting feature: 33/500\n",
      "Extracting feature: 34/500\n",
      "Extracting feature: 35/500\n",
      "Extracting feature: 36/500\n",
      "Extracting feature: 37/500\n",
      "Extracting feature: 38/500\n",
      "Extracting feature: 39/500\n",
      "Extracting feature: 40/500\n",
      "Extracting feature: 41/500\n",
      "Extracting feature: 42/500\n",
      "Extracting feature: 43/500\n",
      "Extracting feature: 44/500\n",
      "Extracting feature: 45/500\n",
      "Extracting feature: 46/500\n",
      "Extracting feature: 47/500\n",
      "Extracting feature: 48/500\n",
      "Extracting feature: 49/500\n",
      "Extracting feature: 50/500\n",
      "Extracting feature: 51/500\n",
      "Extracting feature: 52/500\n",
      "Extracting feature: 53/500\n",
      "Extracting feature: 54/500\n",
      "Extracting feature: 55/500\n",
      "Extracting feature: 56/500\n",
      "Extracting feature: 57/500\n",
      "Extracting feature: 58/500\n",
      "Extracting feature: 59/500\n",
      "Extracting feature: 60/500\n",
      "Extracting feature: 61/500\n",
      "Extracting feature: 62/500\n",
      "Extracting feature: 63/500\n",
      "Extracting feature: 64/500\n",
      "Extracting feature: 65/500\n",
      "Extracting feature: 66/500\n",
      "Extracting feature: 67/500\n",
      "Extracting feature: 68/500\n",
      "Extracting feature: 69/500\n",
      "Extracting feature: 70/500\n",
      "Extracting feature: 71/500\n",
      "Extracting feature: 72/500\n",
      "Extracting feature: 73/500\n",
      "Extracting feature: 74/500\n",
      "Extracting feature: 75/500\n",
      "Extracting feature: 76/500\n",
      "Extracting feature: 77/500\n",
      "Extracting feature: 78/500\n",
      "Extracting feature: 79/500\n",
      "Extracting feature: 80/500\n",
      "Extracting feature: 81/500\n",
      "Extracting feature: 82/500\n",
      "Extracting feature: 83/500\n",
      "Extracting feature: 84/500\n",
      "Extracting feature: 85/500\n",
      "Extracting feature: 86/500\n",
      "Extracting feature: 87/500\n",
      "Extracting feature: 88/500\n",
      "Extracting feature: 89/500\n",
      "Extracting feature: 90/500\n",
      "Extracting feature: 91/500\n",
      "Extracting feature: 92/500\n",
      "Extracting feature: 93/500\n",
      "Extracting feature: 94/500\n",
      "Extracting feature: 95/500\n",
      "Extracting feature: 96/500\n",
      "Extracting feature: 97/500\n",
      "Extracting feature: 98/500\n",
      "Extracting feature: 99/500\n",
      "Extracting feature: 100/500\n",
      "Extracting feature: 101/500\n",
      "Extracting feature: 102/500\n",
      "Extracting feature: 103/500\n",
      "Extracting feature: 104/500\n",
      "Extracting feature: 105/500\n",
      "Extracting feature: 106/500\n",
      "Extracting feature: 107/500\n",
      "Extracting feature: 108/500\n",
      "Extracting feature: 109/500\n",
      "Extracting feature: 110/500\n",
      "Extracting feature: 111/500\n",
      "Extracting feature: 112/500\n",
      "Extracting feature: 113/500\n",
      "Extracting feature: 114/500\n",
      "Extracting feature: 115/500\n",
      "Extracting feature: 116/500\n",
      "Extracting feature: 117/500\n",
      "Extracting feature: 118/500\n",
      "Extracting feature: 119/500\n",
      "Extracting feature: 120/500\n",
      "Extracting feature: 121/500\n",
      "Extracting feature: 122/500\n",
      "Extracting feature: 123/500\n",
      "Extracting feature: 124/500\n",
      "Extracting feature: 125/500\n",
      "Extracting feature: 126/500\n",
      "Extracting feature: 127/500\n",
      "Extracting feature: 128/500\n",
      "Extracting feature: 129/500\n",
      "Extracting feature: 130/500\n",
      "Extracting feature: 131/500\n",
      "Extracting feature: 132/500\n",
      "Extracting feature: 133/500\n",
      "Extracting feature: 134/500\n",
      "Extracting feature: 135/500\n",
      "Extracting feature: 136/500\n",
      "Extracting feature: 137/500\n",
      "Extracting feature: 138/500\n",
      "Extracting feature: 139/500\n",
      "Extracting feature: 140/500\n",
      "Extracting feature: 141/500\n",
      "Extracting feature: 142/500\n",
      "Extracting feature: 143/500\n",
      "Extracting feature: 144/500\n",
      "Extracting feature: 145/500\n",
      "Extracting feature: 146/500\n",
      "Extracting feature: 147/500\n",
      "Extracting feature: 148/500\n",
      "Extracting feature: 149/500\n",
      "Extracting feature: 150/500\n",
      "Extracting feature: 151/500\n",
      "Extracting feature: 152/500\n",
      "Extracting feature: 153/500\n",
      "Extracting feature: 154/500\n",
      "Extracting feature: 155/500\n",
      "Extracting feature: 156/500\n",
      "Extracting feature: 157/500\n",
      "Extracting feature: 158/500\n",
      "Extracting feature: 159/500\n",
      "Extracting feature: 160/500\n",
      "Extracting feature: 161/500\n",
      "Extracting feature: 162/500\n",
      "Extracting feature: 163/500\n",
      "Extracting feature: 164/500\n",
      "Extracting feature: 165/500\n",
      "Extracting feature: 166/500\n",
      "Extracting feature: 167/500\n",
      "Extracting feature: 168/500\n",
      "Extracting feature: 169/500\n",
      "Extracting feature: 170/500\n",
      "Extracting feature: 171/500\n",
      "Extracting feature: 172/500\n",
      "Extracting feature: 173/500\n",
      "Extracting feature: 174/500\n",
      "Extracting feature: 175/500\n",
      "Extracting feature: 176/500\n",
      "Extracting feature: 177/500\n",
      "Extracting feature: 178/500\n",
      "Extracting feature: 179/500\n",
      "Extracting feature: 180/500\n",
      "Extracting feature: 181/500\n",
      "Extracting feature: 182/500\n",
      "Extracting feature: 183/500\n",
      "Extracting feature: 184/500\n",
      "Extracting feature: 185/500\n",
      "Extracting feature: 186/500\n",
      "Extracting feature: 187/500\n",
      "Extracting feature: 188/500\n",
      "Extracting feature: 189/500\n",
      "Extracting feature: 190/500\n",
      "Extracting feature: 191/500\n",
      "Extracting feature: 192/500\n",
      "Extracting feature: 193/500\n",
      "Extracting feature: 194/500\n",
      "Extracting feature: 195/500\n",
      "Extracting feature: 196/500\n",
      "Extracting feature: 197/500\n",
      "Extracting feature: 198/500\n",
      "Extracting feature: 199/500\n",
      "Extracting feature: 200/500\n",
      "Extracting feature: 201/500\n",
      "Extracting feature: 202/500\n",
      "Extracting feature: 203/500\n",
      "Extracting feature: 204/500\n",
      "Extracting feature: 205/500\n",
      "Extracting feature: 206/500\n",
      "Extracting feature: 207/500\n",
      "Extracting feature: 208/500\n",
      "Extracting feature: 209/500\n",
      "Extracting feature: 210/500\n",
      "Extracting feature: 211/500\n",
      "Extracting feature: 212/500\n",
      "Extracting feature: 213/500\n",
      "Extracting feature: 214/500\n",
      "Extracting feature: 215/500\n",
      "Extracting feature: 216/500\n",
      "Extracting feature: 217/500\n",
      "Extracting feature: 218/500\n",
      "Extracting feature: 219/500\n",
      "Extracting feature: 220/500\n",
      "Extracting feature: 221/500\n",
      "Extracting feature: 222/500\n",
      "Extracting feature: 223/500\n",
      "Extracting feature: 224/500\n",
      "Extracting feature: 225/500\n",
      "Extracting feature: 226/500\n",
      "Extracting feature: 227/500\n",
      "Extracting feature: 228/500\n",
      "Extracting feature: 229/500\n",
      "Extracting feature: 230/500\n",
      "Extracting feature: 231/500\n",
      "Extracting feature: 232/500\n",
      "Extracting feature: 233/500\n",
      "Extracting feature: 234/500\n",
      "Extracting feature: 235/500\n",
      "Extracting feature: 236/500\n",
      "Extracting feature: 237/500\n",
      "Extracting feature: 238/500\n",
      "Extracting feature: 239/500\n",
      "Extracting feature: 240/500\n",
      "Extracting feature: 241/500\n",
      "Extracting feature: 242/500\n",
      "Extracting feature: 243/500\n",
      "Extracting feature: 244/500\n",
      "Extracting feature: 245/500\n",
      "Extracting feature: 246/500\n",
      "Extracting feature: 247/500\n",
      "Extracting feature: 248/500\n",
      "Extracting feature: 249/500\n",
      "Extracting feature: 250/500\n",
      "Extracting feature: 251/500\n",
      "Extracting feature: 252/500\n",
      "Extracting feature: 253/500\n",
      "Extracting feature: 254/500\n",
      "Extracting feature: 255/500\n",
      "Extracting feature: 256/500\n",
      "Extracting feature: 257/500\n",
      "Extracting feature: 258/500\n",
      "Extracting feature: 259/500\n",
      "Extracting feature: 260/500\n",
      "Extracting feature: 261/500\n",
      "Extracting feature: 262/500\n",
      "Extracting feature: 263/500\n",
      "Extracting feature: 264/500\n",
      "Extracting feature: 265/500\n",
      "Extracting feature: 266/500\n",
      "Extracting feature: 267/500\n",
      "Extracting feature: 268/500\n",
      "Extracting feature: 269/500\n",
      "Extracting feature: 270/500\n",
      "Extracting feature: 271/500\n",
      "Extracting feature: 272/500\n",
      "Extracting feature: 273/500\n",
      "Extracting feature: 274/500\n",
      "Extracting feature: 275/500\n",
      "Extracting feature: 276/500\n",
      "Extracting feature: 277/500\n",
      "Extracting feature: 278/500\n",
      "Extracting feature: 279/500\n",
      "Extracting feature: 280/500\n",
      "Extracting feature: 281/500\n",
      "Extracting feature: 282/500\n",
      "Extracting feature: 283/500\n",
      "Extracting feature: 284/500\n",
      "Extracting feature: 285/500\n",
      "Extracting feature: 286/500\n",
      "Extracting feature: 287/500\n",
      "Extracting feature: 288/500\n",
      "Extracting feature: 289/500\n",
      "Extracting feature: 290/500\n",
      "Extracting feature: 291/500\n",
      "Extracting feature: 292/500\n",
      "Extracting feature: 293/500\n",
      "Extracting feature: 294/500\n",
      "Extracting feature: 295/500\n",
      "Extracting feature: 296/500\n",
      "Extracting feature: 297/500\n",
      "Extracting feature: 298/500\n",
      "Extracting feature: 299/500\n",
      "Extracting feature: 300/500\n",
      "Extracting feature: 301/500\n",
      "Extracting feature: 302/500\n",
      "Extracting feature: 303/500\n",
      "Extracting feature: 304/500\n",
      "Extracting feature: 305/500\n",
      "Extracting feature: 306/500\n",
      "Extracting feature: 307/500\n",
      "Extracting feature: 308/500\n",
      "Extracting feature: 309/500\n",
      "Extracting feature: 310/500\n",
      "Extracting feature: 311/500\n",
      "Extracting feature: 312/500\n",
      "Extracting feature: 313/500\n",
      "Extracting feature: 314/500\n",
      "Extracting feature: 315/500\n",
      "Extracting feature: 316/500\n",
      "Extracting feature: 317/500\n",
      "Extracting feature: 318/500\n",
      "Extracting feature: 319/500\n",
      "Extracting feature: 320/500\n",
      "Extracting feature: 321/500\n",
      "Extracting feature: 322/500\n",
      "Extracting feature: 323/500\n",
      "Extracting feature: 324/500\n",
      "Extracting feature: 325/500\n",
      "Extracting feature: 326/500\n",
      "Extracting feature: 327/500\n",
      "Extracting feature: 328/500\n",
      "Extracting feature: 329/500\n",
      "Extracting feature: 330/500\n",
      "Extracting feature: 331/500\n",
      "Extracting feature: 332/500\n",
      "Extracting feature: 333/500\n",
      "Extracting feature: 334/500\n",
      "Extracting feature: 335/500\n",
      "Extracting feature: 336/500\n",
      "Extracting feature: 337/500\n",
      "Extracting feature: 338/500\n",
      "Extracting feature: 339/500\n",
      "Extracting feature: 340/500\n",
      "Extracting feature: 341/500\n",
      "Extracting feature: 342/500\n",
      "Extracting feature: 343/500\n",
      "Extracting feature: 344/500\n",
      "Extracting feature: 345/500\n",
      "Extracting feature: 346/500\n",
      "Extracting feature: 347/500\n",
      "Extracting feature: 348/500\n",
      "Extracting feature: 349/500\n",
      "Extracting feature: 350/500\n",
      "Extracting feature: 351/500\n",
      "Extracting feature: 352/500\n",
      "Extracting feature: 353/500\n",
      "Extracting feature: 354/500\n",
      "Extracting feature: 355/500\n",
      "Extracting feature: 356/500\n",
      "Extracting feature: 357/500\n",
      "Extracting feature: 358/500\n",
      "Extracting feature: 359/500\n",
      "Extracting feature: 360/500\n",
      "Extracting feature: 361/500\n",
      "Extracting feature: 362/500\n",
      "Extracting feature: 363/500\n",
      "Extracting feature: 364/500\n",
      "Extracting feature: 365/500\n",
      "Extracting feature: 366/500\n",
      "Extracting feature: 367/500\n",
      "Extracting feature: 368/500\n",
      "Extracting feature: 369/500\n",
      "Extracting feature: 370/500\n",
      "Extracting feature: 371/500\n",
      "Extracting feature: 372/500\n",
      "Extracting feature: 373/500\n",
      "Extracting feature: 374/500\n",
      "Extracting feature: 375/500\n",
      "Extracting feature: 376/500\n",
      "Extracting feature: 377/500\n",
      "Extracting feature: 378/500\n",
      "Extracting feature: 379/500\n",
      "Extracting feature: 380/500\n",
      "Extracting feature: 381/500\n",
      "Extracting feature: 382/500\n",
      "Extracting feature: 383/500\n",
      "Extracting feature: 384/500\n",
      "Extracting feature: 385/500\n",
      "Extracting feature: 386/500\n",
      "Extracting feature: 387/500\n",
      "Extracting feature: 388/500\n",
      "Extracting feature: 389/500\n",
      "Extracting feature: 390/500\n",
      "Extracting feature: 391/500\n",
      "Extracting feature: 392/500\n",
      "Extracting feature: 393/500\n",
      "Extracting feature: 394/500\n",
      "Extracting feature: 395/500\n",
      "Extracting feature: 396/500\n",
      "Extracting feature: 397/500\n",
      "Extracting feature: 398/500\n",
      "Extracting feature: 399/500\n",
      "Extracting feature: 400/500\n",
      "Extracting feature: 401/500\n",
      "Extracting feature: 402/500\n",
      "Extracting feature: 403/500\n",
      "Extracting feature: 404/500\n",
      "Extracting feature: 405/500\n",
      "Extracting feature: 406/500\n",
      "Extracting feature: 407/500\n",
      "Extracting feature: 408/500\n",
      "Extracting feature: 409/500\n",
      "Extracting feature: 410/500\n",
      "Extracting feature: 411/500\n",
      "Extracting feature: 412/500\n",
      "Extracting feature: 413/500\n",
      "Extracting feature: 414/500\n",
      "Extracting feature: 415/500\n",
      "Extracting feature: 416/500\n",
      "Extracting feature: 417/500\n",
      "Extracting feature: 418/500\n",
      "Extracting feature: 419/500\n",
      "Extracting feature: 420/500\n",
      "Extracting feature: 421/500\n",
      "Extracting feature: 422/500\n",
      "Extracting feature: 423/500\n",
      "Extracting feature: 424/500\n",
      "Extracting feature: 425/500\n",
      "Extracting feature: 426/500\n",
      "Extracting feature: 427/500\n",
      "Extracting feature: 428/500\n",
      "Extracting feature: 429/500\n",
      "Extracting feature: 430/500\n",
      "Extracting feature: 431/500\n",
      "Extracting feature: 432/500\n",
      "Extracting feature: 433/500\n",
      "Extracting feature: 434/500\n",
      "Extracting feature: 435/500\n",
      "Extracting feature: 436/500\n",
      "Extracting feature: 437/500\n",
      "Extracting feature: 438/500\n",
      "Extracting feature: 439/500\n",
      "Extracting feature: 440/500\n",
      "Extracting feature: 441/500\n",
      "Extracting feature: 442/500\n",
      "Extracting feature: 443/500\n",
      "Extracting feature: 444/500\n",
      "Extracting feature: 445/500\n",
      "Extracting feature: 446/500\n",
      "Extracting feature: 447/500\n",
      "Extracting feature: 448/500\n",
      "Extracting feature: 449/500\n",
      "Extracting feature: 450/500\n",
      "Extracting feature: 451/500\n",
      "Extracting feature: 452/500\n",
      "Extracting feature: 453/500\n",
      "Extracting feature: 454/500\n",
      "Extracting feature: 455/500\n",
      "Extracting feature: 456/500\n",
      "Extracting feature: 457/500\n",
      "Extracting feature: 458/500\n",
      "Extracting feature: 459/500\n",
      "Extracting feature: 460/500\n",
      "Extracting feature: 461/500\n",
      "Extracting feature: 462/500\n",
      "Extracting feature: 463/500\n",
      "Extracting feature: 464/500\n",
      "Extracting feature: 465/500\n",
      "Extracting feature: 466/500\n",
      "Extracting feature: 467/500\n",
      "Extracting feature: 468/500\n",
      "Extracting feature: 469/500\n",
      "Extracting feature: 470/500\n",
      "Extracting feature: 471/500\n",
      "Extracting feature: 472/500\n",
      "Extracting feature: 473/500\n",
      "Extracting feature: 474/500\n",
      "Extracting feature: 475/500\n",
      "Extracting feature: 476/500\n",
      "Extracting feature: 477/500\n",
      "Extracting feature: 478/500\n",
      "Extracting feature: 479/500\n",
      "Extracting feature: 480/500\n",
      "Extracting feature: 481/500\n",
      "Extracting feature: 482/500\n",
      "Extracting feature: 483/500\n",
      "Extracting feature: 484/500\n",
      "Extracting feature: 485/500\n",
      "Extracting feature: 486/500\n",
      "Extracting feature: 487/500\n",
      "Extracting feature: 488/500\n",
      "Extracting feature: 489/500\n",
      "Extracting feature: 490/500\n",
      "Extracting feature: 491/500\n",
      "Extracting feature: 492/500\n",
      "Extracting feature: 493/500\n",
      "Extracting feature: 494/500\n",
      "Extracting feature: 495/500\n",
      "Extracting feature: 496/500\n",
      "Extracting feature: 497/500\n",
      "Extracting feature: 498/500\n",
      "Extracting feature: 499/500\n",
      "(500, 25088)\n"
     ]
    }
   ],
   "source": [
    "normalization_std = [0.229, 0.224, 0.225]\n",
    "normalization_mean = [0.485, 0.456, 0.406]\n",
    "\n",
    "loader = transforms.Compose(\n",
    "    [\n",
    "        # transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=normalization_mean, std=normalization_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "vgg_out = {\"train\": [], \"valid\": []}\n",
    "\n",
    "# Initialize the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.vgg16(weights=models.VGG16_Weights.DEFAULT).features.to(device)\n",
    "\n",
    "for img_type in dataset.keys():\n",
    "    vgg_out[img_type] = []\n",
    "\n",
    "    for image_idx in range(dataset[img_type][\"data\"].shape[0]):\n",
    "        loaded_image = (\n",
    "            loader(dataset[img_type][\"data\"][image_idx, :]).unsqueeze(0).to(device)\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            res = model(loaded_image)\n",
    "        features = res.data.detach().cpu().numpy().flatten()\n",
    "        print(f\"Extracting feature: {image_idx}/{dataset[img_type]['data'].shape[0]}\")\n",
    "\n",
    "        vgg_out[img_type].append(features)\n",
    "\n",
    "    vgg_out[img_type] = np.asarray(vgg_out[img_type])\n",
    "    print(vgg_out[img_type].shape)\n",
    "\n",
    "pickle.dump(vgg_out, open(\".pkl/vgg_out.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each method is tested with a set of numer of components\n",
    "n_components_to_test = {\n",
    "    \"PCA\": [3, 10, 50, 100, 200, 500, 1200],\n",
    "    \"LDA\": [3, 5, 7, 9],\n",
    "    \"TSNE\": [2, 3],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PCA] Extracting features (# components:3)\n",
      "[0.02996423 0.02048971 0.01742603]\n",
      "[PCA] Extracting features (# components:10)\n",
      "[0.02996422 0.02048968 0.01742605 0.01123542 0.01054162 0.00948114\n",
      " 0.008656   0.00766105 0.00714866 0.00691733]\n",
      "[PCA] Extracting features (# components:50)\n",
      "[0.02996423 0.02048969 0.01742603 0.01123543 0.01054164 0.00948118\n",
      " 0.00865612 0.0076617  0.00715026 0.00691878 0.00634067 0.00612115\n",
      " 0.00539468 0.00539097 0.00501659 0.00472771 0.00463642 0.00459523\n",
      " 0.0043562  0.00424079 0.00406343 0.00397978 0.00390117 0.00379479\n",
      " 0.0036678  0.00363544 0.00348592 0.0034434  0.00332897 0.00326923\n",
      " 0.00320907 0.00315311 0.00304729 0.00299434 0.00296574 0.00292028\n",
      " 0.00287376 0.00284058 0.00279697 0.00271531 0.00264048 0.00260975\n",
      " 0.00259773 0.00250833 0.00248171 0.00246514 0.00241889 0.00240694\n",
      " 0.0023717  0.00231239]\n",
      "[PCA] Extracting features (# components:100)\n",
      "[0.02996419 0.02048968 0.01742603 0.01123543 0.01054163 0.00948117\n",
      " 0.00865612 0.00766171 0.00715025 0.00691877 0.00634068 0.00612115\n",
      " 0.00539468 0.00539098 0.00501659 0.00472772 0.00463644 0.00459525\n",
      " 0.00435627 0.00424085 0.00406373 0.00397992 0.00390138 0.00379538\n",
      " 0.00366866 0.00363572 0.00348653 0.00344539 0.00333045 0.00327193\n",
      " 0.00321206 0.00315438 0.00305124 0.00300023 0.00297181 0.00292621\n",
      " 0.0028808  0.00284578 0.00280721 0.00273583 0.00266687 0.00262155\n",
      " 0.00261583 0.00253522 0.00250937 0.00248945 0.00247419 0.00245135\n",
      " 0.00242131 0.00237142 0.00233597 0.00232996 0.00231565 0.00229634\n",
      " 0.00227648 0.0022609  0.00221759 0.00220557 0.00216933 0.00214981\n",
      " 0.00212852 0.00211214 0.00206667 0.00205291 0.00204668 0.00201856\n",
      " 0.00200187 0.00197934 0.00195983 0.00195603 0.00194089 0.0019072\n",
      " 0.00189137 0.00188292 0.00186495 0.00186198 0.00183896 0.00183552\n",
      " 0.00181667 0.00179408 0.00177192 0.00175286 0.00173561 0.0017277\n",
      " 0.00171598 0.0016945  0.00167867 0.00166956 0.00165437 0.0016371\n",
      " 0.0016289  0.00161041 0.00160866 0.00158226 0.00157903 0.00156546\n",
      " 0.00155608 0.00153805 0.00153211 0.00152281]\n",
      "[PCA] Extracting features (# components:200)\n",
      "[0.02996422 0.0204897  0.01742608 0.01123543 0.01054164 0.00948119\n",
      " 0.00865612 0.00766171 0.00715026 0.00691877 0.00634068 0.00612115\n",
      " 0.00539468 0.00539098 0.00501659 0.00472772 0.00463643 0.00459524\n",
      " 0.00435625 0.00424084 0.00406371 0.00397991 0.00390137 0.00379535\n",
      " 0.00366863 0.0036357  0.0034865  0.00344534 0.00333043 0.00327187\n",
      " 0.00321199 0.00315434 0.00305113 0.00300011 0.00297172 0.00292609\n",
      " 0.00288073 0.00284567 0.00280721 0.00273589 0.00266671 0.00262135\n",
      " 0.0026158  0.00253538 0.00250925 0.00248954 0.00247391 0.00245153\n",
      " 0.00242204 0.00237164 0.00233618 0.00232949 0.00231568 0.00229616\n",
      " 0.0022774  0.00226248 0.00221954 0.00220625 0.00217136 0.00215106\n",
      " 0.00213021 0.00211801 0.00206782 0.00205496 0.00204882 0.0020233\n",
      " 0.0020098  0.00198331 0.00197019 0.00196308 0.00194702 0.00190957\n",
      " 0.00189426 0.00188972 0.00187227 0.00186837 0.00185128 0.00184316\n",
      " 0.00182752 0.00180559 0.00178085 0.00177045 0.00174809 0.00174501\n",
      " 0.00173442 0.00171433 0.00169654 0.00168792 0.00168604 0.00167381\n",
      " 0.00166365 0.0016557  0.0016504  0.0016322  0.00162621 0.00160639\n",
      " 0.0015966  0.00158895 0.0015775  0.00156762 0.00155865 0.00154927\n",
      " 0.00154124 0.00153456 0.00151922 0.00151022 0.00150264 0.00149368\n",
      " 0.0014868  0.00147457 0.00147078 0.0014635  0.00145036 0.00144215\n",
      " 0.00143652 0.00142996 0.00142616 0.00141354 0.00140744 0.00139896\n",
      " 0.00139457 0.00138561 0.00137895 0.00137267 0.00136589 0.00136294\n",
      " 0.00135584 0.00134053 0.00133686 0.00133133 0.00132765 0.00131484\n",
      " 0.00131039 0.00130684 0.00130326 0.00129763 0.00129185 0.00128733\n",
      " 0.00128074 0.00127124 0.00126188 0.00125659 0.00125105 0.00124752\n",
      " 0.00123892 0.00123236 0.0012239  0.00121193 0.00120897 0.00119428\n",
      " 0.00119189 0.00118385 0.0011785  0.0011764  0.00117038 0.00116797\n",
      " 0.00116145 0.0011516  0.00114454 0.00114118 0.00113506 0.00112947\n",
      " 0.00112424 0.00112075 0.00111323 0.00110889 0.00109899 0.00109791\n",
      " 0.00109148 0.00108721 0.00107508 0.00107389 0.00107062 0.00106949\n",
      " 0.0010604  0.00105466 0.00105076 0.00104889 0.00104527 0.00104164\n",
      " 0.00103268 0.00102851 0.00102319 0.00101591 0.00100792 0.00100677\n",
      " 0.00099548 0.0009897  0.00098505 0.00098158 0.00097772 0.00097093\n",
      " 0.00096278 0.00095911 0.0009576  0.00095446 0.00095009 0.00093578\n",
      " 0.00093232 0.0009296 ]\n",
      "[PCA] Extracting features (# components:500)\n",
      "[0.0299642  0.02048971 0.01742607 0.01123545 0.01054164 0.00948119\n",
      " 0.00865612 0.00766171 0.00715025 0.00691877 0.00634069 0.00612115\n",
      " 0.00539469 0.00539098 0.00501659 0.00472772 0.00463644 0.00459525\n",
      " 0.00435627 0.00424085 0.00406373 0.00397993 0.00390138 0.00379538\n",
      " 0.00366867 0.00363572 0.00348655 0.0034454  0.00333047 0.00327194\n",
      " 0.00321209 0.00315441 0.00305126 0.0030003  0.00297186 0.00292627\n",
      " 0.00288092 0.00284589 0.00280739 0.00273608 0.00266704 0.00262171\n",
      " 0.00261611 0.00253587 0.00250996 0.00249019 0.00247458 0.00245203\n",
      " 0.00242269 0.00237242 0.00233718 0.00233078 0.00231672 0.00229703\n",
      " 0.00227817 0.00226357 0.00222089 0.00220716 0.00217283 0.00215286\n",
      " 0.00213238 0.00211956 0.00207071 0.00205715 0.00205043 0.00202501\n",
      " 0.00201193 0.001986   0.00197296 0.00196576 0.00195013 0.00191251\n",
      " 0.00189919 0.00189327 0.00187683 0.00187303 0.00185529 0.00184882\n",
      " 0.00183149 0.00180964 0.00178791 0.00177548 0.00175636 0.0017523\n",
      " 0.00174143 0.00172265 0.00170466 0.00169687 0.00169339 0.00168129\n",
      " 0.00167049 0.0016643  0.00165946 0.00164201 0.00163675 0.00161582\n",
      " 0.00160552 0.00159973 0.00158977 0.00158112 0.00157172 0.00156051\n",
      " 0.00155419 0.00154975 0.00153247 0.00152596 0.00151973 0.00151871\n",
      " 0.00149988 0.00149729 0.00148506 0.00147624 0.00146803 0.00146088\n",
      " 0.00145848 0.00144984 0.00144533 0.00143408 0.00142719 0.00142275\n",
      " 0.00141962 0.00141335 0.00140726 0.00139828 0.00139268 0.00138756\n",
      " 0.00137581 0.00137002 0.00136712 0.00136004 0.0013546  0.00134738\n",
      " 0.00134253 0.00133789 0.00133067 0.00132339 0.00132067 0.00131777\n",
      " 0.0013084  0.00130627 0.00129855 0.00129101 0.00128809 0.00127969\n",
      " 0.00127214 0.0012703  0.00126771 0.00125915 0.00124925 0.00124547\n",
      " 0.00124222 0.00123779 0.00122975 0.00122585 0.00121902 0.00121833\n",
      " 0.00121328 0.00121021 0.00120664 0.00120388 0.00119307 0.00118766\n",
      " 0.00118221 0.00118002 0.00117657 0.00117199 0.00116691 0.00116217\n",
      " 0.00115707 0.00115645 0.00115457 0.00114404 0.0011429  0.00113872\n",
      " 0.00113345 0.00112997 0.00112443 0.00112244 0.00111822 0.00111618\n",
      " 0.00111136 0.00110992 0.00110694 0.00110077 0.00109477 0.00109271\n",
      " 0.0010867  0.00108226 0.0010789  0.00107611 0.00107235 0.00106982\n",
      " 0.00106738 0.00106639 0.00106171 0.00105602 0.00105395 0.00104903\n",
      " 0.00104725 0.00104159 0.001038   0.00103712 0.00103321 0.00102899\n",
      " 0.00102802 0.00102472 0.00102106 0.00101832 0.0010164  0.00101351\n",
      " 0.0010094  0.00100531 0.00100347 0.00100094 0.0009968  0.00099503\n",
      " 0.00098981 0.00098629 0.00098303 0.00097847 0.00097508 0.0009714\n",
      " 0.00096999 0.00096718 0.00096336 0.00096043 0.00095828 0.00095414\n",
      " 0.00095249 0.00095049 0.00094694 0.00094499 0.00094216 0.00093954\n",
      " 0.00093617 0.0009336  0.00093266 0.0009287  0.00092601 0.00092376\n",
      " 0.00092054 0.00091963 0.0009185  0.00091473 0.00091227 0.00091103\n",
      " 0.00090955 0.00090757 0.0009045  0.00090122 0.00089839 0.00089673\n",
      " 0.00089528 0.00089273 0.00088988 0.00088811 0.00088385 0.00088186\n",
      " 0.00087859 0.00087815 0.0008733  0.0008684  0.00086634 0.00086572\n",
      " 0.00086233 0.0008611  0.00085866 0.00085687 0.00085405 0.00085207\n",
      " 0.00085071 0.00084774 0.0008448  0.00084418 0.00084214 0.00084014\n",
      " 0.00083931 0.00083465 0.0008338  0.00083195 0.00083131 0.00082909\n",
      " 0.00082647 0.00082504 0.00082244 0.00082102 0.00081903 0.00081776\n",
      " 0.00081592 0.00081156 0.00080927 0.00080712 0.00080449 0.00080309\n",
      " 0.00080004 0.00079925 0.00079812 0.00079489 0.00079321 0.00079022\n",
      " 0.00078763 0.00078687 0.00078438 0.00078206 0.00078012 0.00077904\n",
      " 0.00077624 0.00077562 0.00077369 0.00077135 0.00076994 0.00076571\n",
      " 0.00076523 0.00076295 0.00076238 0.00076168 0.00075772 0.00075468\n",
      " 0.00075436 0.00075344 0.00075284 0.0007521  0.00074761 0.00074707\n",
      " 0.00074532 0.00074151 0.00074009 0.00073837 0.00073608 0.00073508\n",
      " 0.00073404 0.00073347 0.00072912 0.00072767 0.00072647 0.00072395\n",
      " 0.00072152 0.0007207  0.00071945 0.00071817 0.00071643 0.00071454\n",
      " 0.00071316 0.00071214 0.00071055 0.00070792 0.00070607 0.00070542\n",
      " 0.00070301 0.00070218 0.00070038 0.00069974 0.00069624 0.00069532\n",
      " 0.00069333 0.00069154 0.00069089 0.00068975 0.00068897 0.00068751\n",
      " 0.00068356 0.0006831  0.00068221 0.00068088 0.00068019 0.00067905\n",
      " 0.00067714 0.00067291 0.00067143 0.00067038 0.00066984 0.00066716\n",
      " 0.0006659  0.00066529 0.00066374 0.00066171 0.00066004 0.000659\n",
      " 0.00065514 0.00065456 0.00065259 0.00065085 0.00065019 0.00064904\n",
      " 0.00064719 0.00064632 0.00064365 0.0006428  0.00064086 0.00064005\n",
      " 0.00063862 0.00063707 0.00063644 0.00063436 0.00063213 0.00063103\n",
      " 0.00063022 0.0006288  0.00062732 0.00062573 0.00062395 0.00062235\n",
      " 0.00062061 0.00062032 0.00061901 0.00061789 0.00061647 0.00061571\n",
      " 0.00061482 0.00061315 0.00061114 0.00061002 0.00060905 0.00060818\n",
      " 0.00060533 0.00060442 0.00060273 0.00060146 0.00059989 0.00059852\n",
      " 0.00059754 0.00059522 0.00059504 0.00059299 0.00059032 0.00058944\n",
      " 0.0005883  0.0005861  0.0005842  0.00058257 0.00058196 0.00058073\n",
      " 0.00057868 0.00057793 0.00057677 0.0005759  0.00057331 0.00057143\n",
      " 0.00057024 0.00056934 0.00056829 0.00056694 0.00056442 0.00056429\n",
      " 0.00056097 0.00055906 0.0005583  0.00055732 0.00055502 0.00055438\n",
      " 0.00055351 0.00055181 0.00055049 0.0005483  0.00054791 0.00054614\n",
      " 0.00054509 0.00054397 0.00054382 0.00054276 0.0005391  0.00053847\n",
      " 0.00053821 0.00053527 0.00053469 0.00053227 0.0005317  0.0005299\n",
      " 0.0005294  0.00052768 0.0005262  0.00052527 0.00052256 0.00052144\n",
      " 0.00052058 0.00051954 0.00051735 0.00051587 0.0005144  0.00051366\n",
      " 0.00051094 0.00050952 0.00050848 0.00050715 0.00050651 0.00050379\n",
      " 0.00050099 0.00050064 0.00049956 0.00049696 0.00049516 0.00049487\n",
      " 0.00049146 0.00049032 0.0004882  0.0004878  0.00048322 0.00048268\n",
      " 0.00048097 0.00047955]\n",
      "[PCA] Extracting features (# components:1200)\n",
      "[0.02996421 0.0204897  0.01742605 ... 0.00020122 0.00020095 0.00020033]\n",
      "[LDA] Extracting features (# components:3)\n",
      "[LDA] Extracting features (# components:5)\n",
      "[LDA] Extracting features (# components:7)\n",
      "[LDA] Extracting features (# components:9)\n",
      "[t-SNE] Extracting features (# components:2)\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 1500 samples in 0.026s...\n",
      "[t-SNE] Computed neighbors for 1500 samples in 0.120s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1500\n",
      "[t-SNE] Computed conditional probabilities for sample 1500 / 1500\n",
      "[t-SNE] Mean sigma: 0.969018\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 64.580933\n",
      "[t-SNE] KL divergence after 3000 iterations: 0.958048\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 500 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 500 samples in 0.014s...\n",
      "[t-SNE] Computed conditional probabilities for sample 500 / 500\n",
      "[t-SNE] Mean sigma: 1.191398\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 59.112549\n",
      "[t-SNE] KL divergence after 2950 iterations: 0.787229\n",
      "[t-SNE] Extracting features (# components:3)\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 1500 samples in 0.003s...\n",
      "[t-SNE] Computed neighbors for 1500 samples in 0.066s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1500\n",
      "[t-SNE] Computed conditional probabilities for sample 1500 / 1500\n",
      "[t-SNE] Mean sigma: 0.969018\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 64.727936\n",
      "[t-SNE] KL divergence after 2800 iterations: 0.803601\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 500 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 500 samples in 0.013s...\n",
      "[t-SNE] Computed conditional probabilities for sample 500 / 500\n",
      "[t-SNE] Mean sigma: 1.191398\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 59.168900\n",
      "[t-SNE] KL divergence after 900 iterations: 0.637909\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_699b1_row0_col0, #T_699b1_row0_col1, #T_699b1_row0_col2, #T_699b1_row1_col0, #T_699b1_row1_col1, #T_699b1_row1_col2, #T_699b1_row2_col0, #T_699b1_row2_col1, #T_699b1_row2_col2, #T_699b1_row3_col0, #T_699b1_row3_col1, #T_699b1_row3_col2, #T_699b1_row4_col0, #T_699b1_row4_col1, #T_699b1_row4_col2, #T_699b1_row5_col0, #T_699b1_row5_col1, #T_699b1_row5_col2, #T_699b1_row6_col0, #T_699b1_row6_col1, #T_699b1_row6_col2 {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_699b1_row0_col3, #T_699b1_row1_col3, #T_699b1_row2_col3, #T_699b1_row3_col3, #T_699b1_row4_col3, #T_699b1_row5_col3 {\n",
       "  background-color: lightcoral;\n",
       "  color: black;\n",
       "  font-weight: bold;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_699b1_row6_col3 {\n",
       "  background-color: lightgreen;\n",
       "  color: black;\n",
       "  font-weight: bold;\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_699b1\">\n",
       "  <caption>PCA Results</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_699b1_level0_col0\" class=\"col_heading level0 col0\" >METHOD</th>\n",
       "      <th id=\"T_699b1_level0_col1\" class=\"col_heading level0 col1\" ># Components</th>\n",
       "      <th id=\"T_699b1_level0_col2\" class=\"col_heading level0 col2\" >CHANNEL</th>\n",
       "      <th id=\"T_699b1_level0_col3\" class=\"col_heading level0 col3\" >Explained Variance Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_699b1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_699b1_row0_col0\" class=\"data row0 col0\" >PCA</td>\n",
       "      <td id=\"T_699b1_row0_col1\" class=\"data row0 col1\" >3</td>\n",
       "      <td id=\"T_699b1_row0_col2\" class=\"data row0 col2\" >RGB</td>\n",
       "      <td id=\"T_699b1_row0_col3\" class=\"data row0 col3\" >0.067880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_699b1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_699b1_row1_col0\" class=\"data row1 col0\" >PCA</td>\n",
       "      <td id=\"T_699b1_row1_col1\" class=\"data row1 col1\" >10</td>\n",
       "      <td id=\"T_699b1_row1_col2\" class=\"data row1 col2\" >RGB</td>\n",
       "      <td id=\"T_699b1_row1_col3\" class=\"data row1 col3\" >0.129521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_699b1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_699b1_row2_col0\" class=\"data row2 col0\" >PCA</td>\n",
       "      <td id=\"T_699b1_row2_col1\" class=\"data row2 col1\" >50</td>\n",
       "      <td id=\"T_699b1_row2_col2\" class=\"data row2 col2\" >RGB</td>\n",
       "      <td id=\"T_699b1_row2_col3\" class=\"data row2 col3\" >0.271245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_699b1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_699b1_row3_col0\" class=\"data row3 col0\" >PCA</td>\n",
       "      <td id=\"T_699b1_row3_col1\" class=\"data row3 col1\" >100</td>\n",
       "      <td id=\"T_699b1_row3_col2\" class=\"data row3 col2\" >RGB</td>\n",
       "      <td id=\"T_699b1_row3_col3\" class=\"data row3 col3\" >0.365943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_699b1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_699b1_row4_col0\" class=\"data row4 col0\" >PCA</td>\n",
       "      <td id=\"T_699b1_row4_col1\" class=\"data row4 col1\" >200</td>\n",
       "      <td id=\"T_699b1_row4_col2\" class=\"data row4 col2\" >RGB</td>\n",
       "      <td id=\"T_699b1_row4_col3\" class=\"data row4 col3\" >0.488130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_699b1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_699b1_row5_col0\" class=\"data row5 col0\" >PCA</td>\n",
       "      <td id=\"T_699b1_row5_col1\" class=\"data row5 col1\" >500</td>\n",
       "      <td id=\"T_699b1_row5_col2\" class=\"data row5 col2\" >RGB</td>\n",
       "      <td id=\"T_699b1_row5_col3\" class=\"data row5 col3\" >0.709697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_699b1_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_699b1_row6_col0\" class=\"data row6 col0\" >PCA</td>\n",
       "      <td id=\"T_699b1_row6_col1\" class=\"data row6 col1\" >1200</td>\n",
       "      <td id=\"T_699b1_row6_col2\" class=\"data row6 col2\" >RGB</td>\n",
       "      <td id=\"T_699b1_row6_col3\" class=\"data row6 col3\" >0.954115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x79a4d4c9d6f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_aa609_row0_col0, #T_aa609_row0_col1, #T_aa609_row0_col2, #T_aa609_row1_col0, #T_aa609_row1_col1, #T_aa609_row1_col2, #T_aa609_row2_col0, #T_aa609_row2_col1, #T_aa609_row2_col2, #T_aa609_row3_col0, #T_aa609_row3_col1, #T_aa609_row3_col2 {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_aa609_row0_col3, #T_aa609_row1_col3 {\n",
       "  background-color: lightcoral;\n",
       "  color: black;\n",
       "  font-weight: bold;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_aa609_row2_col3, #T_aa609_row3_col3 {\n",
       "  background-color: lightgreen;\n",
       "  color: black;\n",
       "  font-weight: bold;\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_aa609\">\n",
       "  <caption>LDA Results</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_aa609_level0_col0\" class=\"col_heading level0 col0\" >METHOD</th>\n",
       "      <th id=\"T_aa609_level0_col1\" class=\"col_heading level0 col1\" ># Components</th>\n",
       "      <th id=\"T_aa609_level0_col2\" class=\"col_heading level0 col2\" >CHANNEL</th>\n",
       "      <th id=\"T_aa609_level0_col3\" class=\"col_heading level0 col3\" >Explained Variance Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aa609_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_aa609_row0_col0\" class=\"data row0 col0\" >LDA</td>\n",
       "      <td id=\"T_aa609_row0_col1\" class=\"data row0 col1\" >3</td>\n",
       "      <td id=\"T_aa609_row0_col2\" class=\"data row0 col2\" >RGB</td>\n",
       "      <td id=\"T_aa609_row0_col3\" class=\"data row0 col3\" >0.636011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa609_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_aa609_row1_col0\" class=\"data row1 col0\" >LDA</td>\n",
       "      <td id=\"T_aa609_row1_col1\" class=\"data row1 col1\" >5</td>\n",
       "      <td id=\"T_aa609_row1_col2\" class=\"data row1 col2\" >RGB</td>\n",
       "      <td id=\"T_aa609_row1_col3\" class=\"data row1 col3\" >0.795970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa609_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_aa609_row2_col0\" class=\"data row2 col0\" >LDA</td>\n",
       "      <td id=\"T_aa609_row2_col1\" class=\"data row2 col1\" >7</td>\n",
       "      <td id=\"T_aa609_row2_col2\" class=\"data row2 col2\" >RGB</td>\n",
       "      <td id=\"T_aa609_row2_col3\" class=\"data row2 col3\" >0.909774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa609_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_aa609_row3_col0\" class=\"data row3 col0\" >LDA</td>\n",
       "      <td id=\"T_aa609_row3_col1\" class=\"data row3 col1\" >9</td>\n",
       "      <td id=\"T_aa609_row3_col2\" class=\"data row3 col2\" >RGB</td>\n",
       "      <td id=\"T_aa609_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x79a4d4a297e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# preload env\n",
    "vgg_out = pickle.load(open(\".pkl/vgg_out.pkl\", \"rb\"))\n",
    "\n",
    "# Results to compare the methods the number of component changes\n",
    "results_PCA = []\n",
    "results_LDA = []\n",
    "\n",
    "PCAs_instances = {}\n",
    "LDAs_instances = {}\n",
    "TSNEs_instances = {}\n",
    "\n",
    "PCAs_results = {\n",
    "    \"train\": {},\n",
    "    \"valid\": {},\n",
    "}\n",
    "\n",
    "LDAs_results = {\n",
    "    \"train\": {},\n",
    "    \"valid\": {},\n",
    "}\n",
    "\n",
    "TSNEs_results = {\n",
    "    \"train\": {},\n",
    "    \"valid\": {},\n",
    "}\n",
    "\n",
    "for n_components in n_components_to_test[\"PCA\"]:\n",
    "    print(f'[PCA] Extracting features (# components:{n_components})')\n",
    "    \n",
    "    PCAs_instances[n_components] = []\n",
    "\n",
    "    PCAs_results[\"train\"][n_components] = []\n",
    "    PCAs_results[\"valid\"][n_components] = []\n",
    "\n",
    "    PCA_instance = PCA(n_components=n_components)\n",
    "\n",
    "    PCA_instance.fit(vgg_out[\"train\"])\n",
    "\n",
    "    PCAs_results[\"train\"][n_components] = PCA_instance.transform(vgg_out[\"train\"])\n",
    "    PCAs_results[\"valid\"][n_components] = PCA_instance.transform(vgg_out[\"valid\"])\n",
    "\n",
    "    PCAs_instances[n_components] = PCA_instance\n",
    "    \n",
    "    results_PCA.append(\n",
    "        {\n",
    "            \"METHOD\": \"PCA\",\n",
    "            \"# Components\": n_components,\n",
    "            \"CHANNEL\": \"RGB\",\n",
    "            \"Explained Variance Ratio\": np.sum(\n",
    "                PCA_instance.explained_variance_ratio_, axis=0\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "\n",
    "for n_components in n_components_to_test[\"LDA\"]:\n",
    "    print(f'[LDA] Extracting features (# components:{n_components})')\n",
    "    \n",
    "    LDAs_instances[n_components] = []\n",
    "\n",
    "    LDAs_results[\"train\"][n_components] = []\n",
    "    LDAs_results[\"valid\"][n_components] = []\n",
    "\n",
    "    LDA_instance = LinearDiscriminantAnalysis(n_components=n_components)\n",
    "\n",
    "    LDA_instance.fit(vgg_out[\"train\"], dataset[\"train\"][\"labels\"])\n",
    "\n",
    "    LDAs_results[\"train\"][n_components] = LDA_instance.transform(vgg_out[\"train\"])\n",
    "    LDAs_results[\"valid\"][n_components] = LDA_instance.transform(vgg_out[\"valid\"])\n",
    "\n",
    "    LDAs_instances[n_components] = LDA_instance\n",
    "\n",
    "    results_LDA.append(\n",
    "        {\n",
    "            \"METHOD\": \"LDA\",\n",
    "            \"# Components\": n_components,\n",
    "            \"CHANNEL\": \"RGB\",\n",
    "            \"Explained Variance Ratio\": np.sum(\n",
    "                LDA_instance.explained_variance_ratio_, axis=0\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "\n",
    "for n_components in n_components_to_test[\"TSNE\"]:\n",
    "    print(f'[t-SNE] Extracting features (# components:{n_components})')\n",
    "\n",
    "    TSNEs_instances[n_components] = []\n",
    "\n",
    "    TSNEs_results[\"train\"][n_components] = []\n",
    "\n",
    "    TSNE_instance_train = TSNE(n_components=n_components, verbose=1, n_iter=3000)\n",
    "    TSNE_instance_valid = TSNE(n_components=n_components, verbose=1, n_iter=3000)\n",
    "\n",
    "    TSNEs_results[\"train\"][n_components] = TSNE_instance_train.fit_transform(\n",
    "        LDAs_results[\"train\"][7]\n",
    "    )\n",
    "    TSNEs_results[\"valid\"][n_components] = TSNE_instance_valid.fit_transform(\n",
    "        LDAs_results[\"valid\"][7]\n",
    "    )\n",
    "\n",
    "    TSNEs_instances[n_components] = [TSNE_instance_train, TSNE_instance_valid]\n",
    "\n",
    "\n",
    "# Pandas tables\n",
    "df_results_PCA = pd.DataFrame(results_PCA)\n",
    "df_results_LDA = pd.DataFrame(results_LDA)\n",
    "\n",
    "def highlight_cells(val):\n",
    "    color = \"\"\n",
    "    if val > 0.80:\n",
    "        color = \"background-color: lightgreen; color: black; font-weight: bold\"\n",
    "    elif val < 0.80:\n",
    "        color = \"background-color: lightcoral; color: black; font-weight: bold\"\n",
    "    return color\n",
    "\n",
    "# Apply the style\n",
    "df_results_PCA_styled = (\n",
    "    df_results_PCA.style.map(highlight_cells, subset=[\"Explained Variance Ratio\"])\n",
    "    .set_caption(\"PCA Results\")\n",
    "    .set_properties(**{\"text-align\": \"center\"})\n",
    ")\n",
    "\n",
    "df_results_LDA_styled = (\n",
    "    df_results_LDA.style.map(highlight_cells, subset=[\"Explained Variance Ratio\"])\n",
    "    .set_caption(\"LDA Results\")\n",
    "    .set_properties(**{\"text-align\": \"center\"})\n",
    ")\n",
    "\n",
    "\n",
    "pickle.dump(PCAs_results, open(\".pkl/vgg_pca_out.pkl\", \"wb\"))\n",
    "pickle.dump(LDAs_results, open(\".pkl/vgg_lda_out.pkl\", \"wb\"))\n",
    "pickle.dump(TSNEs_results, open(\".pkl/vgg_tsne_out.pkl\", \"wb\"))\n",
    "\n",
    "display(df_results_PCA_styled)\n",
    "display(df_results_LDA_styled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D/3D Data visualization using t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ec8c20f7e50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_out = pickle.load(open(\".pkl/vgg_out.pkl\", \"rb\"))\n",
    " \n",
    "PCAs_results = pickle.load(open(\".pkl/vgg_pca_out.pkl\", \"rb\"))\n",
    "LDAs_results = pickle.load(open(\".pkl/vgg_lda_out.pkl\", \"rb\"))\n",
    "TSNEs_results = pickle.load(open(\".pkl/vgg_tsne_out.pkl\", \"rb\"))\n",
    "\n",
    "# 2D plot\n",
    "plt.ion()\n",
    "plt.show()\n",
    "\n",
    "tSNE_fig_2D = plt.figure()\n",
    "tSNE_3D = tSNE_fig_2D.add_subplot()\n",
    "\n",
    "for i in range(len(dataset[\"train\"][\"unique_labels\"])):\n",
    "    classIdxs = dataset[\"train\"][\"labels\"] == i\n",
    "\n",
    "    tsne_features = TSNEs_results[\"train\"][2][classIdxs, :]\n",
    "\n",
    "    tSNE_3D.set_label(dataset[\"train\"][\"unique_labels\"][i])\n",
    "    tSNE_3D.scatter(\n",
    "        tsne_features[:, 0],\n",
    "        tsne_features[:, 1],\n",
    "        marker=\".\",\n",
    "        label=dataset[\"train\"][\"unique_labels\"][i],\n",
    "    )\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# 3D plot\n",
    "tSNE_fig_3D = plt.figure()\n",
    "tSNE_3D = tSNE_fig_3D.add_subplot(projection=\"3d\")\n",
    "\n",
    "for i in range(len(dataset[\"train\"][\"unique_labels\"])):\n",
    "    classIdxs = dataset[\"train\"][\"labels\"] == i\n",
    "\n",
    "    tsne_features = TSNEs_results[\"train\"][3][classIdxs, :]\n",
    "\n",
    "    tSNE_3D.scatter(\n",
    "        tsne_features[:, 0],\n",
    "        tsne_features[:, 1],\n",
    "        tsne_features[:, 2],\n",
    "        marker=\".\",\n",
    "        label=dataset[\"train\"][\"unique_labels\"][i],\n",
    "    )\n",
    "\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k\\VGG</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>(0.346, 0.616)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>(0.366, 0.592)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>(0.362, 0.574)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>(0.354, 0.63)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>(0.324, 0.648)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55</td>\n",
       "      <td>(0.268, 0.79)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111</td>\n",
       "      <td>(0.242, 0.706)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>251</td>\n",
       "      <td>(0.242, 0.767)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k\\VGG                \n",
       "0      3  (0.346, 0.616)\n",
       "1      5  (0.366, 0.592)\n",
       "2      9  (0.362, 0.574)\n",
       "3     15   (0.354, 0.63)\n",
       "4     21  (0.324, 0.648)\n",
       "5     55   (0.268, 0.79)\n",
       "6    111  (0.242, 0.706)\n",
       "7    251  (0.242, 0.767)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k\\PCA components</th>\n",
       "      <th>3</th>\n",
       "      <th>10</th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>200</th>\n",
       "      <th>500</th>\n",
       "      <th>1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>(0.352, 0.347)</td>\n",
       "      <td>(0.544, 0.552)</td>\n",
       "      <td>(0.676, 0.69)</td>\n",
       "      <td>(0.648, 0.665)</td>\n",
       "      <td>(0.582, 0.631)</td>\n",
       "      <td>(0.5, 0.614)</td>\n",
       "      <td>(0.34, 0.527)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>(0.4, 0.401)</td>\n",
       "      <td>(0.572, 0.584)</td>\n",
       "      <td>(0.69, 0.707)</td>\n",
       "      <td>(0.668, 0.708)</td>\n",
       "      <td>(0.602, 0.679)</td>\n",
       "      <td>(0.472, 0.631)</td>\n",
       "      <td>(0.328, 0.52)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>(0.402, 0.398)</td>\n",
       "      <td>(0.586, 0.596)</td>\n",
       "      <td>(0.688, 0.737)</td>\n",
       "      <td>(0.642, 0.719)</td>\n",
       "      <td>(0.588, 0.691)</td>\n",
       "      <td>(0.458, 0.651)</td>\n",
       "      <td>(0.306, 0.717)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>(0.368, 0.357)</td>\n",
       "      <td>(0.596, 0.608)</td>\n",
       "      <td>(0.698, 0.754)</td>\n",
       "      <td>(0.624, 0.725)</td>\n",
       "      <td>(0.526, 0.693)</td>\n",
       "      <td>(0.394, 0.677)</td>\n",
       "      <td>(0.282, 0.719)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>(0.364, 0.359)</td>\n",
       "      <td>(0.598, 0.61)</td>\n",
       "      <td>(0.67, 0.737)</td>\n",
       "      <td>(0.618, 0.739)</td>\n",
       "      <td>(0.5, 0.714)</td>\n",
       "      <td>(0.37, 0.754)</td>\n",
       "      <td>(0.254, 0.774)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55</td>\n",
       "      <td>(0.378, 0.371)</td>\n",
       "      <td>(0.566, 0.583)</td>\n",
       "      <td>(0.606, 0.745)</td>\n",
       "      <td>(0.496, 0.707)</td>\n",
       "      <td>(0.398, 0.713)</td>\n",
       "      <td>(0.262, 0.757)</td>\n",
       "      <td>(0.212, 0.817)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111</td>\n",
       "      <td>(0.352, 0.357)</td>\n",
       "      <td>(0.512, 0.561)</td>\n",
       "      <td>(0.516, 0.71)</td>\n",
       "      <td>(0.438, 0.695)</td>\n",
       "      <td>(0.342, 0.736)</td>\n",
       "      <td>(0.246, 0.768)</td>\n",
       "      <td>(0.232, 0.643)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>251</td>\n",
       "      <td>(0.328, 0.311)</td>\n",
       "      <td>(0.392, 0.503)</td>\n",
       "      <td>(0.4, 0.661)</td>\n",
       "      <td>(0.356, 0.535)</td>\n",
       "      <td>(0.358, 0.517)</td>\n",
       "      <td>(0.304, 0.544)</td>\n",
       "      <td>(0.316, 0.59)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k\\PCA components               3              10              50  \\\n",
       "0                 3  (0.352, 0.347)  (0.544, 0.552)   (0.676, 0.69)   \n",
       "1                 5    (0.4, 0.401)  (0.572, 0.584)   (0.69, 0.707)   \n",
       "2                 9  (0.402, 0.398)  (0.586, 0.596)  (0.688, 0.737)   \n",
       "3                15  (0.368, 0.357)  (0.596, 0.608)  (0.698, 0.754)   \n",
       "4                21  (0.364, 0.359)   (0.598, 0.61)   (0.67, 0.737)   \n",
       "5                55  (0.378, 0.371)  (0.566, 0.583)  (0.606, 0.745)   \n",
       "6               111  (0.352, 0.357)  (0.512, 0.561)   (0.516, 0.71)   \n",
       "7               251  (0.328, 0.311)  (0.392, 0.503)    (0.4, 0.661)   \n",
       "\n",
       "              100             200             500            1200  \n",
       "0  (0.648, 0.665)  (0.582, 0.631)    (0.5, 0.614)   (0.34, 0.527)  \n",
       "1  (0.668, 0.708)  (0.602, 0.679)  (0.472, 0.631)   (0.328, 0.52)  \n",
       "2  (0.642, 0.719)  (0.588, 0.691)  (0.458, 0.651)  (0.306, 0.717)  \n",
       "3  (0.624, 0.725)  (0.526, 0.693)  (0.394, 0.677)  (0.282, 0.719)  \n",
       "4  (0.618, 0.739)    (0.5, 0.714)   (0.37, 0.754)  (0.254, 0.774)  \n",
       "5  (0.496, 0.707)  (0.398, 0.713)  (0.262, 0.757)  (0.212, 0.817)  \n",
       "6  (0.438, 0.695)  (0.342, 0.736)  (0.246, 0.768)  (0.232, 0.643)  \n",
       "7  (0.356, 0.535)  (0.358, 0.517)  (0.304, 0.544)   (0.316, 0.59)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k\\LDA components</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>(0.514, 0.55)</td>\n",
       "      <td>(0.626, 0.655)</td>\n",
       "      <td>(0.726, 0.73)</td>\n",
       "      <td>(0.748, 0.749)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>(0.536, 0.574)</td>\n",
       "      <td>(0.648, 0.681)</td>\n",
       "      <td>(0.73, 0.736)</td>\n",
       "      <td>(0.754, 0.756)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>(0.532, 0.568)</td>\n",
       "      <td>(0.678, 0.709)</td>\n",
       "      <td>(0.754, 0.762)</td>\n",
       "      <td>(0.784, 0.787)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>(0.526, 0.563)</td>\n",
       "      <td>(0.67, 0.712)</td>\n",
       "      <td>(0.76, 0.77)</td>\n",
       "      <td>(0.78, 0.786)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>(0.536, 0.582)</td>\n",
       "      <td>(0.684, 0.726)</td>\n",
       "      <td>(0.754, 0.767)</td>\n",
       "      <td>(0.778, 0.783)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55</td>\n",
       "      <td>(0.52, 0.579)</td>\n",
       "      <td>(0.672, 0.726)</td>\n",
       "      <td>(0.752, 0.769)</td>\n",
       "      <td>(0.806, 0.81)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111</td>\n",
       "      <td>(0.52, 0.581)</td>\n",
       "      <td>(0.65, 0.71)</td>\n",
       "      <td>(0.752, 0.772)</td>\n",
       "      <td>(0.792, 0.796)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>251</td>\n",
       "      <td>(0.5, 0.569)</td>\n",
       "      <td>(0.604, 0.667)</td>\n",
       "      <td>(0.734, 0.773)</td>\n",
       "      <td>(0.778, 0.794)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k\\LDA components               3               5               7  \\\n",
       "0                 3   (0.514, 0.55)  (0.626, 0.655)   (0.726, 0.73)   \n",
       "1                 5  (0.536, 0.574)  (0.648, 0.681)   (0.73, 0.736)   \n",
       "2                 9  (0.532, 0.568)  (0.678, 0.709)  (0.754, 0.762)   \n",
       "3                15  (0.526, 0.563)   (0.67, 0.712)    (0.76, 0.77)   \n",
       "4                21  (0.536, 0.582)  (0.684, 0.726)  (0.754, 0.767)   \n",
       "5                55   (0.52, 0.579)  (0.672, 0.726)  (0.752, 0.769)   \n",
       "6               111   (0.52, 0.581)    (0.65, 0.71)  (0.752, 0.772)   \n",
       "7               251    (0.5, 0.569)  (0.604, 0.667)  (0.734, 0.773)   \n",
       "\n",
       "                9  \n",
       "0  (0.748, 0.749)  \n",
       "1  (0.754, 0.756)  \n",
       "2  (0.784, 0.787)  \n",
       "3   (0.78, 0.786)  \n",
       "4  (0.778, 0.783)  \n",
       "5   (0.806, 0.81)  \n",
       "6  (0.792, 0.796)  \n",
       "7  (0.778, 0.794)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vgg_out = pickle.load(open(\".pkl/vgg_out.pkl\", \"rb\"))\n",
    " \n",
    "PCAs_results = pickle.load(open(\".pkl/vgg_pca_out.pkl\", \"rb\"))\n",
    "LDAs_results = pickle.load(open(\".pkl/vgg_lda_out.pkl\", \"rb\"))\n",
    "TSNEs_results = pickle.load(open(\".pkl/vgg_tsne_out.pkl\", \"rb\"))\n",
    "\n",
    "# Number of neighbors to test\n",
    "k_to_test = {\n",
    "    \"VGG\": [3, 5, 9, 15, 21, 55, 111, 251],\n",
    "    \"PCA\": [3, 5, 9, 15, 21, 55, 111, 251],\n",
    "    \"LDA\": [3, 5, 9, 15, 21, 55, 111, 251],\n",
    "}\n",
    "\n",
    "KNN_VGG_stats = []\n",
    "KNN_PCA_stats = []\n",
    "KNN_LDA_stats = []\n",
    "\n",
    "for k_idx, k in enumerate(k_to_test[\"VGG\"]):\n",
    "\n",
    "    KNN_VGG_stats.insert(k_idx, [k])\n",
    "\n",
    "    knn = OneVsOneClassifier(KNeighborsClassifier(k))\n",
    "\n",
    "    knn.fit(vgg_out[\"train\"], dataset[\"train\"][\"labels\"])\n",
    "    preds = knn.predict(vgg_out[\"valid\"])\n",
    "\n",
    "    accuracy = round(accuracy_score(dataset[\"valid\"][\"labels\"], preds), 3)\n",
    "    precision = round(\n",
    "        # f1_score(dataset[\"valid\"][\"labels\"], preds, average=\"weighted\")\n",
    "        # precision_score(dataset[\"valid\"][\"labels\"], preds, average=\"weighted\", labels=np.unique(preds)), 3\n",
    "    )\n",
    "\n",
    "    KNN_VGG_stats[k_idx].append((accuracy, precision))\n",
    "\n",
    "    # ConfusionMatrixDisplay(confusion_matrix(dataset['valid']['labels'], preds),display_labels=dataset['valid']['unique_labels']).plot()\n",
    "\n",
    "KNN_VGG_df = pd.DataFrame(KNN_VGG_stats, columns=[\"k\\\\VGG\", \"\"])\n",
    "display(KNN_VGG_df)\n",
    "\n",
    "for k_idx, k in enumerate(k_to_test[\"PCA\"]):\n",
    "\n",
    "    KNN_PCA_stats.insert(k_idx, [k])\n",
    "\n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test[\"PCA\"]):\n",
    "        knn = OneVsOneClassifier(KNeighborsClassifier(k))\n",
    "\n",
    "        knn.fit(PCAs_results[\"train\"][n_components], dataset[\"train\"][\"labels\"])\n",
    "        preds = knn.predict(PCAs_results[\"valid\"][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset[\"valid\"][\"labels\"], preds), 3)\n",
    "        precision = round(\n",
    "            precision_score(dataset[\"valid\"][\"labels\"], preds, average=\"weighted\", labels=np.unique(preds)), 3\n",
    "        )\n",
    "\n",
    "        KNN_PCA_stats[k_idx].insert(n_components_idx + 1, (accuracy, precision))\n",
    "\n",
    "        # ConfusionMatrixDisplay(confusion_matrix(dataset['valid']['labels'], preds),display_labels=dataset['valid']['unique_labels']).plot()\n",
    "\n",
    "KNN_PCA_df = pd.DataFrame(\n",
    "    KNN_PCA_stats, columns=[\"k\\\\PCA components\"] + n_components_to_test[\"PCA\"]\n",
    ")\n",
    "display(KNN_PCA_df)\n",
    "\n",
    "for k_idx, k in enumerate(k_to_test[\"LDA\"]):\n",
    "\n",
    "    KNN_LDA_stats.insert(k_idx, [k])\n",
    "\n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test[\"LDA\"]):\n",
    "        knn = OneVsOneClassifier(KNeighborsClassifier(k))\n",
    "\n",
    "        knn.fit(LDAs_results[\"train\"][n_components], dataset[\"train\"][\"labels\"])\n",
    "        preds = knn.predict(LDAs_results[\"valid\"][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset[\"valid\"][\"labels\"], preds), 3)\n",
    "        precision = round(\n",
    "            precision_score(dataset[\"valid\"][\"labels\"], preds, average=\"weighted\"), 3\n",
    "        )\n",
    "\n",
    "        KNN_LDA_stats[k_idx].insert(n_components_idx + 1, (accuracy, precision))\n",
    "        # ConfusionMatrixDisplay(confusion_matrix(dataset['valid']['labels'], preds),display_labels=dataset['valid']['unique_labels']).plot()\n",
    "\n",
    "\n",
    "KNN_LDA_df = pd.DataFrame(\n",
    "    KNN_LDA_stats, columns=[\"k\\\\LDA components\"] + n_components_to_test[\"LDA\"]\n",
    ")\n",
    "display(KNN_LDA_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel\\PCA components</th>\n",
       "      <th>3</th>\n",
       "      <th>10</th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>200</th>\n",
       "      <th>500</th>\n",
       "      <th>1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>(0.386, 0.373)</td>\n",
       "      <td>(0.622, 0.623)</td>\n",
       "      <td>(0.73, 0.742)</td>\n",
       "      <td>(0.73, 0.731)</td>\n",
       "      <td>(0.776, 0.777)</td>\n",
       "      <td>(0.794, 0.799)</td>\n",
       "      <td>(0.806, 0.811)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poly</td>\n",
       "      <td>(0.378, 0.417)</td>\n",
       "      <td>(0.598, 0.645)</td>\n",
       "      <td>(0.624, 0.774)</td>\n",
       "      <td>(0.544, 0.771)</td>\n",
       "      <td>(0.396, 0.785)</td>\n",
       "      <td>(0.236, 0.872)</td>\n",
       "      <td>(0.218, 0.667)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>(0.306, 0.305)</td>\n",
       "      <td>(0.548, 0.54)</td>\n",
       "      <td>(0.78, 0.785)</td>\n",
       "      <td>(0.796, 0.8)</td>\n",
       "      <td>(0.804, 0.81)</td>\n",
       "      <td>(0.832, 0.84)</td>\n",
       "      <td>(0.836, 0.842)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernel\\PCA components               3              10              50  \\\n",
       "0                linear  (0.386, 0.373)  (0.622, 0.623)   (0.73, 0.742)   \n",
       "1                  poly  (0.378, 0.417)  (0.598, 0.645)  (0.624, 0.774)   \n",
       "2               sigmoid  (0.306, 0.305)   (0.548, 0.54)   (0.78, 0.785)   \n",
       "\n",
       "              100             200             500            1200  \n",
       "0   (0.73, 0.731)  (0.776, 0.777)  (0.794, 0.799)  (0.806, 0.811)  \n",
       "1  (0.544, 0.771)  (0.396, 0.785)  (0.236, 0.872)  (0.218, 0.667)  \n",
       "2    (0.796, 0.8)   (0.804, 0.81)   (0.832, 0.84)  (0.836, 0.842)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel\\LDA components</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>(0.542, 0.576)</td>\n",
       "      <td>(0.664, 0.693)</td>\n",
       "      <td>(0.758, 0.776)</td>\n",
       "      <td>(0.774, 0.78)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poly</td>\n",
       "      <td>(0.498, 0.602)</td>\n",
       "      <td>(0.572, 0.755)</td>\n",
       "      <td>(0.646, 0.78)</td>\n",
       "      <td>(0.672, 0.788)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>(0.41, 0.393)</td>\n",
       "      <td>(0.592, 0.583)</td>\n",
       "      <td>(0.694, 0.7)</td>\n",
       "      <td>(0.738, 0.745)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernel\\LDA components               3               5               7  \\\n",
       "0                linear  (0.542, 0.576)  (0.664, 0.693)  (0.758, 0.776)   \n",
       "1                  poly  (0.498, 0.602)  (0.572, 0.755)   (0.646, 0.78)   \n",
       "2               sigmoid   (0.41, 0.393)  (0.592, 0.583)    (0.694, 0.7)   \n",
       "\n",
       "                9  \n",
       "0   (0.774, 0.78)  \n",
       "1  (0.672, 0.788)  \n",
       "2  (0.738, 0.745)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel\\VGG components</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>(0.802, 0.806)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poly</td>\n",
       "      <td>(0.53, 0.739)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>(0.832, 0.837)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernel\\VGG components                \n",
       "0                linear  (0.802, 0.806)\n",
       "1                  poly   (0.53, 0.739)\n",
       "2               sigmoid  (0.832, 0.837)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kernels_to_test = {\n",
    "    \"VGG\": [\"linear\", \"poly\", \"sigmoid\"], \n",
    "    \"PCA\": [\"linear\", \"poly\", \"sigmoid\"], \n",
    "    \"LDA\": [\"linear\", \"poly\", \"sigmoid\"], \n",
    "}\n",
    "\n",
    "SVM_VGG_stats = []\n",
    "SVM_PCA_stats = []\n",
    "SVM_LDA_stats = []\n",
    "\n",
    "for kernel_idx, kernel in enumerate(kernels_to_test[\"PCA\"]):\n",
    "\n",
    "    SVM_PCA_stats.insert(kernel_idx, [kernel])\n",
    "\n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test[\"PCA\"]):\n",
    "        svm = OneVsOneClassifier(SVC(kernel=kernel))\n",
    "\n",
    "        svm.fit(PCAs_results[\"train\"][n_components], dataset[\"train\"][\"labels\"])\n",
    "\n",
    "        preds = svm.predict(PCAs_results[\"valid\"][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset[\"valid\"][\"labels\"], preds), 3)\n",
    "        precision = round(\n",
    "            precision_score(dataset[\"valid\"][\"labels\"], preds, average=\"weighted\"), 3\n",
    "        )\n",
    "\n",
    "        SVM_PCA_stats[kernel_idx].insert(n_components_idx + 1, (accuracy, precision))\n",
    "\n",
    "SVM_PCA_df = pd.DataFrame(\n",
    "    SVM_PCA_stats, columns=[\"kernel\\\\PCA components\"] + n_components_to_test[\"PCA\"]\n",
    ")\n",
    "display(SVM_PCA_df)\n",
    "\n",
    "for kernel_idx, kernel in enumerate(kernels_to_test[\"LDA\"]):\n",
    "\n",
    "    SVM_LDA_stats.insert(kernel_idx, [kernel])\n",
    "\n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test[\"LDA\"]):\n",
    "        svm = OneVsOneClassifier(SVC(kernel=kernel))\n",
    "\n",
    "        svm.fit(LDAs_results[\"train\"][n_components], dataset[\"train\"][\"labels\"])\n",
    "\n",
    "        preds = svm.predict(LDAs_results[\"valid\"][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset[\"valid\"][\"labels\"], preds), 3)\n",
    "        precision = round(\n",
    "            precision_score(dataset[\"valid\"][\"labels\"], preds, average=\"weighted\"), 3\n",
    "        )\n",
    "\n",
    "        SVM_LDA_stats[kernel_idx].insert(n_components_idx + 1, (accuracy, precision))\n",
    "\n",
    "SVM_LDA_df = pd.DataFrame(\n",
    "    SVM_LDA_stats, columns=[\"kernel\\\\LDA components\"] + n_components_to_test[\"LDA\"]\n",
    ")\n",
    "display(SVM_LDA_df)\n",
    "\n",
    "\n",
    "for kernel_idx, kernel in enumerate(kernels_to_test[\"VGG\"]):\n",
    "\n",
    "    SVM_VGG_stats.insert(kernel_idx, [kernel])\n",
    "\n",
    "    svm = OneVsOneClassifier(SVC(kernel=kernel))\n",
    "\n",
    "    svm.fit(vgg_out[\"train\"], dataset[\"train\"][\"labels\"])\n",
    "\n",
    "    preds = svm.predict(vgg_out[\"valid\"])\n",
    "\n",
    "    accuracy = round(accuracy_score(dataset[\"valid\"][\"labels\"], preds), 3)\n",
    "    precision = round(\n",
    "        precision_score(dataset[\"valid\"][\"labels\"], preds, average=\"weighted\"), 3\n",
    "    )\n",
    "\n",
    "    SVM_VGG_stats[kernel_idx].append((accuracy, precision))\n",
    "\n",
    "SVM_VGG_df = pd.DataFrame(\n",
    "    SVM_VGG_stats, columns=[\"kernel\\\\VGG components\", \"\"]\n",
    ")\n",
    "display(SVM_VGG_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification - GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>components\\PCA components</th>\n",
       "      <th>500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>(0.106, 0.059)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>(0.002, 1.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   components\\PCA components             500\n",
       "0                         15  (0.106, 0.059)\n",
       "1                        251    (0.002, 1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "2 columns passed, passed data had 5 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:939\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:986\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    989\u001b[0m     )\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 2 columns passed, passed data had 5 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 70\u001b[0m\n\u001b[1;32m     63\u001b[0m         precision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(\n\u001b[1;32m     64\u001b[0m             precision_score(dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m], preds, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     65\u001b[0m         )\n\u001b[1;32m     67\u001b[0m         GMM_LDA_stats[gmm_components_idx]\u001b[38;5;241m.\u001b[39minsert(n_components_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, (accuracy, precision))\n\u001b[0;32m---> 70\u001b[0m GMM_LDA_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mGMM_LDA_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponents\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mLDA components\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# n_components_to_test[\"LDA\"]\u001b[39;49;00m\n\u001b[1;32m     72\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m display(GMM_LDA_df)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:809\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    808\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 809\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    811\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    812\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    815\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    817\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    818\u001b[0m         arrays,\n\u001b[1;32m    819\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    822\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    823\u001b[0m     )\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[0;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:845\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    842\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m    843\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 845\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:942\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    945\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: 2 columns passed, passed data had 5 columns"
     ]
    }
   ],
   "source": [
    "gmm_n_components_to_test = {\n",
    "    \"VGG\": [15, 251],\n",
    "    \"PCA\": [15, 251],\n",
    "    \"LDA\": [15, 251],\n",
    "}\n",
    "\n",
    "GMM_VGG_stats = []\n",
    "GMM_PCA_stats = []\n",
    "GMM_LDA_stats = []\n",
    "\n",
    "# for gmm_components_idx, gmm_n_components in enumerate(gmm_n_components_to_test[\"VGG\"]):\n",
    "\n",
    "#     GMM_VGG_stats.insert(gmm_components_idx, [gmm_n_components])\n",
    "\n",
    "#     GMM = OneVsOneClassifier(GaussianMixture(n_components=gmm_n_components))\n",
    "\n",
    "#     GMM.fit(vgg_out[\"train\"], dataset[\"train\"][\"labels\"])\n",
    "#     preds = GMM.predict(vgg_out[\"valid\"])\n",
    "\n",
    "#     accuracy = round(accuracy_score(dataset[\"valid\"][\"labels\"], preds), 3)\n",
    "#     precision = round(\n",
    "#         precision_score(dataset[\"valid\"][\"labels\"], preds, average=\"weighted\", labels=np.unique(preds)), 3\n",
    "#     )\n",
    "\n",
    "#     GMM_VGG_stats[gmm_components_idx].append((accuracy, precision))\n",
    "\n",
    "# GMM_VGG_df = pd.DataFrame(GMM_VGG_stats, columns=[\"components\\\\VGG\", \"\"])\n",
    "# display(GMM_VGG_df)\n",
    "\n",
    "for gmm_components_idx, gmm_n_components in enumerate(gmm_n_components_to_test[\"PCA\"]):\n",
    "\n",
    "    GMM_PCA_stats.insert(gmm_components_idx, [gmm_n_components])\n",
    "\n",
    "    for n_components_idx, n_components in enumerate([ 500 ]):#enumerate(n_components_to_test[\"PCA\"]):\n",
    "        GMM = GaussianMixture(n_components=gmm_n_components)\n",
    "\n",
    "        GMM.fit(PCAs_results[\"train\"][n_components], dataset[\"train\"][\"labels\"])\n",
    "        preds = GMM.predict(PCAs_results[\"valid\"][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset[\"valid\"][\"labels\"], preds), 3)\n",
    "        precision = round(\n",
    "            precision_score(dataset[\"valid\"][\"labels\"], preds, average=\"weighted\", labels=np.unique(preds)), 3\n",
    "        )\n",
    "\n",
    "        GMM_PCA_stats[gmm_components_idx].insert(n_components_idx + 1, (accuracy, precision))\n",
    "\n",
    "GMM_PCA_df = pd.DataFrame(\n",
    "    GMM_PCA_stats, columns=[\"components\\\\PCA components\"] + [ 500 ]#n_components_to_test[\"PCA\"]\n",
    ")\n",
    "display(GMM_PCA_df)\n",
    "\n",
    "for gmm_components_idx, gmm_n_components in enumerate([7]):#enumerate(gmm_n_components_to_test[\"LDA\"]):\n",
    "\n",
    "    GMM_LDA_stats.insert(gmm_components_idx, [gmm_n_components])\n",
    "\n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test[\"LDA\"]):\n",
    "        GMM = GaussianMixture(n_components=gmm_n_components)\n",
    "\n",
    "        GMM.fit(LDAs_results[\"train\"][n_components], dataset[\"train\"][\"labels\"])\n",
    "        preds = GMM.predict(LDAs_results[\"valid\"][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset[\"valid\"][\"labels\"], preds), 3)\n",
    "        precision = round(\n",
    "            precision_score(dataset[\"valid\"][\"labels\"], preds, average=\"weighted\"), 3\n",
    "        )\n",
    "\n",
    "        GMM_LDA_stats[gmm_components_idx].insert(n_components_idx + 1, (accuracy, precision))\n",
    "\n",
    "\n",
    "GMM_LDA_df = pd.DataFrame(\n",
    "    GMM_LDA_stats, columns=[\"components\\\\LDA components\"] + [ 7 ] # n_components_to_test[\"LDA\"]\n",
    ")\n",
    "display(GMM_LDA_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification - SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss\\VGG</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modified_huber</td>\n",
       "      <td>(0.802, 0.806)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_loss</td>\n",
       "      <td>(0.786, 0.793)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hinge</td>\n",
       "      <td>(0.814, 0.822)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss\\VGG                \n",
       "0  modified_huber  (0.802, 0.806)\n",
       "1        log_loss  (0.786, 0.793)\n",
       "2           hinge  (0.814, 0.822)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss\\PCA</th>\n",
       "      <th>3</th>\n",
       "      <th>10</th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>200</th>\n",
       "      <th>500</th>\n",
       "      <th>1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modified_huber</td>\n",
       "      <td>(0.29, 0.298)</td>\n",
       "      <td>(0.598, 0.592)</td>\n",
       "      <td>(0.744, 0.747)</td>\n",
       "      <td>(0.75, 0.746)</td>\n",
       "      <td>(0.748, 0.748)</td>\n",
       "      <td>(0.772, 0.773)</td>\n",
       "      <td>(0.806, 0.808)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_loss</td>\n",
       "      <td>(0.308, 0.381)</td>\n",
       "      <td>(0.582, 0.63)</td>\n",
       "      <td>(0.752, 0.753)</td>\n",
       "      <td>(0.74, 0.737)</td>\n",
       "      <td>(0.75, 0.75)</td>\n",
       "      <td>(0.78, 0.784)</td>\n",
       "      <td>(0.788, 0.795)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hinge</td>\n",
       "      <td>(0.312, 0.376)</td>\n",
       "      <td>(0.574, 0.557)</td>\n",
       "      <td>(0.734, 0.736)</td>\n",
       "      <td>(0.75, 0.749)</td>\n",
       "      <td>(0.74, 0.739)</td>\n",
       "      <td>(0.768, 0.776)</td>\n",
       "      <td>(0.796, 0.798)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss\\PCA               3              10              50  \\\n",
       "0  modified_huber   (0.29, 0.298)  (0.598, 0.592)  (0.744, 0.747)   \n",
       "1        log_loss  (0.308, 0.381)   (0.582, 0.63)  (0.752, 0.753)   \n",
       "2           hinge  (0.312, 0.376)  (0.574, 0.557)  (0.734, 0.736)   \n",
       "\n",
       "             100             200             500            1200  \n",
       "0  (0.75, 0.746)  (0.748, 0.748)  (0.772, 0.773)  (0.806, 0.808)  \n",
       "1  (0.74, 0.737)    (0.75, 0.75)   (0.78, 0.784)  (0.788, 0.795)  \n",
       "2  (0.75, 0.749)   (0.74, 0.739)  (0.768, 0.776)  (0.796, 0.798)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss\\LDA</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modified_huber</td>\n",
       "      <td>(0.422, 0.441)</td>\n",
       "      <td>(0.522, 0.488)</td>\n",
       "      <td>(0.648, 0.706)</td>\n",
       "      <td>(0.72, 0.737)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_loss</td>\n",
       "      <td>(0.516, 0.635)</td>\n",
       "      <td>(0.64, 0.679)</td>\n",
       "      <td>(0.72, 0.736)</td>\n",
       "      <td>(0.754, 0.775)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hinge</td>\n",
       "      <td>(0.48, 0.538)</td>\n",
       "      <td>(0.598, 0.686)</td>\n",
       "      <td>(0.68, 0.693)</td>\n",
       "      <td>(0.722, 0.749)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss\\LDA               3               5               7  \\\n",
       "0  modified_huber  (0.422, 0.441)  (0.522, 0.488)  (0.648, 0.706)   \n",
       "1        log_loss  (0.516, 0.635)   (0.64, 0.679)   (0.72, 0.736)   \n",
       "2           hinge   (0.48, 0.538)  (0.598, 0.686)   (0.68, 0.693)   \n",
       "\n",
       "                9  \n",
       "0   (0.72, 0.737)  \n",
       "1  (0.754, 0.775)  \n",
       "2  (0.722, 0.749)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "losses_to_test = {\n",
    "    \"VGG\": [\"modified_huber\", \"log_loss\", \"hinge\"],\n",
    "    \"PCA\": [\"modified_huber\", \"log_loss\", \"hinge\"],\n",
    "    \"LDA\": [\"modified_huber\", \"log_loss\", \"hinge\"]\n",
    "}\n",
    "\n",
    "SGD_VGG_stats = []\n",
    "SGD_PCA_stats = []\n",
    "SGD_LDA_stats = []\n",
    "\n",
    "for loss_idx, loss in enumerate(losses_to_test[\"VGG\"]):\n",
    "\n",
    "    SGD_VGG_stats.insert(loss_idx, [loss])\n",
    "\n",
    "    svm = SGDClassifier(loss=loss, max_iter=10000)\n",
    "\n",
    "    svm.fit(vgg_out[\"train\"], dataset[\"train\"][\"labels\"])\n",
    "\n",
    "    preds = svm.predict(vgg_out[\"valid\"])\n",
    "\n",
    "    accuracy = round(accuracy_score(dataset[\"valid\"][\"labels\"], preds), 3)\n",
    "    precision = round(\n",
    "        precision_score(dataset[\"valid\"][\"labels\"], preds, average=\"weighted\"), 3\n",
    "    )\n",
    "\n",
    "    SGD_VGG_stats[loss_idx].append((accuracy, precision))\n",
    "\n",
    "SVM_VGG_df = pd.DataFrame(\n",
    "    SGD_VGG_stats, columns=[\"loss\\\\VGG\", \"\"]\n",
    ")\n",
    "display(SVM_VGG_df)\n",
    "\n",
    "for loss_idx, loss in enumerate(losses_to_test[\"PCA\"]):\n",
    "\n",
    "    SGD_PCA_stats.insert(loss_idx, [loss])\n",
    "\n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test[\"PCA\"]):\n",
    "        sgd = SGDClassifier(loss=loss, max_iter=10000)\n",
    "\n",
    "        sgd.fit(PCAs_results[\"train\"][n_components], dataset[\"train\"][\"labels\"])\n",
    "\n",
    "        preds = sgd.predict(PCAs_results[\"valid\"][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset[\"valid\"][\"labels\"], preds), 3)\n",
    "        precision = round(\n",
    "            precision_score(dataset[\"valid\"][\"labels\"], preds, average=\"macro\"), 3\n",
    "        )\n",
    "\n",
    "        SGD_PCA_stats[loss_idx].insert(\n",
    "            n_components_idx + 1, (accuracy, precision)\n",
    "        )\n",
    "        # ConfusionMatrixDisplay(confusion_matrix(dataset['valid']['labels'], preds),display_labels=dataset['valid']['unique_labels']).plot()\n",
    "\n",
    "SGD_PCA_df = pd.DataFrame(\n",
    "    SGD_PCA_stats, columns=[\"loss\\\\PCA\"] + n_components_to_test[\"PCA\"]\n",
    ")\n",
    "display(SGD_PCA_df)\n",
    "\n",
    "for loss_idx, loss in enumerate(losses_to_test[\"LDA\"]):\n",
    "\n",
    "    SGD_LDA_stats.insert(loss_idx, [loss])\n",
    "\n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test[\"LDA\"]):\n",
    "        sgd = SGDClassifier(loss=loss, max_iter=10000)\n",
    "\n",
    "        sgd.fit(LDAs_results[\"train\"][n_components], dataset[\"train\"][\"labels\"])\n",
    "\n",
    "        preds = sgd.predict(LDAs_results[\"valid\"][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset[\"valid\"][\"labels\"], preds), 3)\n",
    "        precision = round(\n",
    "            precision_score(dataset[\"valid\"][\"labels\"], preds, average=\"macro\"), 3\n",
    "        )\n",
    "\n",
    "        SGD_LDA_stats[loss_idx].insert(\n",
    "            n_components_idx + 1, (accuracy, precision)\n",
    "        )\n",
    "\n",
    "SGD_LDA_df = pd.DataFrame(\n",
    "    SGD_LDA_stats, columns=[\"loss\\\\LDA\"] + n_components_to_test[\"LDA\"]\n",
    ")\n",
    "display(SGD_LDA_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
