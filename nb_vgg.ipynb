{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image,ImageOps\n",
    "import io\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from package.utils.logger import logger\n",
    "import torch\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision.models import VGG16_Weights\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, adjusted_rand_score\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Initialing compute device (use GPU if available).\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEFAULT_LOGGER: 2024-06-14 16:17:48,671 | INFO | 1276424662.py:44 ['data shape(train)', (1500, 224, 224, 3)]\n",
      "DEFAULT_LOGGER: 2024-06-14 16:17:48,672 | INFO | 1276424662.py:45 ['data labels(train)', (1500,)]\n",
      "DEFAULT_LOGGER: 2024-06-14 16:17:48,673 | INFO | 1276424662.py:46 ['data unique labels(train)', array(['apple_pie', 'bibimbap', 'cannoli', 'edamame', 'falafel',\n",
      "       'french_toast', 'ice_cream', 'ramen', 'sushi', 'tiramisu'],\n",
      "      dtype='<U12')]\n",
      "DEFAULT_LOGGER: 2024-06-14 16:17:48,681 | INFO | 1276424662.py:44 ['data shape(valid)', (500, 224, 224, 3)]\n",
      "DEFAULT_LOGGER: 2024-06-14 16:17:48,682 | INFO | 1276424662.py:45 ['data labels(valid)', (500,)]\n",
      "DEFAULT_LOGGER: 2024-06-14 16:17:48,682 | INFO | 1276424662.py:46 ['data unique labels(valid)', array(['apple_pie', 'bibimbap', 'cannoli', 'edamame', 'falafel',\n",
      "       'french_toast', 'ice_cream', 'ramen', 'sushi', 'tiramisu'],\n",
      "      dtype='<U12')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Bootstrap\n",
    "raw_dataset = np.load('.ds.tiny/dataset.zip')\n",
    "\n",
    "dataset = {\n",
    "    'train': {\n",
    "        'data': [],\n",
    "        'names': [],\n",
    "        'labels': [],\n",
    "        'unique_labels': [],\n",
    "    },\n",
    "    'valid': {\n",
    "        'data': [],\n",
    "        'names': [],\n",
    "        'labels': [],\n",
    "        'unique_labels': [],\n",
    "    }\n",
    "}\n",
    "\n",
    "images_shape = (224,224)\n",
    "\n",
    "# For each image we have the path from which we extract the name and the label of the image\n",
    "for dsKey in raw_dataset.keys():\n",
    "    splittedKey = dsKey.split('/')\n",
    "\n",
    "    img_type = splittedKey[2]\n",
    "    img_label = splittedKey[3]\n",
    "    img_name = splittedKey[4]\n",
    "    \n",
    "    img = Image.open(io.BytesIO(raw_dataset[dsKey]))\n",
    "    img = ImageOps.fit(img,images_shape, Image.Resampling.LANCZOS).convert('RGB')\n",
    "    \n",
    "    img_array = np.asarray(img)#.reshape(images_shape[0]*images_shape[1], 3)\n",
    "    \n",
    "    dataset[img_type]['data'].append(img_array)\n",
    "    dataset[img_type]['names'].append(img_name)\n",
    "    dataset[img_type]['labels'].append(img_label)\n",
    "\n",
    "for img_type in dataset.keys():\n",
    "    dataset[img_type]['data'] = np.asarray(dataset[img_type]['data'])\n",
    "    dataset[img_type]['names'] = np.asarray(dataset[img_type]['names'])\n",
    "\n",
    "    dataset[img_type]['unique_labels'], dataset[img_type]['labels'] = np.unique(np.asarray(dataset[img_type]['labels']), return_inverse=True)\n",
    "\n",
    "    logger.info([f'data shape({img_type})', dataset[img_type]['data'].shape])\n",
    "    logger.info([f'data labels({img_type})', dataset[img_type]['labels'].shape])\n",
    "    logger.info([f'data unique labels({img_type})', dataset[img_type]['unique_labels']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 26\u001b[0m\n\u001b[1;32m     21\u001b[0m vgg_out[img_type] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     24\u001b[0m loaded_images \u001b[38;5;241m=\u001b[39m DataLoader(dataset[img_type][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39mdataset[img_type][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 26\u001b[0m res \u001b[38;5;241m=\u001b[39m model(\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloaded_images\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dataset[img_type][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m~/anaconda3/envs/uni/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/envs/uni/lib/python3.10/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/uni/lib/python3.10/site-packages/torchvision/transforms/functional.py:141\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    139\u001b[0m     _log_api_usage_once(to_tensor)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (F_pil\u001b[38;5;241m.\u001b[39m_is_pil_image(pic) \u001b[38;5;129;01mor\u001b[39;00m _is_numpy(pic)):\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic should be PIL Image or ndarray. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(pic)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy(pic) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_numpy_image(pic):\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic should be 2/3 dimensional. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpic\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>"
     ]
    }
   ],
   "source": [
    "normalization_std = [0.229, 0.224, 0.225]\n",
    "normalization_mean = [0.485, 0.456, 0.406]\n",
    "\n",
    "\n",
    "\n",
    "loader = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.RandomResizedCrop(224),\n",
    "    # transforms.Normalize(mean=normalization_mean, std=normalization_std)\n",
    "])\n",
    "\n",
    "vgg_out = {\n",
    "    'train': [],\n",
    "    'valid': []\n",
    "}\n",
    "\n",
    "# Initialize the model.\n",
    "model = models.vgg16(weights=VGG16_Weights.DEFAULT).features.to(device)\n",
    "\n",
    "for img_type in dataset.keys():\n",
    "    vgg_out[img_type] = []\n",
    "\n",
    "\n",
    "    loaded_images = DataLoader(dataset[img_type]['data'], batch_size=dataset[img_type]['data'].shape[0])\n",
    "\n",
    "    res = model(loader(next(iter(loaded_images))))\n",
    "\n",
    "    print(res)\n",
    "    \n",
    "    for image_idx in range(dataset[img_type]['data'].shape[0]):\n",
    "        loaded_image = loader(dataset[img_type]['data'][image_idx, :]).unsqueeze(0).to(device)\n",
    "\n",
    "        res = model(loaded_image)\n",
    "        features = res.data.detach().cpu().numpy().flatten()\n",
    "        print(f\"Extracting feature: {image_idx}/{dataset[img_type]['data'].shape[0]}\")\n",
    "\n",
    "        vgg_out[img_type].append(features)\n",
    "    \n",
    "    vgg_out[img_type] = np.asarray(vgg_out[img_type])\n",
    "    print(vgg_out[img_type].shape)\n",
    "\n",
    "pickle.dump(vgg_out, open( \"vgg_out.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEFAULT_LOGGER: 2024-06-14 16:29:44,258 | INFO | 3293090023.py:46 ['PCA (120 components): explained_variance_ratio sum', 0.41986844]\n",
      "DEFAULT_LOGGER: 2024-06-14 16:29:51,186 | INFO | 3293090023.py:46 ['PCA (800 components): explained_variance_ratio sum', 0.8584969]\n",
      "DEFAULT_LOGGER: 2024-06-14 16:30:08,156 | INFO | 3293090023.py:65 ['LDA (5 components): explained_variance_ratio sum', 0.78163844]\n",
      "DEFAULT_LOGGER: 2024-06-14 16:30:25,789 | INFO | 3293090023.py:65 ['LDA (7 components): explained_variance_ratio sum', 0.90211105]\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 1500 samples in 0.002s...\n",
      "[t-SNE] Computed neighbors for 1500 samples in 0.073s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1500\n",
      "[t-SNE] Computed conditional probabilities for sample 1500 / 1500\n",
      "[t-SNE] Mean sigma: 0.862684\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 62.166275\n",
      "[t-SNE] KL divergence after 3000 iterations: 0.914307\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 500 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 500 samples in 0.010s...\n",
      "[t-SNE] Computed conditional probabilities for sample 500 / 500\n",
      "[t-SNE] Mean sigma: 1.203968\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 60.802074\n",
      "[t-SNE] KL divergence after 2800 iterations: 0.939625\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 1500 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 1500 samples in 0.044s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1500\n",
      "[t-SNE] Computed conditional probabilities for sample 1500 / 1500\n",
      "[t-SNE] Mean sigma: 0.862684\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 62.375847\n",
      "[t-SNE] KL divergence after 3000 iterations: 0.759224\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 500 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 500 samples in 0.011s...\n",
      "[t-SNE] Computed conditional probabilities for sample 500 / 500\n",
      "[t-SNE] Mean sigma: 1.203968\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 60.806877\n",
      "[t-SNE] KL divergence after 850 iterations: 0.747598\n"
     ]
    }
   ],
   "source": [
    "# preload env \n",
    "vgg_out = pickle.load(open( \"vgg_out.pkl\", \"rb\" ))\n",
    "\n",
    "# Dimensionality reduction\n",
    "\n",
    "n_components_to_test = {\n",
    "    'PCA': [120, 800],#[3, 10, 50, 100, 200, 500, 1200],\n",
    "    'LDA': [5, 7],#[3, 5, 7, 9]    \n",
    "    'TSNE': [2,3]\n",
    "}\n",
    "\n",
    "PCAs_instances = {}\n",
    "LDAs_instances = {}\n",
    "TSNEs_instances = {}\n",
    "\n",
    "PCAs_results = {\n",
    "    'train': {},\n",
    "    'valid': {},\n",
    "}\n",
    "\n",
    "LDAs_results = {\n",
    "    'train': {},\n",
    "    'valid': {},\n",
    "}\n",
    "\n",
    "TSNEs_results = {\n",
    "    'train': {},\n",
    "    'valid': {},\n",
    "}\n",
    "\n",
    "for n_components in n_components_to_test['PCA']:\n",
    "    PCAs_instances[n_components] = []\n",
    "\n",
    "    PCAs_results['train'][n_components] = []\n",
    "    PCAs_results['valid'][n_components] = []\n",
    "\n",
    "    PCA_instance = PCA(n_components=n_components)\n",
    "    \n",
    "    PCA_instance.fit(vgg_out['train'])\n",
    "\n",
    "    PCAs_results['train'][n_components] = PCA_instance.transform(vgg_out['train'])\n",
    "    PCAs_results['valid'][n_components] = PCA_instance.transform(vgg_out['valid']) \n",
    "\n",
    "    PCAs_instances[n_components] = PCA_instance\n",
    "\n",
    "    logger.info([f'PCA ({n_components} components): explained_variance_ratio sum', np.sum(PCA_instance.explained_variance_ratio_,axis=0)])\n",
    "\n",
    "\n",
    "for n_components in n_components_to_test['LDA']:\n",
    "\n",
    "    LDAs_instances[n_components] = []\n",
    "\n",
    "    LDAs_results['train'][n_components] = []\n",
    "    LDAs_results['valid'][n_components] = []\n",
    "\n",
    "    LDA_instance = LinearDiscriminantAnalysis(n_components=n_components)\n",
    "    \n",
    "    LDA_instance.fit(vgg_out['train'], dataset['train']['labels'])\n",
    "\n",
    "    LDAs_results['train'][n_components] = LDA_instance.transform(vgg_out['train'])\n",
    "    LDAs_results['valid'][n_components] = LDA_instance.transform(vgg_out['valid']) \n",
    "\n",
    "    LDAs_instances[n_components] = LDA_instance\n",
    "\n",
    "    logger.info([f'LDA ({n_components} components): explained_variance_ratio sum', np.sum(LDA_instance.explained_variance_ratio_,axis=0)])\n",
    "\n",
    "for n_components in n_components_to_test['TSNE']:\n",
    "\n",
    "    TSNEs_instances[n_components] = []\n",
    "\n",
    "    TSNEs_results['train'][n_components] = []\n",
    "    #TSNEs_results['valid'][n_components] = []\n",
    "\n",
    "    TSNE_instance_train =  TSNE(n_components=n_components, verbose=1, n_iter=3000)\n",
    "    TSNE_instance_valid =  TSNE(n_components=n_components, verbose=1, n_iter=3000)\n",
    "\n",
    "    #TSNEs_results['train'][n_components] = TSNE_instance_train.fit_transform(vgg_out['train'])\n",
    "    #TSNEs_results['valid'][n_components] = TSNE_instance_valid.fit_transform(vgg_out['valid'])\n",
    "\n",
    "    TSNEs_results['train'][n_components] = TSNE_instance_train.fit_transform(LDAs_results['train'][7])\n",
    "    TSNEs_results['valid'][n_components] = TSNE_instance_valid.fit_transform(LDAs_results['valid'][7])\n",
    "\n",
    "    TSNEs_instances[n_components] = [TSNE_instance_train, TSNE_instance_valid]\n",
    "\n",
    "\n",
    "    # logger.info([f'TSNE ({n_components} components): explained_variance_ratio sum', np.sum(TSNE_instance[1].explained_variance_ratio_,axis=0)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 2)\n",
      "(150, 2)\n",
      "(150, 2)\n",
      "(150, 2)\n",
      "(150, 2)\n",
      "(150, 2)\n",
      "(150, 2)\n",
      "(150, 2)\n",
      "(150, 2)\n",
      "(150, 2)\n"
     ]
    }
   ],
   "source": [
    "fig_2d = plt.figure()\n",
    "ax = fig_2d.add_subplot()\n",
    "\n",
    "for i in range(len(dataset['train']['unique_labels'])):\n",
    "    classIdxs = dataset['train']['labels'] == i\n",
    "\n",
    "    tsne_features = TSNEs_results['train'][2][classIdxs,:]\n",
    "\n",
    "    print(tsne_features.shape)\n",
    "\n",
    "    ax.set_label(dataset['train']['unique_labels'][i])\n",
    "    ax.scatter(tsne_features[:,0], tsne_features[:,1], marker='.', label=dataset['train']['unique_labels'][i])\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "fig_3d = plt.figure()\n",
    "ax = fig_3d.add_subplot(projection='3d')\n",
    "for i in range(len(dataset['train']['unique_labels'])):\n",
    "    classIdxs = dataset['train']['labels'] == i\n",
    "\n",
    "    tsne_features = TSNEs_results['train'][3][classIdxs,:]\n",
    "    \n",
    "    ax.scatter(tsne_features[:,0], tsne_features[:,1], tsne_features[:,2], marker='.', label=dataset['train']['unique_labels'][i])\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k\\VGG</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>(0.276, 0.521)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>(0.318, 0.404)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>(0.334, 0.444)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>(0.344, 0.487)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>(0.322, 0.502)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55</td>\n",
       "      <td>(0.264, 0.519)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111</td>\n",
       "      <td>(0.23, 0.643)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>251</td>\n",
       "      <td>(0.23, 0.325)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k\\VGG                \n",
       "0      3  (0.276, 0.521)\n",
       "1      5  (0.318, 0.404)\n",
       "2      9  (0.334, 0.444)\n",
       "3     15  (0.344, 0.487)\n",
       "4     21  (0.322, 0.502)\n",
       "5     55  (0.264, 0.519)\n",
       "6    111   (0.23, 0.643)\n",
       "7    251   (0.23, 0.325)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k\\PCA components</th>\n",
       "      <th>120</th>\n",
       "      <th>800</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>(0.544, 0.564)</td>\n",
       "      <td>(0.358, 0.444)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>(0.554, 0.589)</td>\n",
       "      <td>(0.346, 0.471)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>(0.548, 0.616)</td>\n",
       "      <td>(0.334, 0.49)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>(0.546, 0.638)</td>\n",
       "      <td>(0.316, 0.568)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>(0.512, 0.634)</td>\n",
       "      <td>(0.29, 0.591)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55</td>\n",
       "      <td>(0.42, 0.619)</td>\n",
       "      <td>(0.212, 0.445)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111</td>\n",
       "      <td>(0.358, 0.632)</td>\n",
       "      <td>(0.212, 0.316)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>251</td>\n",
       "      <td>(0.234, 0.367)</td>\n",
       "      <td>(0.222, 0.241)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k\\PCA components             120             800\n",
       "0                 3  (0.544, 0.564)  (0.358, 0.444)\n",
       "1                 5  (0.554, 0.589)  (0.346, 0.471)\n",
       "2                 9  (0.548, 0.616)   (0.334, 0.49)\n",
       "3                15  (0.546, 0.638)  (0.316, 0.568)\n",
       "4                21  (0.512, 0.634)   (0.29, 0.591)\n",
       "5                55   (0.42, 0.619)  (0.212, 0.445)\n",
       "6               111  (0.358, 0.632)  (0.212, 0.316)\n",
       "7               251  (0.234, 0.367)  (0.222, 0.241)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k\\LDA components</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>(0.496, 0.526)</td>\n",
       "      <td>(0.596, 0.615)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>(0.52, 0.572)</td>\n",
       "      <td>(0.628, 0.649)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>(0.538, 0.596)</td>\n",
       "      <td>(0.642, 0.667)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>(0.548, 0.62)</td>\n",
       "      <td>(0.628, 0.656)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>(0.55, 0.617)</td>\n",
       "      <td>(0.632, 0.665)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55</td>\n",
       "      <td>(0.544, 0.632)</td>\n",
       "      <td>(0.642, 0.685)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111</td>\n",
       "      <td>(0.536, 0.641)</td>\n",
       "      <td>(0.62, 0.69)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>251</td>\n",
       "      <td>(0.502, 0.617)</td>\n",
       "      <td>(0.596, 0.69)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k\\LDA components               5               7\n",
       "0                 3  (0.496, 0.526)  (0.596, 0.615)\n",
       "1                 5   (0.52, 0.572)  (0.628, 0.649)\n",
       "2                 9  (0.538, 0.596)  (0.642, 0.667)\n",
       "3                15   (0.548, 0.62)  (0.628, 0.656)\n",
       "4                21   (0.55, 0.617)  (0.632, 0.665)\n",
       "5                55  (0.544, 0.632)  (0.642, 0.685)\n",
       "6               111  (0.536, 0.641)    (0.62, 0.69)\n",
       "7               251  (0.502, 0.617)   (0.596, 0.69)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classification - KNN\n",
    "\n",
    "k_to_test = {\n",
    "    'VGG': [3, 5, 9, 15, 21, 55, 111, 251],\n",
    "    'PCA': [3, 5, 9, 15, 21, 55, 111, 251],\n",
    "    'LDA': [3, 5, 9, 15, 21, 55, 111, 251]\n",
    "}\n",
    "\n",
    "KNN_VGG_stats = []\n",
    "KNN_PCA_stats = []\n",
    "KNN_LDA_stats = []\n",
    "\n",
    "for k_idx, k in enumerate(k_to_test['VGG']):\n",
    "\n",
    "    KNN_VGG_stats.insert(k_idx,[k])\n",
    "\n",
    "    knn = KNeighborsClassifier(k)\n",
    "\n",
    "    knn.fit(vgg_out['train'], dataset['train']['labels'])\n",
    "    preds = knn.predict(vgg_out['valid'])\n",
    "\n",
    "    accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "    precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "    \n",
    "    KNN_VGG_stats[k_idx].append((accuracy, precision))\n",
    "\n",
    "    #ConfusionMatrixDisplay(confusion_matrix(dataset['valid']['labels'], preds),display_labels=dataset['valid']['unique_labels']).plot()\n",
    "\n",
    "KNN_VGG_df = pd.DataFrame(KNN_VGG_stats, columns=['k\\\\VGG', ''])\n",
    "display(KNN_VGG_df)\n",
    "\n",
    "for k_idx, k in enumerate(k_to_test['PCA']):\n",
    "\n",
    "    KNN_PCA_stats.insert(k_idx,[k])\n",
    "\n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['PCA']):\n",
    "        knn = OneVsOneClassifier(KNeighborsClassifier(k))\n",
    "\n",
    "        knn.fit(PCAs_results['train'][n_components], dataset['train']['labels'])\n",
    "        preds = knn.predict(PCAs_results['valid'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "        \n",
    "        KNN_PCA_stats[k_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "        #ConfusionMatrixDisplay(confusion_matrix(dataset['valid']['labels'], preds),display_labels=dataset['valid']['unique_labels']).plot()\n",
    "\n",
    "KNN_PCA_df = pd.DataFrame(KNN_PCA_stats, columns=['k\\\\PCA components'] + n_components_to_test['PCA'])\n",
    "display(KNN_PCA_df)\n",
    "\n",
    "for k_idx,k in enumerate(k_to_test['LDA']):\n",
    "    \n",
    "    KNN_LDA_stats.insert(k_idx,[k])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['LDA']):\n",
    "        knn = OneVsOneClassifier( KNeighborsClassifier(k))\n",
    "        \n",
    "        knn.fit(LDAs_results['train'][n_components], dataset['train']['labels'])\n",
    "        preds = knn.predict(LDAs_results['valid'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        KNN_LDA_stats[k_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "        # ConfusionMatrixDisplay(confusion_matrix(dataset['valid']['labels'], preds),display_labels=dataset['valid']['unique_labels']).plot()\n",
    "\n",
    "\n",
    "KNN_LDA_df = pd.DataFrame(KNN_LDA_stats, columns=['k\\\\LDA components'] + n_components_to_test['LDA'])\n",
    "display(KNN_LDA_df)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel\\PCA components</th>\n",
       "      <th>120</th>\n",
       "      <th>800</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>(0.678, 0.69)</td>\n",
       "      <td>(0.722, 0.727)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poly</td>\n",
       "      <td>(0.428, 0.699)</td>\n",
       "      <td>(0.198, 0.728)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>(0.714, 0.723)</td>\n",
       "      <td>(0.728, 0.735)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernel\\PCA components             120             800\n",
       "0                linear   (0.678, 0.69)  (0.722, 0.727)\n",
       "1                  poly  (0.428, 0.699)  (0.198, 0.728)\n",
       "2               sigmoid  (0.714, 0.723)  (0.728, 0.735)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel\\LDA components</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>(0.512, 0.562)</td>\n",
       "      <td>(0.59, 0.627)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poly</td>\n",
       "      <td>(0.446, 0.655)</td>\n",
       "      <td>(0.466, 0.727)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>(0.496, 0.498)</td>\n",
       "      <td>(0.616, 0.616)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernel\\LDA components               5               7\n",
       "0                linear  (0.512, 0.562)   (0.59, 0.627)\n",
       "1                  poly  (0.446, 0.655)  (0.466, 0.727)\n",
       "2               sigmoid  (0.496, 0.498)  (0.616, 0.616)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/enrico/anaconda3/envs/uni/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel\\TSNE components</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>(0.038, 0.02)</td>\n",
       "      <td>(0.07, 0.044)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poly</td>\n",
       "      <td>(0.08, 0.016)</td>\n",
       "      <td>(0.078, 0.026)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>(0.036, 0.032)</td>\n",
       "      <td>(0.032, 0.035)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernel\\TSNE components               2               3\n",
       "0                 linear   (0.038, 0.02)   (0.07, 0.044)\n",
       "1                   poly   (0.08, 0.016)  (0.078, 0.026)\n",
       "2                sigmoid  (0.036, 0.032)  (0.032, 0.035)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classification - SVM\n",
    "\n",
    "kernels_to_test = {\n",
    "    'PCA': ['linear', 'poly', 'sigmoid'],#['linear', 'poly', 'sigmoid'],\n",
    "    'LDA': ['linear', 'poly', 'sigmoid'],#['linear', 'poly', 'sigmoid'],\n",
    "    'TSNE': ['linear', 'poly', 'sigmoid']#['linear', 'poly', 'sigmoid'],\n",
    "}\n",
    "\n",
    "SVM_PCA_stats = []\n",
    "SVM_LDA_stats = []\n",
    "SVM_TSNE_stats = []\n",
    "\n",
    "for kernel_idx,kernel in enumerate(kernels_to_test['PCA']):\n",
    "\n",
    "    SVM_PCA_stats.insert(kernel_idx,[kernel])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['PCA']):#n_components_to_test['PCA']):\n",
    "        svm = OneVsOneClassifier(SVC(kernel=kernel))\n",
    "\n",
    "        svm.fit(PCAs_results['train'][n_components], dataset['train']['labels'])\n",
    "\n",
    "        preds = svm.predict(PCAs_results['valid'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        SVM_PCA_stats[kernel_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "SVM_PCA_df = pd.DataFrame(SVM_PCA_stats, columns=['kernel\\\\PCA components'] + n_components_to_test['PCA'])\n",
    "display(SVM_PCA_df)\n",
    "\n",
    "for kernel_idx,kernel in enumerate(kernels_to_test['LDA']):\n",
    "\n",
    "    SVM_LDA_stats.insert(kernel_idx,[kernel])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['LDA']):\n",
    "        svm = OneVsOneClassifier(SVC(kernel=kernel))\n",
    "\n",
    "        svm.fit(LDAs_results['train'][n_components], dataset['train']['labels'])\n",
    "\n",
    "        preds = svm.predict(LDAs_results['valid'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        SVM_LDA_stats[kernel_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "SVM_LDA_df = pd.DataFrame(SVM_LDA_stats, columns=['kernel\\\\LDA components'] + n_components_to_test['LDA'])\n",
    "display(SVM_LDA_df)\n",
    "\n",
    "for kernel_idx,kernel in enumerate(kernels_to_test['TSNE']):\n",
    "\n",
    "    SVM_TSNE_stats.insert(kernel_idx,[kernel])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['TSNE']):\n",
    "        svm = OneVsOneClassifier(SVC(kernel=kernel))\n",
    "\n",
    "        svm.fit(TSNEs_results['train'][n_components], dataset['train']['labels'])\n",
    "\n",
    "        preds = svm.predict(TSNEs_results['valid'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        SVM_TSNE_stats[kernel_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "SVM_TSNE_df = pd.DataFrame(SVM_TSNE_stats, columns=['kernel\\\\TSNE components'] + n_components_to_test['TSNE'])\n",
    "display(SVM_TSNE_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss\\PCA</th>\n",
       "      <th>120</th>\n",
       "      <th>800</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modified_huber</td>\n",
       "      <td>(0.684, 0.694)</td>\n",
       "      <td>(0.708, 0.712)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_loss</td>\n",
       "      <td>(0.676, 0.681)</td>\n",
       "      <td>(0.718, 0.721)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hinge</td>\n",
       "      <td>(0.694, 0.696)</td>\n",
       "      <td>(0.704, 0.714)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss\\PCA             120             800\n",
       "0  modified_huber  (0.684, 0.694)  (0.708, 0.712)\n",
       "1        log_loss  (0.676, 0.681)  (0.718, 0.721)\n",
       "2           hinge  (0.694, 0.696)  (0.704, 0.714)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss\\LDA</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modified_huber</td>\n",
       "      <td>(0.494, 0.515)</td>\n",
       "      <td>(0.528, 0.544)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_loss</td>\n",
       "      <td>(0.488, 0.463)</td>\n",
       "      <td>(0.544, 0.565)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hinge</td>\n",
       "      <td>(0.494, 0.49)</td>\n",
       "      <td>(0.546, 0.584)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss\\LDA               5               7\n",
       "0  modified_huber  (0.494, 0.515)  (0.528, 0.544)\n",
       "1        log_loss  (0.488, 0.463)  (0.544, 0.565)\n",
       "2           hinge   (0.494, 0.49)  (0.546, 0.584)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classification - SGD\n",
    "\n",
    "losses_to_test = {\n",
    "    'PCA': ['modified_huber', 'log_loss', 'hinge'],\n",
    "    'LDA': ['modified_huber', 'log_loss', 'hinge'],#['modified_huber', 'log_loss', 'hinge']\n",
    "}\n",
    "\n",
    "SGD_PCA_grayscale_stats = []\n",
    "SGD_LDA_grayscale_stats = []\n",
    "\n",
    "for loss_idx,loss in enumerate(losses_to_test['PCA']):\n",
    "\n",
    "    SGD_PCA_grayscale_stats.insert(loss_idx,[loss])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['PCA']):#n_components_to_test['PCA']):\n",
    "        svm = OneVsOneClassifier(SGDClassifier(loss=loss, max_iter=10000 ))\n",
    "\n",
    "        svm.fit(PCAs_results['train'][n_components], dataset['train']['labels'])\n",
    "\n",
    "        preds = svm.predict(PCAs_results['valid'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        SGD_PCA_grayscale_stats[loss_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "        # ConfusionMatrixDisplay(confusion_matrix(dataset['valid']['labels'], preds),display_labels=dataset['valid']['unique_labels']).plot()\n",
    "\n",
    "SGD_PCA_df = pd.DataFrame(SGD_PCA_grayscale_stats, columns=['loss\\\\PCA'] + n_components_to_test['PCA'])\n",
    "display(SGD_PCA_df)\n",
    "\n",
    "for loss_idx,loss in enumerate(losses_to_test['LDA']):\n",
    "\n",
    "    SGD_LDA_grayscale_stats.insert(loss_idx,[loss])\n",
    "    \n",
    "    for n_components_idx, n_components in enumerate(n_components_to_test['LDA']):\n",
    "        svm = OneVsOneClassifier(SGDClassifier(loss=loss, max_iter=10000 ))\n",
    "\n",
    "        svm.fit(LDAs_results['train'][n_components], dataset['train']['labels'])\n",
    "\n",
    "        preds = svm.predict(LDAs_results['valid'][n_components])\n",
    "\n",
    "        accuracy = round(accuracy_score(dataset['valid']['labels'], preds), 3)\n",
    "        precision = round(precision_score(dataset['valid']['labels'], preds, average='macro'),3)\n",
    "\n",
    "        SGD_LDA_grayscale_stats[loss_idx].insert(n_components_idx + 1,(accuracy, precision))\n",
    "\n",
    "SGD_LDA_df = pd.DataFrame(SGD_LDA_grayscale_stats, columns=['loss\\\\LDA'] + n_components_to_test['LDA'])\n",
    "display(SGD_LDA_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = transforms.Compose([\n",
    "    \n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
